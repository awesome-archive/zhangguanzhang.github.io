<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Zhangguanzhang</title>
  
  <subtitle>站在巨人的肩膀上</subtitle>
  <link href="http://zhangguanzhang.github.io/atom.xml" rel="self"/>
  
  <link href="http://zhangguanzhang.github.io/"/>
  <updated>2022-03-24T20:28:30.000Z</updated>
  <id>http://zhangguanzhang.github.io/</id>
  
  <author>
    <name>Zhangguanzhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>python kubernetes client list permission</title>
    <link href="http://zhangguanzhang.github.io/2022/03/24/python-list-kubernetes-permission/"/>
    <id>http://zhangguanzhang.github.io/2022/03/24/python-list-kubernetes-permission/</id>
    <published>2022-03-24T20:28:30.000Z</published>
    <updated>2022-03-24T20:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>这几天内部有个功能就是看 kubernetes client 的权限有哪些</p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><h3 id="kubeconfig-生成"><a href="#kubeconfig-生成" class="headerlink" title="kubeconfig 生成"></a>kubeconfig 生成</h3><p>先制作一个非 admin 的 kubeconfig，记得以前有个项目是部署后可以生成 kubeconfig 的，询问了一番后，其他群友提示下想起来是 <a href="https://github.com/sighupio/permission-manager">permission-manager</a>，部署后结果发现生成的 kubeconfig 压根不能用，报错未知机构签署的，结果还是按照以前 <a href="https://zhangguanzhang.github.io/2018/10/27/create-kubeconfig/">生成kubeconfig常规的两种方法</a> 生成了一个简单的。</p><h3 id="尝试过程"><a href="#尝试过程" class="headerlink" title="尝试过程"></a>尝试过程</h3><p>其实一开始打算自己写逻辑，增删改查需要的资源便利来检查，然后突然想起来 kubectl (忘了哪个版本开始)有个 auth 子命令的 <code>can-i</code> 来列出权限：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl --kubeconfig=/etc/kubernetes/develoop.kubeconfig  auth can-i --namespace xxx --list -v=8</span><br><span class="line">I0325 15:58:24.972928   31603 loader.go:379] Config loaded from file:  /etc/kubernetes/develoop.kubeconfig</span><br><span class="line">I0325 15:58:24.974793   31603 request.go:1107] Request Body: &#123;&quot;kind&quot;:&quot;SelfSubjectRulesReview&quot;,&quot;apiVersion&quot;:&quot;authorization.k8s.io/v1&quot;,&quot;metadata&quot;:&#123;&quot;creationTimestamp&quot;:null&#125;,&quot;spec&quot;:&#123;&quot;namespace&quot;:&quot;xxx&quot;&#125;,&quot;status&quot;:&#123;&quot;resourceRules&quot;:null,&quot;nonResourceRules&quot;:null,&quot;incomplete&quot;:false&#125;&#125;</span><br><span class="line">I0325 15:58:24.974912   31603 round_trippers.go:422] POST https://127.0.0.1:8443/apis/authorization.k8s.io/v1/selfsubjectrulesreviews</span><br><span class="line">I0325 15:58:24.974927   31603 round_trippers.go:429] Request Headers:</span><br><span class="line">I0325 15:58:24.974938   31603 round_trippers.go:433]     Accept: application/json, */*</span><br><span class="line">I0325 15:58:24.974947   31603 round_trippers.go:433]     Content-Type: application/json</span><br><span class="line">I0325 15:58:24.974957   31603 round_trippers.go:433]     User-Agent: kubectl/v1.20.6 (linux/amd64) kubernetes/8a62859</span><br><span class="line">I0325 15:58:24.974968   31603 round_trippers.go:433]     Authorization: Bearer &lt;masked&gt;</span><br><span class="line">I0325 15:58:25.007471   31603 round_trippers.go:448] Response Status: 201 Created in 32 milliseconds</span><br><span class="line">I0325 15:58:25.007513   31603 round_trippers.go:451] Response Headers:</span><br><span class="line">I0325 15:58:25.007523   31603 round_trippers.go:454]     Cache-Control: no-cache, private</span><br><span class="line">I0325 15:58:25.007530   31603 round_trippers.go:454]     Content-Type: application/json</span><br><span class="line">I0325 15:58:25.007537   31603 round_trippers.go:454]     X-Kubernetes-Pf-Flowschema-Uid: 39e31546-1002-4e5b-a810-7bbeb09467a5</span><br><span class="line">I0325 15:58:25.007547   31603 round_trippers.go:454]     X-Kubernetes-Pf-Prioritylevel-Uid: 08ee1b31-c8de-4f8a-aa1c-b098f4e02ae1</span><br><span class="line">I0325 15:58:25.007554   31603 round_trippers.go:454]     Content-Length: 1028</span><br><span class="line">I0325 15:58:25.007561   31603 round_trippers.go:454]     Date: Fri, 25 Mar 2022 07:58:25 GMT</span><br><span class="line">I0325 15:58:25.007656   31603 request.go:1107] Response Body: &#123;&quot;kind&quot;:&quot;SelfSubjectRulesReview&quot;,&quot;apiVersion&quot;:&quot;authorization.k8s.io/v1&quot;,&quot;metadata&quot;:&#123;&quot;creationTimestamp&quot;:null&#125;,&quot;spec&quot;:&#123;&#125;,&quot;status&quot;:&#123;&quot;resourceRules&quot;:[&#123;&quot;verbs&quot;:[&quot;create&quot;],&quot;apiGroups&quot;:[&quot;authorization.k8s.io&quot;],&quot;resources&quot;:[&quot;selfsubjectaccessreviews&quot;,&quot;selfsubjectrulesreviews&quot;]&#125;,&#123;&quot;verbs&quot;:[&quot;*&quot;],&quot;apiGroups&quot;:[&quot;*&quot;],&quot;resources&quot;:[&quot;secrets&quot;,&quot;configmaps&quot;,&quot;serviceaccounts&quot;,&quot;endpoints&quot;,&quot;events&quot;,&quot;pods&quot;,&quot;pods/log&quot;,&quot;pods/portforward&quot;,&quot;podtemplates&quot;,&quot;resourcequotas&quot;,&quot;limitranges&quot;,&quot;services&quot;,&quot;replicationcontrollers&quot;,&quot;daemonsets&quot;,&quot;deployments&quot;,&quot;replicasets&quot;,&quot;statefulsets&quot;,&quot;cronjobs&quot;,&quot;jobs&quot;,&quot;persistentvolumeclaims&quot;,&quot;ingresses&quot;,&quot;networkpolicies&quot;,&quot;poddisruptionbudgets&quot;]&#125;],&quot;nonResourceRules&quot;:[&#123;&quot;verbs&quot;:[&quot;get&quot;],&quot;nonResourceURLs&quot;:[&quot;/healthz&quot;,&quot;/livez&quot;,&quot;/readyz&quot;,&quot;/version&quot;,&quot;/version/&quot;]&#125;,&#123;&quot;verbs&quot;:[&quot;get&quot;],&quot;nonResourceURLs&quot;:[&quot;/api&quot;,&quot;/api/*&quot;,&quot;/apis&quot;,&quot;/apis/*&quot;,&quot;/healthz&quot;,&quot;/livez&quot;,&quot;/openapi&quot;,&quot;/openapi/*&quot;,&quot;/readyz&quot;,&quot;/version&quot;,&quot;/version/&quot;]&#125;,&#123;&quot;verbs&quot;:[&quot;get&quot;],&quot;nonResourceURLs&quot;:[&quot;/.well-known/openid-configuration&quot;,&quot;/openid/v1/jwks&quot;]&#125;],&quot;incomplete&quot;:fals [truncated 4 chars]</span><br><span class="line">Resources                                       Non-Resource URLs                     Resource Names   Verbs</span><br><span class="line">configmaps.*                                    []                                    []               [*]</span><br><span class="line">cronjobs.*                                      []                                    []               [*]</span><br><span class="line">daemonsets.*                                    []                                    []               [*]</span><br><span class="line">deployments.*                                   []                                    []               [*]</span><br><span class="line">endpoints.*                                     []                                    []               [*]</span><br><span class="line">events.*                                        []                                    []               [*]</span><br><span class="line">ingresses.*                                     []                                    []               [*]</span><br><span class="line">jobs.*                                          []                                    []               [*]</span><br><span class="line">limitranges.*                                   []                                    []               [*]</span><br><span class="line">networkpolicies.*                               []                                    []               [*]</span><br><span class="line">persistentvolumeclaims.*                        []                                    []               [*]</span><br><span class="line">poddisruptionbudgets.*                          []                                    []               [*]</span><br><span class="line">pods.*/log                                      []                                    []               [*]</span><br><span class="line">pods.*/portforward                              []                                    []               [*]</span><br><span class="line">pods.*                                          []                                    []               [*]</span><br><span class="line">podtemplates.*                                  []                                    []               [*]</span><br><span class="line">replicasets.*                                   []                                    []               [*]</span><br><span class="line">replicationcontrollers.*                        []                                    []               [*]</span><br><span class="line">resourcequotas.*                                []                                    []               [*]</span><br><span class="line">secrets.*                                       []                                    []               [*]</span><br><span class="line">serviceaccounts.*                               []                                    []               [*]</span><br><span class="line">services.*                                      []                                    []               [*]</span><br><span class="line">statefulsets.*                                  []                                    []               [*]</span><br><span class="line">selfsubjectaccessreviews.authorization.k8s.io   []                                    []               [create]</span><br><span class="line">selfsubjectrulesreviews.authorization.k8s.io    []                                    []               [create]</span><br><span class="line">                                                [/.well-known/openid-configuration]   []               [get]</span><br><span class="line">                                                [/api/*]                              []               [get]</span><br><span class="line">                                                [/api]                                []               [get]</span><br><span class="line">                                                [/apis/*]                             []               [get]</span><br><span class="line">                                                [/apis]                               []               [get]</span><br><span class="line">                                                [/healthz]                            []               [get]</span><br><span class="line">                                                [/healthz]                            []               [get]</span><br><span class="line">                                                [/livez]                              []               [get]</span><br><span class="line">                                                [/livez]                              []               [get]</span><br><span class="line">                                                [/openapi/*]                          []               [get]</span><br><span class="line">                                                [/openapi]                            []               [get]</span><br><span class="line">                                                [/openid/v1/jwks]                     []               [get]</span><br><span class="line">                                                [/readyz]                             []               [get]</span><br><span class="line">                                                [/readyz]                             []               [get]</span><br><span class="line">                                                [/version/]                           []               [get]</span><br><span class="line">                                                [/version/]                           []               [get]</span><br><span class="line">                                                [/version]                            []               [get]</span><br><span class="line">                                                [/version]                            []               [get]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>搜索 python kubernetes client selfsubjectrulesreviews 搜到官方的 <a href="https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/AuthorizationV1Api.md#create_self_subject_rules_review">create_self_subject_rules_review 示例</a></p><p>试了下报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ cat t2</span><br><span class="line"></span><br><span class="line">from kubernetes import client, config</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    body = client.V1SelfSubjectRulesReview()</span><br><span class="line">    print(body)</span><br><span class="line">$ python t2</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;t2&quot;, line 5, in &lt;module&gt;</span><br><span class="line">    body = client.V1SelfSubjectRulesReview()</span><br><span class="line">  File &quot;/usr/local/lib/python3.7/site-packages/kubernetes/client/models/v1_self_subject_rules_review.py&quot;, line 70, in __init__</span><br><span class="line">    self.spec = spec</span><br><span class="line">  File &quot;/usr/local/lib/python3.7/site-packages/kubernetes/client/models/v1_self_subject_rules_review.py&quot;, line 160, in spec</span><br><span class="line">    raise ValueError(&quot;Invalid value for `spec`, must not be `None`&quot;)  # noqa: E501</span><br><span class="line">ValueError: Invalid value for `spec`, must not be `None`</span><br></pre></td></tr></table></figure><p>大概看了下这个类 <code>V1SelfSubjectRulesReview</code>，需要传递 spec 属性才不会报错，点击跳转到模块源码里，没看到啥有用的参考，毕竟弱语言类型。后面找了个 <a href="https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1SelfSubjectRulesReviewSpec.md">V1SelfSubjectRulesReviewSpec</a>，单独传个空的 v1 spec 就会报错缺少 namespace，按照 python 的 client 库习惯，尝试了下面的还是报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rule_review_spec = client.V1SelfSubjectAccessReviewSpec(namespace=&#x27;xxx&#x27;)</span><br><span class="line">body = c.V1SelfSubjectRulesReview(spec=rule_review_spec)</span><br></pre></td></tr></table></figure><p>最后摸索出来下面这样才对，真是无语了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">body = client.V1SelfSubjectRulesReview(spec=&#123;<span class="string">&quot;namespace&quot;</span>: namespace&#125;)</span><br><span class="line">result = client.AuthorizationV1Api().create_self_subject_rules_review(body=body)</span><br><span class="line"><span class="keyword">return</span> result.status.resource_rules</span><br></pre></td></tr></table></figure><p>输出为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[&#123;&#x27;api_groups&#x27;: [&#x27;authorization.k8s.io&#x27;],</span><br><span class="line"> &#x27;resource_names&#x27;: None,</span><br><span class="line"> &#x27;resources&#x27;: [&#x27;selfsubjectaccessreviews&#x27;, &#x27;selfsubjectrulesreviews&#x27;],</span><br><span class="line"> &#x27;verbs&#x27;: [&#x27;create&#x27;]&#125;, &#123;&#x27;api_groups&#x27;: [&#x27;*&#x27;],</span><br><span class="line"> &#x27;resource_names&#x27;: None,</span><br><span class="line"> &#x27;resources&#x27;: [&#x27;secrets&#x27;,</span><br><span class="line">               &#x27;configmaps&#x27;,</span><br><span class="line">               &#x27;serviceaccounts&#x27;,</span><br><span class="line">               &#x27;endpoints&#x27;,</span><br><span class="line">               &#x27;events&#x27;,</span><br><span class="line">               &#x27;pods&#x27;,</span><br><span class="line">               &#x27;pods/log&#x27;,</span><br><span class="line">               &#x27;pods/portforward&#x27;,</span><br><span class="line">               &#x27;podtemplates&#x27;,</span><br><span class="line">               &#x27;resourcequotas&#x27;,</span><br><span class="line">               &#x27;limitranges&#x27;,</span><br><span class="line">               &#x27;services&#x27;,</span><br><span class="line">               &#x27;replicationcontrollers&#x27;,</span><br><span class="line">               &#x27;daemonsets&#x27;,</span><br><span class="line">               &#x27;deployments&#x27;,</span><br><span class="line">               &#x27;replicasets&#x27;,</span><br><span class="line">               &#x27;statefulsets&#x27;,</span><br><span class="line">               &#x27;cronjobs&#x27;,</span><br><span class="line">               &#x27;jobs&#x27;,</span><br><span class="line">               &#x27;persistentvolumeclaims&#x27;,</span><br><span class="line">               &#x27;ingresses&#x27;,</span><br><span class="line">               &#x27;networkpolicies&#x27;,</span><br><span class="line">               &#x27;poddisruptionbudgets&#x27;],</span><br><span class="line"> &#x27;verbs&#x27;: [&#x27;*&#x27;]&#125;]</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://github.com/kubernetes-client/python/blob/master/kubernetes/README.md#documentation-for-api-endpoints">documentation-for-api-endpoints</a></li><li><a href="https://github.com/kubernetes-client/python/blob/master/kubernetes/README.md">官方 client 库的 readme，里面有方法名字对应调用的哪个 URL</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;由来&quot;&gt;&lt;a href=&quot;#由来&quot; class=&quot;headerlink&quot; title=&quot;由来&quot;&gt;&lt;/a&gt;由来&lt;/h2&gt;&lt;p&gt;这几天内部有个功能就是看 kubernetes client 的权限有哪些&lt;/p&gt;
&lt;h2 id=&quot;过程&quot;&gt;&lt;a href=&quot;#过程&quot; cl</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://zhangguanzhang.github.io/tags/kubernetes/"/>
    
    <category term="python" scheme="http://zhangguanzhang.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>server 端的 cannot assign requested address</title>
    <link href="http://zhangguanzhang.github.io/2022/03/16/cannot-assign-requested-address/"/>
    <id>http://zhangguanzhang.github.io/2022/03/16/cannot-assign-requested-address/</id>
    <published>2022-03-16T20:28:30.000Z</published>
    <updated>2022-03-16T20:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>今天碰到了这个问题，但是最终结果出乎意料</p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><h3 id="项目相关部分"><a href="#项目相关部分" class="headerlink" title="项目相关部分"></a>项目相关部分</h3><p>客户的 OA 对接我们的应用，使用过程中会调用我们的接口，我们的接口再回调客户的回调地址。调用流是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">客户 OA 后端 ----&gt; 我们应用 A 的后端 -----&gt; 我们应用 B 后端  -----&gt; 客户写的回调地址</span><br></pre></td></tr></table></figure><p>然后我们接口 A 返回 B 访问回调的报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;Get http://10.192.xxx.xxx/xxxxinfo?...: dial tcp 10.192.xxx.xxx:80: connect: cannot assign requested address&quot;</span><br></pre></td></tr></table></figure><h3 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h3><p>一开始看到这个报错的时候就知道，这个报错是 TCP 四元组哪个组不够用都会报错这个的，但是最优先和最常见的就是 client 的端口耗尽，也就是 client 端的 port range 不够用了，一般是这个 B 服务机器上 client 的端口达到上限了，可以通过下面参数调整下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -a |&amp; grep port | grep range</span><br></pre></td></tr></table></figure><p>结果实际上上去 B 服务上 curl 这个 url 能返回 http 状态码。起初以为真的是我们服务 B 在瞬间有端口没释放的 bug，但是 curl 能返回 http 状态码（但是内容是空的），说明 tcp 层面没问题。因为 http 返回信息是空的，我们初步怀疑到是客户的回调服务偷偷更新了后导致的。后面让客户取消掉他们回调 url 的后端校验 token 逻辑。他们换了后还是一样，然后他们把这个接口的逻辑代码截图了，以及把回调服务的日志发过来的。</p><p>看了下日志，发现报错信息里有 token 校验过的和没有校验成功的，校验失败的那些原因都是过期了。询问了下发现回调的 IP 后面有好几个服务副本，让客户他们去检查机器时间试试，然后客户下班了，另一个同事说可以单独修改我们服务 B 的设置，指向单台副本绕过负载均衡试试，最后发现 5 个每个单独都正常，指向负载均衡的 IP 就不行，询问后发现是硬件负载均衡。最后第二天客户排查到是硬件负载均衡的连接数异常。是深信服的硬件负载均衡。</p><h2 id="结论和学习"><a href="#结论和学习" class="headerlink" title="结论和学习"></a>结论和学习</h2><p>其实一开始的 curl 正常能返回 http 状态码就说明 tcp 没问题，不过这次也算是见识到了，server 端的端口不够也会返回 <code>cannot assign requested address</code> 的报错，也就是主动打开还是被动打开，这个错误的信息都是一样的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;由来&quot;&gt;&lt;a href=&quot;#由来&quot; class=&quot;headerlink&quot; title=&quot;由来&quot;&gt;&lt;/a&gt;由来&lt;/h2&gt;&lt;p&gt;今天碰到了这个问题，但是最终结果出乎意料&lt;/p&gt;
&lt;h2 id=&quot;过程&quot;&gt;&lt;a href=&quot;#过程&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    
    <category term="golang" scheme="http://zhangguanzhang.github.io/tags/golang/"/>
    
    <category term="tcp" scheme="http://zhangguanzhang.github.io/tags/tcp/"/>
    
  </entry>
  
  <entry>
    <title>keepalived static link build</title>
    <link href="http://zhangguanzhang.github.io/2022/02/24/keepalived-static-build/"/>
    <id>http://zhangguanzhang.github.io/2022/02/24/keepalived-static-build/</id>
    <published>2022-02-24T14:28:30.000Z</published>
    <updated>2022-02-24T14:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>之前那篇 ipvs svc 的文章，内部已经上生产了，客户的环境可能完全内网，包管理安装 keepalived 不现实，所以 keepalived 是部署容器里的。在容灾测试的时候，例如 3 台机器部署好业务，然后跑压测脚本模拟用户使用，发现关台机器的时候故障时间很短，但是这个机器开机的期间，还是很大概率故障时间很长，体现在接口的错误数量很多。大概看了下，是 keepalived 启动慢，先试启动 docker daemon，然后容器启动是顺序不固定，可能 keepalived 很后起来，于是就想着看看能不能 keepalived 拿出来，也就是静态编译。</p><h3 id="buildx-使用"><a href="#buildx-使用" class="headerlink" title="buildx 使用"></a>buildx 使用</h3><p>见文章 <a href="https://github.com/zhangguanzhang/docker-need-to-know/blob/master/2.docker-image/dockerfile/buildx.md">buildx 使用</a></p><h3 id="折腾"><a href="#折腾" class="headerlink" title="折腾"></a>折腾</h3><p>在官方仓库提了 issue <a href="https://github.com/acassen/keepalived/issues/2107">is there any way to static build</a> 后，和开发者沟通尝试过不少姿势都不行，然后有个大佬 hack 下编译成功了。开发者参照改了下后我试了下最新源码试可以整出来了。</p><p>主要是在 alpine 容器构建:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/acassen/keepalived.git</span><br><span class="line"><span class="built_in">cd</span> keepalived</span><br><span class="line">docker run -v <span class="variable">$PWD</span>:/opt --workdir /opt --rm -ti alpine</span><br></pre></td></tr></table></figure><p>构建依赖参考仓库里的 <a href="https://github.com/acassen/keepalived/blob/master/Dockerfile.in">Dockerfile.in</a> , static 库之类的可以 <a href="https://pkgs.alpinelinux.org/packages?name=*-static*&branch=edge&repo=main">alpinelinux</a> 上去搜索</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">if [ -f /etc/apk/repositories ];then sed -i &#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27; /etc/apk/repositories; fi &amp;&amp; \</span><br><span class="line">    if [ -f /etc/apt/sources.list ];then sed -ri &#x27;s/(deb|security).debian.org/mirrors.aliyun.com/g&#x27; /etc/apt/sources.list; fi &amp;&amp; \</span><br><span class="line">    if [ ! -e /etc/nsswitch.conf ];then echo &#x27;hosts: files dns myhostname&#x27; &gt; /etc/nsswitch.conf; fi</span><br><span class="line"></span><br><span class="line">apk --no-cache add \</span><br><span class="line">    binutils \</span><br><span class="line">    file \</span><br><span class="line">    file-dev \</span><br><span class="line">    gcc \</span><br><span class="line">    glib \</span><br><span class="line">    glib-dev \</span><br><span class="line">    ipset \</span><br><span class="line">    ipset-dev \</span><br><span class="line">    iptables \</span><br><span class="line">    iptables-dev \</span><br><span class="line">    libmnl-dev \</span><br><span class="line">    libnftnl-dev \</span><br><span class="line">    libnl3 \</span><br><span class="line">    libnl3-dev \</span><br><span class="line">    make \</span><br><span class="line">    musl-dev \</span><br><span class="line">    net-snmp-dev \</span><br><span class="line">    openssl \</span><br><span class="line">    openssl-dev \</span><br><span class="line">    openssl-libs-static \</span><br><span class="line">    pcre2 \</span><br><span class="line">    pcre2-dev \</span><br><span class="line">    autoconf \</span><br><span class="line">    automake zlib-static  alpine-sdk linux-headers  libmnl-static</span><br></pre></td></tr></table></figure><p>当然，你会发现没有 <code>configure</code> 脚本，可以参照 <a href="https://github.com/acassen/keepalived/blob/master/INSTALL">INSTALL</a> 里执行 <code>./autogen.sh</code> 生成，INSTALL 里可以参考下，有些包名在 os 上可能换了名字。同时如果要折腾的话，建议看下 <code>--help</code> 的内容。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./autogen.sh</span><br><span class="line">./configure --help</span><br></pre></td></tr></table></figure><p>静态编译的配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">CFLAGS=&#x27;-static -s&#x27; LDFLAGS=-static ./configure  --disable-dynamic-linking \</span><br><span class="line">    --prefix=/usr \</span><br><span class="line">    --exec-prefix=/usr \</span><br><span class="line">    --bindir=/usr/bin \</span><br><span class="line">    --sbindir=/usr/sbin \</span><br><span class="line">    --sysconfdir=/etc \</span><br><span class="line">    --datadir=/usr/share \</span><br><span class="line">    --localstatedir=/var \</span><br><span class="line">    --mandir=/usr/share/man \</span><br><span class="line">    --enable-bfd \</span><br><span class="line">    --enable-snmp \</span><br><span class="line">    --enable-snmp-rfc \</span><br><span class="line">    --enable-nftables \</span><br><span class="line">    --enable-regex \</span><br><span class="line">    --enable-json  --with-init=systemd --enable-vrrp --enable-libnl-dynamic</span><br></pre></td></tr></table></figure><p>配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">Keepalived version       : 2.2.7</span><br><span class="line">Compiler                 : gcc gcc (Alpine 10.3.1_git20211027) 10.3.1 20211027</span><br><span class="line">Preprocessor flags       : -D_GNU_SOURCE -DNETSNMP_NO_INLINE</span><br><span class="line">Compiler flags           : -g -static -s -Wall -Wextra -Wunused -Wstrict-prototypes -Wabi -Wabsolute-value -Waddress-of-packed-member -Walloca -Walloc-zero -Warith-conversion -Warray-bounds=2 -Wattribute-alias=2 -Wbad-function-cast -Wc11-c2x-compat -Wcast-align -Wcast-qual -Wdate-time -Wdisabled-optimization -Wdouble-promotion -Wduplicated-branches -Wduplicated-cond -Wfloat-conversion -Wfloat-equal -Wformat-overflow -Wformat-security -Wformat-signedness -Wformat-truncation -Wframe-larger-than=5120 -Wimplicit-fallthrough=3 -Winit-self -Winline -Winvalid-pch -Wjump-misses-init -Wlogical-op -Wmissing-declarations -Wmissing-field-initializers -Wmissing-include-dirs -Wmissing-prototypes -Wnested-externs -Wnormalized -Wnull-dereference -Wold-style-definition -Woverlength-strings -Wpointer-arith -Wredundant-decls -Wshadow -Wshift-overflow=2 -Wstack-protector -Wstrict-overflow=4 -Wstringop-overflow=2 -Wstringop-truncation -Wsuggest-attribute=cold -Wsuggest-attribute=const -Wsuggest-attribute=format -Wsuggest-attribute=malloc -Wsuggest-attribute=noreturn -Wsuggest-attribute=pure -Wsync-nand -Wtrampolines -Wundef -Wuninitialized -Wunknown-pragmas -Wunsafe-loop-optimizations -Wunsuffixed-float-constants -Wunused-const-variable=2 -Wvariadic-macros -Wwrite-strings -fPIE -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -O2</span><br><span class="line">Linker flags             : -static -pie -Wl,-z,relro -Wl,-z,now -L/usr/lib</span><br><span class="line">Extra Lib                : -lm -lssl -lcrypto -lnftnl -lmnl -lpcre2-8 -lnetsnmpmibs -lnetsnmpagent -lnetsnmp -lcrypto</span><br><span class="line">Use IPVS Framework       : Yes</span><br><span class="line">IPVS use libnl           : No</span><br><span class="line">IPVS syncd attributes    : Yes</span><br><span class="line">IPVS 64 bit stats        : Yes</span><br><span class="line">HTTP_GET regex support   : Yes</span><br><span class="line">fwmark socket support    : Yes</span><br><span class="line">Use VRRP Framework       : Yes</span><br><span class="line">Use VRRP VMAC            : Yes</span><br><span class="line">Use VRRP authentication  : Yes</span><br><span class="line">With track_process       : Yes</span><br><span class="line">With linkbeat            : Yes</span><br><span class="line">Use BFD Framework        : Yes</span><br><span class="line">SNMP vrrp support        : Yes</span><br><span class="line">SNMP checker support     : Yes</span><br><span class="line">SNMP RFCv2 support       : Yes</span><br><span class="line">SNMP RFCv3 support       : Yes</span><br><span class="line">SNMP send V3 for V2      : Yes</span><br><span class="line">DBUS support             : No</span><br><span class="line">Use JSON output          : Yes</span><br><span class="line">libnl version            : None</span><br><span class="line">Use IPv4 devconf         : Yes</span><br><span class="line">Use iptables             : No</span><br><span class="line">Use nftables             : Yes</span><br><span class="line">init type                : systemd</span><br><span class="line">systemd notify           : No</span><br><span class="line">Strict config checks     : No</span><br><span class="line">Build documentation      : No</span><br><span class="line">Default runtime options  : -D</span><br><span class="line"></span><br><span class="line">*** WARNING - this build will not support IPVS with IPv6. Please install libnl/libnl-3 dev libraries to support IPv6 with IPVS.</span><br></pre></td></tr></table></figure><p><code>libnl/libnl-3</code> 这个我试了下加不进去，<code>apk add libnl-dev</code> 可以加上去，但是我看了 alpine 里 <code>keepalived -v</code> 的 configure 里也没我上面开的多。强开我试了 <code>CPPFLAGS=&#39;-I/usr/include/libnl3&#39; LDLIBS=&#39;-lnl3 -lnl-genl-3&#39; </code> 和下载 libnl-3 编译安装后都不行，想折腾和传递参数啥的话，多看看 <code>configure</code> 文件里的内容。</p><p>编译和安装：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">/opt # keepalived -v</span><br><span class="line">Keepalived v2.2.7 (02/23,2022), git commit v2.2.7-22-geb533a93</span><br><span class="line"></span><br><span class="line">Copyright(C) 2001-2022 Alexandre Cassen, &lt;acassen@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">Built with kernel headers for Linux 5.10.41</span><br><span class="line">Running on Linux 5.4.0-99-generic #112-Ubuntu SMP Thu Feb 3 13:50:55 UTC 2022</span><br><span class="line">Distro: Alpine Linux v3.15</span><br><span class="line"></span><br><span class="line">configure options: --disable-dynamic-linking --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --localstatedir=/var --mandir=/usr/share/man --enable-bfd --enable-snmp --enable-snmp-rfc --enable-nftables --enable-regex --enable-json --with-init=systemd --enable-vrrp --enable-libnl-dynamic CFLAGS=-static -s LDFLAGS=-static</span><br><span class="line"></span><br><span class="line">Config options:  NFTABLES LVS REGEX VRRP VRRP_AUTH VRRP_VMAC JSON BFD OLD_CHKSUM_COMPAT SNMP_V3_FOR_V2 SNMP_VRRP SNMP_CHECKER SNMP_RFCV2 SNMP_RFCV3 INIT=systemd</span><br><span class="line"></span><br><span class="line">System options:  VSYSLOG MEMFD_CREATE IPV6_MULTICAST_ALL IPV4_DEVCONF RTA_ENCAP RTA_EXPIRES RTA_NEWDST RTA_PREF FRA_SUPPRESS_PREFIXLEN FRA_SUPPRESS_IFGROUP FRA_TUN_ID RTAX_CC_ALGO RTAX_QUICKACK RTEXT_FILTER_SKIP_STATS FRA_L3MDEV FRA_UID_RANGE RTAX_FASTOPEN_NO_COOKIE RTA_VIA FRA_PROTOCOL FRA_IP_PROTO FRA_SPORT_RANGE FRA_DPORT_RANGE RTA_TTL_PROPAGATE IFA_FLAGS LWTUNNEL_ENCAP_MPLS LWTUNNEL_ENCAP_ILA NET_LINUX_IF_H_COLLISION NETINET_LINUX_IF_ETHER_H_COLLISION IPVS_DEST_ATTR_ADDR_FAMILY IPVS_SYNCD_ATTRIBUTES IPVS_64BIT_STATS IPVS_TUN_TYPE IPVS_TUN_CSUM IPVS_TUN_GRE VRRP_IPVLAN IFLA_LINK_NETNSID INET6_ADDR_GEN_MODE VRF SO_MARK</span><br><span class="line">/opt # file `which keepalived`</span><br><span class="line">/usr/sbin/keepalived: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, stripped</span><br><span class="line">/opt # ldd `which keepalived`</span><br><span class="line">/lib/ld-musl-x86_64.so.1: /usr/sbin/keepalived: Not a valid dynamic program</span><br></pre></td></tr></table></figure><h3 id="buildx-一步到位"><a href="#buildx-一步到位" class="headerlink" title="buildx 一步到位"></a>buildx 一步到位</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine as build</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="keyword">if</span> [ -f /etc/apk/repositories ];<span class="keyword">then</span> sed -i <span class="string">&#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27;</span> /etc/apk/repositories; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="keyword">if</span> [ -f /etc/apt/sources.list ];<span class="keyword">then</span> sed -ri <span class="string">&#x27;s/(deb|security).debian.org/mirrors.aliyun.com/g&#x27;</span> /etc/apt/sources.list; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="keyword">if</span> [ ! -e /etc/nsswitch.conf ];<span class="keyword">then</span> <span class="built_in">echo</span> <span class="string">&#x27;hosts: files dns myhostname&#x27;</span> &gt; /etc/nsswitch.conf; <span class="keyword">fi</span>  &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk --no-cache add \</span></span><br><span class="line"><span class="bash">        binutils \</span></span><br><span class="line"><span class="bash">        file \</span></span><br><span class="line"><span class="bash">        file-dev \</span></span><br><span class="line"><span class="bash">        gcc \</span></span><br><span class="line"><span class="bash">        glib \</span></span><br><span class="line"><span class="bash">        glib-dev \</span></span><br><span class="line"><span class="bash">        ipset \</span></span><br><span class="line"><span class="bash">        ipset-dev \</span></span><br><span class="line"><span class="bash">        iptables \</span></span><br><span class="line"><span class="bash">        iptables-dev \</span></span><br><span class="line"><span class="bash">        libmnl-dev \</span></span><br><span class="line"><span class="bash">        libnftnl-dev \</span></span><br><span class="line"><span class="bash">        libnl3 \</span></span><br><span class="line"><span class="bash">        libnl3-dev \</span></span><br><span class="line"><span class="bash">        make \</span></span><br><span class="line"><span class="bash">        musl-dev \</span></span><br><span class="line"><span class="bash">        net-snmp-dev \</span></span><br><span class="line"><span class="bash">        openssl \</span></span><br><span class="line"><span class="bash">        openssl-dev \</span></span><br><span class="line"><span class="bash">        openssl-libs-static \</span></span><br><span class="line"><span class="bash">        pcre2 \</span></span><br><span class="line"><span class="bash">        pcre2-dev \</span></span><br><span class="line"><span class="bash">        autoconf \</span></span><br><span class="line"><span class="bash">        automake zlib-static  alpine-sdk linux-headers  libmnl-static git</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /opt</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/acassen/keepalived.git</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -ex &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">cd</span> /opt/keepalived &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ./autogen.sh &amp;&amp; \</span></span><br><span class="line"><span class="bash">    CFLAGS=<span class="string">&#x27;-static -s&#x27;</span> LDFLAGS=-static ./configure  --disable-dynamic-linking \</span></span><br><span class="line"><span class="bash">    --prefix=/usr \</span></span><br><span class="line"><span class="bash">    --exec-prefix=/usr \</span></span><br><span class="line"><span class="bash">    --bindir=/usr/bin \</span></span><br><span class="line"><span class="bash">    --sbindir=/usr/sbin \</span></span><br><span class="line"><span class="bash">    --sysconfdir=/etc \</span></span><br><span class="line"><span class="bash">    --datadir=/usr/share \</span></span><br><span class="line"><span class="bash">    --localstatedir=/var \</span></span><br><span class="line"><span class="bash">    --mandir=/usr/share/man \</span></span><br><span class="line"><span class="bash">    --enable-bfd \</span></span><br><span class="line"><span class="bash">    --enable-snmp \</span></span><br><span class="line"><span class="bash">    --enable-snmp-rfc \</span></span><br><span class="line"><span class="bash">    --enable-nftables \</span></span><br><span class="line"><span class="bash">    --enable-regex \</span></span><br><span class="line"><span class="bash">    --enable-json  --with-init=systemd --enable-vrrp --enable-libnl-dynamic</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -ex &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">cd</span> /opt/keepalived &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make DESTDIR=/install_root install &amp;&amp; \</span></span><br><span class="line"><span class="bash">    find /install_root &amp;&amp; \</span></span><br><span class="line"><span class="bash"><span class="comment"># delete the docs</span></span></span><br><span class="line">    rm -rf /install_root/usr/share</span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> scratch AS bin</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=build /install_root /</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>构建:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker buildx build  . --platform linux/amd64,linux/arm64 \</span><br><span class="line">    --target bin --output . </span><br></pre></td></tr></table></figure><p>信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ ./usr/sbin/keepalived -v</span><br><span class="line">Keepalived v2.2.7 (02/23,2022), git commit v2.2.7-22-geb533a93</span><br><span class="line"></span><br><span class="line">Copyright(C) 2001-2022 Alexandre Cassen, &lt;acassen@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">Built with kernel headers for Linux 5.10.41</span><br><span class="line">Running on Linux 5.4.0-99-generic #112-Ubuntu SMP Thu Feb 3 13:50:55 UTC 2022</span><br><span class="line">Distro: Ubuntu 20.04.3 LTS</span><br><span class="line"></span><br><span class="line">configure options: --disable-dynamic-linking --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --localstatedir=/var --mandir=/usr/share/man --enable-bfd --enable-snmp --enable-snmp-rfc --enable-nftables --enable-regex --enable-json --with-init=systemd --enable-vrrp --enable-libnl-dynamic CFLAGS=-static -s LDFLAGS=-static</span><br><span class="line"></span><br><span class="line">Config options:  NFTABLES LVS REGEX VRRP VRRP_AUTH VRRP_VMAC JSON BFD OLD_CHKSUM_COMPAT SNMP_V3_FOR_V2 SNMP_VRRP SNMP_CHECKER SNMP_RFCV2 SNMP_RFCV3 INIT=systemd</span><br><span class="line"></span><br><span class="line">System options:  VSYSLOG MEMFD_CREATE IPV6_MULTICAST_ALL IPV4_DEVCONF RTA_ENCAP RTA_EXPIRES RTA_NEWDST RTA_PREF FRA_SUPPRESS_PREFIXLEN FRA_SUPPRESS_IFGROUP FRA_TUN_ID RTAX_CC_ALGO RTAX_QUICKACK RTEXT_FILTER_SKIP_STATS FRA_L3MDEV FRA_UID_RANGE RTAX_FASTOPEN_NO_COOKIE RTA_VIA FRA_PROTOCOL FRA_IP_PROTO FRA_SPORT_RANGE FRA_DPORT_RANGE RTA_TTL_PROPAGATE IFA_FLAGS LWTUNNEL_ENCAP_MPLS LWTUNNEL_ENCAP_ILA NET_LINUX_IF_H_COLLISION NETINET_LINUX_IF_ETHER_H_COLLISION IPVS_DEST_ATTR_ADDR_FAMILY IPVS_SYNCD_ATTRIBUTES IPVS_64BIT_STATS IPVS_TUN_TYPE IPVS_TUN_CSUM IPVS_TUN_GRE VRRP_IPVLAN IFLA_LINK_NETNSID INET6_ADDR_GEN_MODE VRF SO_MARK</span><br><span class="line"></span><br><span class="line">$ ldd ./usr/sbin/keepalived </span><br><span class="line">not a dynamic executable</span><br><span class="line">$ file ./usr/sbin/keepalived</span><br><span class="line">./usr/sbin/keepalived: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, stripped</span><br><span class="line">$ ls -lh ./usr/sbin/keepalived</span><br><span class="line">-rwxr-xr-x 1 root root 4.4M Feb 24 17:56 ./usr/sbin/keepalived</span><br></pre></td></tr></table></figure><p>试了下 arm64的也可以构建 <code>--platform linux/amd64,linux/arm64</code> 即可。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;由来&quot;&gt;&lt;a href=&quot;#由来&quot; class=&quot;headerlink&quot; title=&quot;由来&quot;&gt;&lt;/a&gt;由来&lt;/h2&gt;&lt;p&gt;之前那篇 ipvs svc 的文章，内部已经上生产了，客户的环境可能完全内网，包管理安装 keepalived 不现实，所以 keepali</summary>
      
    
    
    
    
    <category term="linux" scheme="http://zhangguanzhang.github.io/tags/linux/"/>
    
    <category term="keepalived" scheme="http://zhangguanzhang.github.io/tags/keepalived/"/>
    
  </entry>
  
  <entry>
    <title>proxmox 开机 error: disk &#39;lvmid/[vg uuid]/[lv uuid]&#39; not found</title>
    <link href="http://zhangguanzhang.github.io/2022/02/18/proxmox-boot-disk-lvmid-not-found/"/>
    <id>http://zhangguanzhang.github.io/2022/02/18/proxmox-boot-disk-lvmid-not-found/</id>
    <published>2022-02-18T14:17:30.000Z</published>
    <updated>2022-02-18T14:17:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>一次 proxmox 机器突然宕机，开机后进入 grub resuce 无法启动的处理过程</p><span id="more"></span><h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>上午 ssh 到 proxmox 上的虚机上做实验，突然机器断开了，以为是虚机的问题，结果发现是 proxmox 机器有问题了，接上显示器重启看到进入了 grub rescue 模式。</p><p>pve 版本信息为如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pveversion</span><br><span class="line">pve-manager/6.2-4/9824574a (running kernel: 5.4.34-1-pve)</span><br></pre></td></tr></table></figure><h2 id="处理过程"><a href="#处理过程" class="headerlink" title="处理过程"></a>处理过程</h2><h3 id="错误信息"><a href="#错误信息" class="headerlink" title="错误信息"></a>错误信息</h3><p>错误信息为如下，暂时看了下 lvm 是存在的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">error: disk `lvmid/ExzA22-yHkV-0ymE-XbMT-zrD6-69Wp-bboRVP/zbB3V2-Kg2Y-EdI6-dbs1-6uSo-e6wk-ZRBJdh&#x27; not found.</span><br><span class="line">Entering rescue mode...</span><br><span class="line">grub rescue&gt; ls</span><br><span class="line">(lvm/pve-root) (lvm/pve-swap) (hd0) (hd1) (hd1,gpt3) (hd1,gpt2) (hd1,gpt1) </span><br></pre></td></tr></table></figure><h3 id="进入-rescue-模式"><a href="#进入-rescue-模式" class="headerlink" title="进入 rescue 模式"></a>进入 rescue 模式</h3><p>向同事借了个 u 盘，把我笔记本上的 CentOS 7.9 minimal 的 ISO 烧录进去后，插到 proxmox 的 USB 口子上，（机器是 dell 台式机）开机 F12 选择从 U 盘启动。<br>选择 <code>Troubleshooting –&gt; Rescue</code> 选中 <code>Rescue a CentOS system</code> ，一直等待，有交互后，选择 3，也就是 <code>3) Skip to shell</code>。</p><p>先看下 lvm 信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ pvs</span><br><span class="line">  PV         VG  Fmt  Attr PSize    PFree  </span><br><span class="line">  /dev/sda1  pve lvm2 a--  &lt;931.51g 697.50g</span><br><span class="line">  /dev/sdb3  pve lvm2 a--  &lt;476.44g      0</span><br><span class="line">$ vgs</span><br><span class="line">  VG  #PV #LV #SN Attr   VSize VFree  </span><br><span class="line">  pve   2  23   0 wz--n- 1.37t 697.50g</span><br><span class="line">$ lvs</span><br><span class="line">  LV                           VG  Attr       LSize    Pool Origin          Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  base-101-disk-0              pve Vri---tz-k   10.00g data                                                        </span><br><span class="line">  base-106-disk-0              pve Vri---tz-k   20.00g data                                                        </span><br><span class="line">  data                         pve twi-aotz-- &lt;550.29g                      73.93  6.08                            </span><br><span class="line">  root                         pve -wi-ao----  146.00g                                                             </span><br><span class="line">  snap_vm-102-disk-0_a20210429 pve Vri---tz-k   30.00g data vm-102-disk-0                                          </span><br><span class="line">  swap                         pve -wi-ao----    7.00g                                                             </span><br><span class="line">  vm-100-cloudinit             pve Vwi-a-tz--    4.00m data                 9.38                                   </span><br><span class="line">  vm-100-disk-0                pve Vwi-a-tz--   10.00g data base-101-disk-0 16.65                                  </span><br><span class="line">  vm-100-disk-1                pve Vwi-a-tz--    7.00g data                 0.17                                   </span><br><span class="line">  vm-101-cloudinit             pve Vwi-a-tz--    4.00m data                 0.00                                   </span><br><span class="line">  vm-102-cloudinit             pve Vwi-aotz--    4.00m data                 9.38                                   </span><br><span class="line">  vm-102-disk-0                pve Vwi-aotz--  100.00g data                 73.78                                  </span><br><span class="line">  vm-102-state-a20210429       pve Vwi-a-tz--   &lt;8.49g data                 44.03                                  </span><br><span class="line">  vm-103-disk-0                pve Vwi-a-tz--   25.00g data                 99.98                                  </span><br><span class="line">  vm-104-disk-0                pve Vwi-a-tz--   &lt;2.02g data                 99.31                                  </span><br><span class="line">  vm-105-cloudinit             pve Vwi-a-tz--    4.00m data                 9.38                                   </span><br><span class="line">  vm-105-disk-0                pve Vwi-a-tz--   10.00g data                 85.13                                  </span><br><span class="line">  vm-106-cloudinit             pve Vwi-a-tz--    4.00m data                 0.00                                   </span><br><span class="line">  vm-107-cloudinit             pve Vwi-a-tz--    4.00m data                 9.38                                   </span><br><span class="line">  vm-107-disk-0                pve Vwi-a-tz--   30.00g data                 65.94                                  </span><br><span class="line">  vm-108-cloudinit             pve Vwi-aotz--    4.00m data                 9.38                                   </span><br><span class="line">  vm-108-disk-0                pve Vwi-aotz--  250.00g data                 99.21                                  </span><br><span class="line">  vm-200-disk-0                pve Vwi-aotz--   &lt;2.02g data                 99.31 </span><br></pre></td></tr></table></figure><p>激活下 vg 看看：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ vgchange -a y</span><br><span class="line">/usr/sbin/dmeventd: stat failed: No such file or directory</span><br><span class="line">WARNING: Failed to monirot pve/data.</span><br><span class="line">/usr/sbin/dmeventd: stat failed: No such file or directory</span><br><span class="line">WARNING: Failed to monirot pve/data.</span><br><span class="line">/usr/sbin/dmeventd: stat failed: No such file or directory</span><br><span class="line">WARNING: Failed to monirot pve/data.</span><br><span class="line">/usr/sbin/dmeventd: stat failed: No such file or directory</span><br><span class="line">WARNING: Failed to monirot pve/data.</span><br><span class="line">/usr/sbin/dmeventd: stat failed: No such file or directory</span><br><span class="line">WARNING: Failed to monirot pve/data.</span><br><span class="line">/usr/sbin/dmeventd: stat failed: No such file or directory</span><br><span class="line">WARNING: Failed to monirot pve/data.</span><br><span class="line">...</span><br><span class="line">20 logical volume(s) in volume group &quot;pve&quot; now active</span><br></pre></td></tr></table></figure><p>手动挂载下看看</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ mount /dev/mapper/pve-root /mnt/sysimage</span><br><span class="line">$ cd /mnt/sysimage</span><br><span class="line">$ ls -l boot/</span><br><span class="line">total 58496</span><br><span class="line">-rw-r--r-- 1 root root   237698 May  7  2020 config-5.4.34-1-pve</span><br><span class="line">drwxr-xr-x 3 root root     4096 Jan  1  1970 efi</span><br><span class="line">drwxr-xr-x 6 root root     4096 Feb 18 12:59 grub</span><br><span class="line">-rw-r--r-- 1 root root 42573458 Aug 18  2021 initrd.img-5.4.34-1-pve</span><br><span class="line">-rw-r--r-- 1 root root   182704 Jun 26  2015 memtest86+.bin</span><br><span class="line">-rw-r--r-- 1 root root   184840 Jun 26  2015 memtest86+_multiboot.bin</span><br><span class="line">drwxr-xr-x 2 root root     4096 Sep  9  2020 pve</span><br><span class="line">-rw-r--r-- 1 root root  4795341 May  7  2020 System.map-5.4.34-1-pve</span><br><span class="line">-rw-r--r-- 1 root root 11901312 May  7  2020 vmlinuz-5.4.34-1-pve</span><br><span class="line">$ cp etc/lvm/backup/pve root/pve</span><br></pre></td></tr></table></figure><p>然后 chroot 进去</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mount -o bind /dev /mnt/sysimage/dev</span><br><span class="line">mount -o bind /proc /mnt/sysimage/proc</span><br><span class="line">mount -o bind /run /mnt/sysimage/run</span><br><span class="line">mount -o bind /sys /mnt/sysimage/sys</span><br><span class="line"># 上面如果在chroot之前不 mount 会导致一些lstat /dev /proc /sys 的命令报错无法读取这些目录 </span><br><span class="line">chroot /mnt/sysimage</span><br></pre></td></tr></table></figure><p>里面去折腾了下，好像是 vg 和 lv 的 uuid 变了，<code>vgcfgrestore --force -f /etc/lvm/backup/pve</code>重启还是不行，看了下 <code>/etc/lvm/backup/pve</code> 也没啥问题。</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>lvm 信息和文件都在，可能是 grub 损坏了。尝试备份 grub.cfg 后 <code>grub-mkconfig</code> 了下， diff 对比了下也没变啥 uuid 相关的地方，然后重启再进 CentOS Rescue 模式里，选择 1 自动挂载。然后尝试 chroot 进去 <code>grub-install</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 退出了 chroot 的话就再 chroot 进来</span><br><span class="line">chroot /mnt/sysimage</span><br><span class="line">cd /boot/grub</span><br><span class="line">cp grub.cfg grub.cfg.bak</span><br><span class="line">lvscan</span><br><span class="line">vgscan</span><br><span class="line">pvscan</span><br><span class="line"></span><br><span class="line"># df -h 看看，如果目录 /boot/efi 为空且 /boot/efi 没挂载，则执行下面命令</span><br><span class="line">mount /dev/sda2 /boot/efi</span><br><span class="line"></span><br><span class="line"># pve 是 grub-install 不是也没有 grub2-install</span><br><span class="line">grub-install --debug --recheck --root-directory=/ /dev/mapper/pve-root</span><br><span class="line"># 上面的 grub-install 没失败就可以了</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><p>然后就好了。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一次 proxmox 机器突然宕机，开机后进入 grub resuce 无法启动的处理过程&lt;/p&gt;</summary>
    
    
    
    
    <category term="grub" scheme="http://zhangguanzhang.github.io/tags/grub/"/>
    
    <category term="linux" scheme="http://zhangguanzhang.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>18.09.03 docker daemon layer broken 的一次不优雅处理</title>
    <link href="http://zhangguanzhang.github.io/2022/02/10/docker-daemon-layer-broken/"/>
    <id>http://zhangguanzhang.github.io/2022/02/10/docker-daemon-layer-broken/</id>
    <published>2022-02-10T14:28:30.000Z</published>
    <updated>2022-02-10T14:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录一次 18.09.03 docker daemon 存储的层损坏无法修复的过程，虽然不优雅，但是没找到更好的解决办法，暂时记录仅供参考。</p><span id="more"></span><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>机器重启后，部分 pod 无法启动。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">$ docker info</span><br><span class="line">Containers: 51</span><br><span class="line"> Running: 27</span><br><span class="line"> Paused: 0</span><br><span class="line"> Stopped: 24</span><br><span class="line">Images: 23</span><br><span class="line">Server Version: 18.09.3</span><br><span class="line">Storage Driver: overlay2</span><br><span class="line"> Backing Filesystem: xfs</span><br><span class="line"> Supports d_type: true</span><br><span class="line"> Native Overlay Diff: true</span><br><span class="line">Logging Driver: json-file</span><br><span class="line">Cgroup Driver: cgroupfs</span><br><span class="line">Plugins:</span><br><span class="line"> Volume: local</span><br><span class="line"> Network: bridge host macvlan null overlay</span><br><span class="line"> Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line">Swarm: inactive</span><br><span class="line">Runtimes: runc</span><br><span class="line">Default Runtime: runc</span><br><span class="line">Init Binary: docker-init</span><br><span class="line">containerd version: e6b3f5632f50dbc4e9cb6288d911bf4f5e95b18e</span><br><span class="line">runc version: 6635b4f0c6af3810594d2770f662f34ddc15b40d</span><br><span class="line">init version: fec3683</span><br><span class="line">Security Options:</span><br><span class="line"> seccomp</span><br><span class="line">  Profile: default</span><br><span class="line">Kernel Version: 3.10.0-693.el7.x86_64</span><br><span class="line">Operating System: CentOS Linux 7 (Core)</span><br><span class="line">OSType: linux</span><br><span class="line">Architecture: x86_64</span><br><span class="line">CPUs: 8</span><br><span class="line">Total Memory: 15.51GiB</span><br><span class="line">Name: hdzwvm000006238.novalocal</span><br><span class="line">ID: AUFF:32CM:54KK:FA2F:M3GS:EI77:2VSQ:HH3T:2LXM:7AFG:WXAQ:IKSV</span><br><span class="line">Docker Root Dir: /data/kube/docker</span><br><span class="line">Debug Mode (client): false</span><br><span class="line">Debug Mode (server): false</span><br><span class="line">Registry: https://index.docker.io/v1/</span><br><span class="line">Labels:</span><br></pre></td></tr></table></figure><h2 id="处理过程"><a href="#处理过程" class="headerlink" title="处理过程"></a>处理过程</h2><p>初步排查了下确认部分镜像损坏了，比如下面这个，<code>history --no-trunc</code> 看了下这个镜像的 rootfs 是 ubuntu ，结果报错下面：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm -ti --entrypoint bash xxx.cn/base/xxxxxx-amd64:v2</span><br><span class="line">standard_init_linux.go:207: exec user process caused &quot;no such file or directory&quot;</span><br></pre></td></tr></table></figure><p>之前也有类似情况，但是 rmi后 load就好了。这次是 rmi 掉后手动 load 也不行，对比了镜像离线文件的 md5sum 和包里的是一样的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ md5sum ./images/xxxxxx-amd64-v2#release_zzzzzzz </span><br><span class="line">cd1cf11ac90d6df59a31460cb1624933  ./images/xxxxxx-amd64-v2#release_zzzzzzz</span><br><span class="line"></span><br><span class="line">$ docker rmi xxx.cn/base/xxxxxx-amd64:v2</span><br><span class="line">Untagged: xxx.cn/base/xxxxxx-amd64:v2</span><br><span class="line">Deleted: sha256:fe7c32d1138c5215dba9fbfa4f675eff47f1a30605d9914fff34a5db00ad45f0</span><br><span class="line">$ docker load -i  xxxxxx-amd64-v2#release_zzzzzzz </span><br><span class="line">Loaded image: xxx.cn/base/xxxxxx-amd64:v2</span><br><span class="line">$ docker run --rm -ti --entrypoint bash xxx.cn/base/xxxxxx-amd64:v2</span><br><span class="line">standard_init_linux.go:207: exec user process caused &quot;no such file or directory&quot;</span><br></pre></td></tr></table></figure><p>然后排查到有安全软件 <code>sangfor</code>，并且机器重启过。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$ ps aux | grep san</span><br><span class="line">root      1183  0.0  0.0 113184  1492 ?        S    Feb09   0:03 /bin/bash /sangfor/edr/agent/bin/eps_services_ctrl</span><br><span class="line">root      5132  0.0  0.0 113436  1696 ?        S    Feb09   0:17 /bin/bash /sangfor/edr/agent/bin/abs_monitor</span><br><span class="line">root      5164  0.0  0.0  48092  3392 ?        S    Feb09   0:04 /sangfor/edr/agent/bin/abs_deployer</span><br><span class="line">root      5205  0.0  0.0  43036  1552 ?        Ss   Feb09   0:07 /sangfor/edr/agent/bin/edr_monitor</span><br><span class="line">root      5378  0.0  0.0 194948  6260 ?        Sl   Feb09   0:04 /sangfor/edr/agent/bin/sfupdatemgr -p edr_monitor</span><br><span class="line">root      5379  0.0  0.0  43360  3560 ?        S    Feb09   0:01 /sangfor/edr/agent/bin/ipc_proxy</span><br><span class="line">root      5380  0.6  0.1 708028 29892 ?        Sl   Feb09   6:56 /sangfor/edr/agent/bin/edr_agent</span><br><span class="line">root      5381  0.1  0.0  17060  1332 ?        S&lt;   Feb09   1:58 /sangfor/edr/agent/bin/cpulimit --limit=50 --exe=edr_agent</span><br><span class="line">root      5382  0.0  0.0 113568  1900 ?        S    Feb09   0:28 /bin/bash /sangfor/edr/agent/bin/asset_collection_cpulimit.sh</span><br><span class="line">root      5383  0.0  0.0 128944  5444 ?        Sl   Feb09   0:27 /sangfor/edr/agent/bin/edr_sec_plan</span><br><span class="line">root      5384  0.0  0.0 117656  8956 ?        S    Feb09   0:00 /sangfor/edr/agent/bin/lloader /sangfor/edr/agent/bin/../lmodules/isolate_area_tool.lua</span><br><span class="line">root      5385  0.0  0.0  68916  3928 ?        S    Feb09   0:01 /sangfor/edr/agent/bin/lloader /sangfor/edr/agent/bin/../lmodules/isolate_area_main.lua</span><br><span class="line">root     22594  0.0  0.0 112712   976 pts/2    S+   11:37   0:00 grep --color=auto san</span><br><span class="line">$ uptime -s</span><br><span class="line">2022-02-09 17:19:09</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line">$ tail -n 40 /var/spool/mail/root</span><br><span class="line">...</span><br><span class="line">edr pid 5205</span><br><span class="line">ls: cannot access /sangfor/edr/agent/bin/../packages/: No such file or directory</span><br><span class="line"></span><br><span class="line">$ ll /etc/cron.d</span><br><span class="line">total 12</span><br><span class="line">-rw-r--r--. 1 root root 128 Aug  3  2017 0hourly</span><br><span class="line">-rw-r--r--  1 root root  60 Dec 10  2020 edr_agent</span><br><span class="line">-rw-------. 1 root root 235 Apr  1  2020 sysstat</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line">$ cat edr_agent </span><br><span class="line">* * * * * root /sangfor/edr/agent/bin/eps_services_check.sh</span><br></pre></td></tr></table></figure><p>让客户卸载掉后还是不行，然后 save 了下发现了问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ docker save -o test.tar xxx.cn/base/xxxxxx-amd64:v2 </span><br><span class="line">Error response from daemon: open /data/kube/docker/overlay2/920a06a6d4eb64db0898234cd3a81b01115d6fcc2cfc50c5107e0205f7230318/diff/lib/x86_64-linux-gnu/ld-2.23.so: no such file or directory</span><br><span class="line">$ docker inspect xxx.cn/base/xxxxxx-amd64:v2 | grep 920a0</span><br><span class="line"> &quot;LowerDir&quot;: ...:/data/kube/docker/overlay2/920a06a6d4eb64db0898234cd3a81b01115d6fcc2cfc50c5107e0205f7230318/diff&quot;,</span><br><span class="line"></span><br><span class="line">$ ls -l /data/kube/docker/overlay2/920a06a6d4eb64db0898234cd3a81b01115d6fcc2cfc50c5107e0205f7230318/diff/lib/x86_64-linux-gnu/ | head</span><br><span class="line">total 10684</span><br><span class="line">lrwxrwxrwx 1 root root      10 Feb  6  2019 ld-linux-x86-64.so.2 -&gt; ld-2.23.so</span><br><span class="line">lrwxrwxrwx 1 root root      15 Feb  7  2016 libacl.so.1 -&gt; libacl.so.1.1.0</span><br><span class="line">-rw-r--r-- 1 root root   31232 Feb  7  2016 libacl.so.1.1.0</span><br><span class="line">-rw-r--r-- 1 root root   14992 Feb  6  2019 libanl-2.23.so</span><br><span class="line">lrwxrwxrwx 1 root root      14 Feb  6  2019 libanl.so.1 -&gt; libanl-2.23.so</span><br><span class="line">lrwxrwxrwx 1 root root      20 May 29  2019 libapparmor.so.1 -&gt; libapparmor.so.1.4.0</span><br><span class="line">-rw-r--r-- 1 root root   64144 May 29  2019 libapparmor.so.1.4.0</span><br><span class="line">lrwxrwxrwx 1 root root      16 Sep  9  2014 libattr.so.1 -&gt; libattr.so.1.1.0</span><br><span class="line">-rw-r--r-- 1 root root   18624 Sep  9  2014 libattr.so.1.1.0</span><br></pre></td></tr></table></figure><p>把那个镜像的离线文件拿到其他机器上 load 后看了下该层是有文件 <code>ld-2.23.so</code> 的:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ll b5f1b3d6665a476b9460532568499f2923c1621d710f6a1e20cf7f3e1a928e17/diff/lib/x86_64-linux-gnu/</span><br><span class="line">total 10844</span><br><span class="line">-rwxr-xr-x 1 root root  162632 Feb  6  2019 ld-2.23.so</span><br><span class="line">lrwxrwxrwx 1 root root      10 Feb  6  2019 ld-linux-x86-64.so.2 -&gt; ld-2.23.so</span><br></pre></td></tr></table></figure><p>最后本地试了下，发现如果 daemon 的层损坏了，rmi 后 load 是不会重新覆盖的，正常 load 一个新镜像 load 的时候是会有层显示的，类似下面：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ docker load -i netshoot#latest </span><br><span class="line">b2d5eeeaba3a: Loading layer [==================================================&gt;]   5.88MB/5.88MB</span><br><span class="line">681ff9ab4914: Loading layer [==================================================&gt;]  301.4MB/301.4MB</span><br><span class="line">0e91662a9cb3: Loading layer [==================================================&gt;]  8.683MB/8.683MB</span><br><span class="line">fdcdfe126cc0: Loading layer [==================================================&gt;]  13.63MB/13.63MB</span><br><span class="line">270c883ade5e: Loading layer [==================================================&gt;]  45.31MB/45.31MB</span><br><span class="line">06e19b7687c5: Loading layer [==================================================&gt;]  14.54MB/14.54MB</span><br><span class="line">def3433d213c: Loading layer [==================================================&gt;]  4.566MB/4.566MB</span><br><span class="line">5b6adb9801a8: Loading layer [==================================================&gt;]  869.9kB/869.9kB</span><br><span class="line">765e2d110fbc: Loading layer [==================================================&gt;]  1.831MB/1.831MB</span><br><span class="line">eead121d6964: Loading layer [==================================================&gt;]  7.168kB/7.168kB</span><br><span class="line">400127227d7a: Loading layer [==================================================&gt;]  3.072kB/3.072kB</span><br><span class="line">2b4f749a4a39: Loading layer [==================================================&gt;]  6.571MB/6.571MB</span><br><span class="line">Loaded image: netshoot:latest</span><br><span class="line">$ docker load -i netshoot#latest </span><br><span class="line">Loaded image: netshoot:latest</span><br></pre></td></tr></table></figure><p>只有镜像存在的情况下只显示一个 <code>Loaded image</code>，回看之前我们 rmi 后 load 就是没有层显示。看了下代码暂时没看出怎么判断是否已存在的，然后把 overlay2 目录删了暂时解决的。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://blog.k8s.li/Exploring-container-image.html">深入浅出容器镜像的一生</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录一次 18.09.03 docker daemon 存储的层损坏无法修复的过程，虽然不优雅，但是没找到更好的解决办法，暂时记录仅供参考。&lt;/p&gt;</summary>
    
    
    
    
    <category term="docker" scheme="http://zhangguanzhang.github.io/tags/docker/"/>
    
    <category term="linux" scheme="http://zhangguanzhang.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>利用 docker buildx 静态编译 nginx</title>
    <link href="http://zhangguanzhang.github.io/2022/01/26/nginx-static-build/"/>
    <id>http://zhangguanzhang.github.io/2022/01/26/nginx-static-build/</id>
    <published>2022-01-26T14:28:30.000Z</published>
    <updated>2022-01-26T14:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>内部有需求需要静态编译 nginx，尝试了下，搞出来了。先是按照官方 nginx Dockerfile 的逻辑走不通，后面下载 nginx 官方源码编译才行。</p><h3 id="buildx-使用"><a href="#buildx-使用" class="headerlink" title="buildx 使用"></a>buildx 使用</h3><p>见文章 <a href="https://github.com/zhangguanzhang/docker-need-to-know/blob/master/2.docker-image/dockerfile/buildx.md">buildx 使用</a></p><h3 id="nginx-Dockerfile"><a href="#nginx-Dockerfile" class="headerlink" title="nginx Dockerfile"></a>nginx Dockerfile</h3><p>先说下官方的失败尝试。先 clone 项目：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/nginxinc/docker-nginx.git</span><br><span class="line"><span class="built_in">cd</span> docker-nginx</span><br></pre></td></tr></table></figure><p>分为 <code>stable</code> 和 <code>mainline</code>。大概研究了下，发现 <code>case &quot;$apkArch&quot; in x86_64|aarch64)</code> 的情况是利用包管理直接安装的，其他的架构才是源码编译安装。改了下这个 case ，先用 arm64 的试下走源码编译。然后看下逻辑是下载源码进去 <code>make all</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -f -O https://hg.nginx.org/pkg-oss/archive/$&#123;NGINX_VERSION&#125;-$&#123;PKG_RELEASE&#125;.tar.gz</span><br><span class="line">tar xzvf $&#123;NGINX_VERSION&#125;-$&#123;PKG_RELEASE&#125;.tar.gz</span><br><span class="line">&amp;&amp; cd pkg-oss-$&#123;NGINX_VERSION&#125;-$&#123;PKG_RELEASE&#125; \</span><br><span class="line">&amp;&amp; cd alpine \</span><br><span class="line">&amp;&amp; make all </span><br></pre></td></tr></table></figure><p>而源码里 <code>Makefile</code> 的前面内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ifeq ($(MODULE_TARGET), plus)</span><br><span class="line">APKBUILD_TEMPLATE=APKBUILD-plus-module.in</span><br><span class="line">MODULE_SUFFIX=-plus</span><br><span class="line">MODULE_SUMMARY_PREFIX=NGINX Plus</span><br><span class="line">TARGET_VERSION=$(PLUS_VERSION)</span><br><span class="line">MODULE_PACKAGE_PREFIX=nginx-plus-module</span><br><span class="line">else</span><br><span class="line">APKBUILD_TEMPLATE=APKBUILD-module.in</span><br><span class="line">MODULE_SUMMARY_PREFIX=nginx</span><br><span class="line">TARGET_VERSION=$(BASE_VERSION)</span><br><span class="line">MODULE_PACKAGE_PREFIX=nginx-module</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>因为不是构建 <code>nginx-plus</code> 所以我们看 <code>cat APKBUILD-module.in</code> 里找到了下面的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">build() &#123;</span><br><span class="line">cd &quot;$builddir&quot;</span><br><span class="line"></span><br><span class="line">_nproc=`getconf _NPROCESSORS_ONLN`</span><br><span class="line">if [ $_nproc -gt 1 ]; then</span><br><span class="line">_make_opts=&quot;-j$_nproc&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">%%MODULE_PREBUILD%%</span><br><span class="line"></span><br><span class="line">cd &quot;$builddir&quot;</span><br><span class="line"></span><br><span class="line">CFLAGS= %%MODULE_ENV%% ./configure %%BASE_CONFIGURE_ARGS%% %%MODULE_CONFIGURE_ARGS%% --with-cc-opt=&quot;$CFLAGS %%MODULE_CC_OPT_DEBUG%%&quot; --with-ld-opt=&quot;$LDFLAGS %%MODULE_LD_OPT_DEBUG%%&quot; --with-debug</span><br><span class="line">make $_make_opts modules</span><br><span class="line">for so in `find objs/ -maxdepth 1 -type f -name &quot;*.so&quot;`; do \</span><br><span class="line">debugso=`echo $&#123;so&#125; | sed -e &#x27;s|\.so$|-debug.so|&#x27;` ; \</span><br><span class="line">mv $&#123;so&#125; $&#123;debugso&#125; ; \</span><br><span class="line">        done</span><br><span class="line">CFLAGS= %%MODULE_ENV%% ./configure %%BASE_CONFIGURE_ARGS%% %%MODULE_CONFIGURE_ARGS%% --with-cc-opt=&quot;$CFLAGS %%MODULE_CC_OPT%%&quot; --with-ld-opt=&quot;$LDFLAGS %%MODULE_LD_OPT%%&quot;</span><br><span class="line">make $_make_opts modules</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>CFLAGS</code> 和 <code>LDFLAGS</code> 是支持环境变量传入的，所以改下 Dockerfile 加入下面的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ARG CFLAGS</span><br><span class="line">ARG LDFLAGS</span><br></pre></td></tr></table></figure><p>然后开始构建：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker buildx build -t zhangguanzhang/nginx:arm64-static . \</span><br><span class="line">    --platform linux/arm64 \</span><br><span class="line">    --build-arg=&quot;CFLAGS=&#x27;-static -s&#x27;&quot; --build-arg=LDFLAGS=-static</span><br></pre></td></tr></table></figure><p>然后失败，报错 <code>./configure: error: the invalid value in --with-ld-opt=&quot;-static&quot;</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#6 481.1 &gt;&gt;&gt; nginx: Unpacking /tmp/tmp.OciAKf/pkg-oss-1.21.5-1/alpine/abuild-base/nginx-1.21.5.tar.gz...</span><br><span class="line">#6 482.9 checking for OS</span><br><span class="line">#6 482.9  + Linux 5.4.0-91-generic aarch64</span><br><span class="line">#6 482.9 checking for C compiler ... found</span><br><span class="line">#6 483.6  + using GNU C compiler</span><br><span class="line">#6 483.7  + gcc version: 10.3.1 20211027 (Alpine 10.3.1_git20211027) </span><br><span class="line">#6 483.7 checking for gcc -pipe switch ... found</span><br><span class="line">#6 484.3 checking for --with-ld-opt=&quot;-static&quot; ... not found</span><br><span class="line">#6 484.3 ./configure: error: the invalid value in --with-ld-opt=&quot;-static&quot;</span><br></pre></td></tr></table></figure><p>然后在 Dockerfile 里 apk add 加了 <code>glibc-static</code> 还是一样报错。然后尝试下官方的</p><h3 id="自己编译"><a href="#自己编译" class="headerlink" title="自己编译"></a>自己编译</h3><h4 id="手动步骤"><a href="#手动步骤" class="headerlink" title="手动步骤"></a>手动步骤</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -ti --name t1 test alpine</span><br></pre></td></tr></table></figure><p>前置依赖</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">if [ -f /etc/apk/repositories ];then sed -i &#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27; /etc/apk/repositories; fi &amp;&amp; \</span><br><span class="line">    if [ -f /etc/apt/sources.list ];then sed -ri &#x27;s/(deb|security).debian.org/mirrors.aliyun.com/g&#x27; /etc/apt/sources.list; fi &amp;&amp; \</span><br><span class="line">    if [ ! -e /etc/nsswitch.conf ];then echo &#x27;hosts: files dns myhostname&#x27; &gt; /etc/nsswitch.conf; fi</span><br><span class="line"></span><br><span class="line">apk add --no-cache --virtual .build-deps \</span><br><span class="line">                gcc \</span><br><span class="line">                libc-dev \</span><br><span class="line">                make \</span><br><span class="line">                openssl-dev \</span><br><span class="line">                pcre2-dev \</span><br><span class="line">                zlib-dev \</span><br><span class="line">              openssl-libs-static zlib-static  \</span><br><span class="line">                linux-headers \</span><br><span class="line">                libxslt-dev \</span><br><span class="line">                gd-dev \</span><br><span class="line">                geoip-dev \</span><br><span class="line">                perl-dev \</span><br><span class="line">                libedit-dev \</span><br><span class="line">                bash \</span><br><span class="line">                alpine-sdk \</span><br><span class="line">                findutils</span><br><span class="line">bash</span><br></pre></td></tr></table></figure><p>下载源码包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://nginx.org/download/nginx-1.21.6.tar.gz</span><br><span class="line">tar zxf nginx-1.21.6.tar.gz</span><br><span class="line">cd nginx-1.21.6</span><br></pre></td></tr></table></figure><p>找下官方的编译参数，下面是我 arm64 上：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm --entrypoint nginx nginx:alpine-perl -V</span><br><span class="line">nginx version: nginx/1.21.6</span><br><span class="line">built by gcc 10.3.1 20211027 (Alpine 10.3.1_git20211027) </span><br><span class="line">built with OpenSSL 1.1.1l  24 Aug 2021</span><br><span class="line">TLS SNI support enabled</span><br><span class="line">configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --with-perl_modules_path=/usr/lib/perl5/vendor_perl --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=&#x27;-Os -fomit-frame-pointer -g&#x27; --with-ld-opt=-Wl,--as-needed,-O1,--sort-common</span><br><span class="line">$ docker run --rm --entrypoint nginx nginx:alpine-perl -V |&amp; grep -Po -- &quot;--[a-z_-]+(=(&#x27;[^&#x27;]+&#x27;|\S+))?&quot;</span><br><span class="line">--prefix=/etc/nginx</span><br><span class="line">--sbin-path=/usr/sbin/nginx</span><br><span class="line">--modules-path=/usr/lib/nginx/modules</span><br><span class="line">--conf-path=/etc/nginx/nginx.conf</span><br><span class="line">--error-log-path=/var/log/nginx/error.log</span><br><span class="line">--http-log-path=/var/log/nginx/access.log</span><br><span class="line">--pid-path=/var/run/nginx.pid</span><br><span class="line">--lock-path=/var/run/nginx.lock</span><br><span class="line">--http-client-body-temp-path=/var/cache/nginx/client_temp</span><br><span class="line">--http-proxy-temp-path=/var/cache/nginx/proxy_temp</span><br><span class="line">--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp</span><br><span class="line">--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp</span><br><span class="line">--http-scgi-temp-path=/var/cache/nginx/scgi_temp</span><br><span class="line">--with-perl_modules_path=/usr/lib/perl5/vendor_perl</span><br><span class="line">--user=nginx</span><br><span class="line">--group=nginx</span><br><span class="line">--with-compat</span><br><span class="line">--with-file-aio</span><br><span class="line">--with-threads</span><br><span class="line">--with-http_addition_module</span><br><span class="line">--with-http_auth_request_module</span><br><span class="line">--with-http_dav_module</span><br><span class="line">--with-http_flv_module</span><br><span class="line">--with-http_gunzip_module</span><br><span class="line">--with-http_gzip_static_module</span><br><span class="line">--with-http_mp</span><br><span class="line">--with-http_random_index_module</span><br><span class="line">--with-http_realip_module</span><br><span class="line">--with-http_secure_link_module</span><br><span class="line">--with-http_slice_module</span><br><span class="line">--with-http_ssl_module</span><br><span class="line">--with-http_stub_status_module</span><br><span class="line">--with-http_sub_module</span><br><span class="line">--with-http_v</span><br><span class="line">--with-mail</span><br><span class="line">--with-mail_ssl_module</span><br><span class="line">--with-stream</span><br><span class="line">--with-stream_realip_module</span><br><span class="line">--with-stream_ssl_module</span><br><span class="line">--with-stream_ssl_preread_module</span><br><span class="line">--with-cc-opt=&#x27;-Os -fomit-frame-pointer -g&#x27;</span><br><span class="line">--with-ld-opt=-Wl,--as-needed,-O1,--sort-common</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>with-http_mp</code> 和 <code>with-http_v</code> 似乎对应 <code>--with-http_mp4_module</code> 和 <code>--with-http_v2_module</code>，更多编译参数参考官方文档 <a href="http://nginx.org/en/docs/configure.html">nginx-configure</a><br>改下 <code>--with-cc-opt</code> 和 <code>--with-ld-opt</code> 后编译</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">./configure \</span><br><span class="line">  --prefix=/etc/nginx \</span><br><span class="line">  --sbin-path=/usr/sbin/nginx \</span><br><span class="line">  --modules-path=/usr/lib/nginx/modules \</span><br><span class="line">  --conf-path=/etc/nginx/nginx.conf \</span><br><span class="line">  --error-log-path=/var/<span class="built_in">log</span>/nginx/error.log \</span><br><span class="line">  --http-log-path=/var/<span class="built_in">log</span>/nginx/access.log \</span><br><span class="line">  --pid-path=/var/run/nginx.pid \</span><br><span class="line">  --lock-path=/var/run/nginx.lock \</span><br><span class="line">  --http-client-body-temp-path=/var/cache/nginx/client_temp \</span><br><span class="line">  --http-proxy-temp-path=/var/cache/nginx/proxy_temp \</span><br><span class="line">  --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \</span><br><span class="line">  --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \</span><br><span class="line">  --http-scgi-temp-path=/var/cache/nginx/scgi_temp \</span><br><span class="line">  --with-perl_modules_path=/usr/lib/perl5/vendor_perl \</span><br><span class="line">  --user=nginx \</span><br><span class="line">  --group=nginx \</span><br><span class="line">  --with-compat \</span><br><span class="line">  --with-file-aio \</span><br><span class="line">  --with-threads \</span><br><span class="line">  --with-http_addition_module \</span><br><span class="line">  --with-http_auth_request_module \</span><br><span class="line">  --with-http_dav_module \</span><br><span class="line">  --with-http_flv_module \</span><br><span class="line">  --with-http_gunzip_module \</span><br><span class="line">  --with-http_gzip_static_module \</span><br><span class="line">  --with-http_mp4_module \</span><br><span class="line">  --with-http_random_index_module \</span><br><span class="line">  --with-http_realip_module \</span><br><span class="line">  --with-http_secure_link_module \</span><br><span class="line">  --with-http_slice_module \</span><br><span class="line">  --with-http_ssl_module \</span><br><span class="line">  --with-http_stub_status_module \</span><br><span class="line">  --with-http_sub_module \</span><br><span class="line">  --with-http_v2_module \</span><br><span class="line">  --with-mail \</span><br><span class="line">  --with-mail_ssl_module \</span><br><span class="line">  --with-stream \</span><br><span class="line">  --with-stream_realip_module \</span><br><span class="line">  --with-stream_ssl_module \</span><br><span class="line">  --with-stream_ssl_preread_module \</span><br><span class="line">  --with-cc-opt=<span class="string">&#x27;-static -s&#x27;</span> \</span><br><span class="line">  --with-ld-opt=-static</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line"></span><br><span class="line">make install</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Dockerfile-构建"><a href="#Dockerfile-构建" class="headerlink" title="Dockerfile 构建"></a>Dockerfile 构建</h4><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine AS build</span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> NGINX_VERSION=<span class="number">1.21</span>.<span class="number">6</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /opt</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="keyword">if</span> [ -f /etc/apk/repositories ];<span class="keyword">then</span> sed -i <span class="string">&#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27;</span> /etc/apk/repositories; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="keyword">if</span> [ -f /etc/apt/sources.list ];<span class="keyword">then</span> sed -ri <span class="string">&#x27;s/(deb|security).debian.org/mirrors.aliyun.com/g&#x27;</span> /etc/apt/sources.list; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="keyword">if</span> [ ! -e /etc/nsswitch.conf ];<span class="keyword">then</span> <span class="built_in">echo</span> <span class="string">&#x27;hosts: files dns myhostname&#x27;</span> &gt; /etc/nsswitch.conf; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk add --no-cache --virtual .build-deps \</span></span><br><span class="line"><span class="bash">                gcc \</span></span><br><span class="line"><span class="bash">                libc-dev \</span></span><br><span class="line"><span class="bash">                make \</span></span><br><span class="line"><span class="bash">                openssl-dev \</span></span><br><span class="line"><span class="bash">                pcre2-dev \</span></span><br><span class="line"><span class="bash">                zlib-dev \</span></span><br><span class="line"><span class="bash">              openssl-libs-static zlib-static  \</span></span><br><span class="line"><span class="bash">                linux-headers \</span></span><br><span class="line"><span class="bash">                libxslt-dev \</span></span><br><span class="line"><span class="bash">                gd-dev \</span></span><br><span class="line"><span class="bash">                geoip-dev \</span></span><br><span class="line"><span class="bash">                perl-dev \</span></span><br><span class="line"><span class="bash">                libedit-dev \</span></span><br><span class="line"><span class="bash">                bash \</span></span><br><span class="line"><span class="bash">                alpine-sdk \</span></span><br><span class="line"><span class="bash">                findutils &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget http://nginx.org/download/nginx-<span class="variable">$&#123;NGINX_VERSION&#125;</span>.tar.gz &amp;&amp; tar zxf nginx-<span class="variable">$&#123;NGINX_VERSION&#125;</span>.tar.gz</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> nginx-<span class="variable">$&#123;NGINX_VERSION&#125;</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ./configure \</span></span><br><span class="line"><span class="bash">    --prefix=/etc/nginx \</span></span><br><span class="line"><span class="bash">    --sbin-path=/usr/sbin/nginx \</span></span><br><span class="line"><span class="bash">    --modules-path=/usr/lib/nginx/modules \</span></span><br><span class="line"><span class="bash">    --conf-path=/etc/nginx/nginx.conf \</span></span><br><span class="line"><span class="bash">    --error-log-path=/var/<span class="built_in">log</span>/nginx/error.log \</span></span><br><span class="line"><span class="bash">    --http-log-path=/var/<span class="built_in">log</span>/nginx/access.log \</span></span><br><span class="line"><span class="bash">    --pid-path=/var/run/nginx.pid \</span></span><br><span class="line"><span class="bash">    --lock-path=/var/run/nginx.lock \</span></span><br><span class="line"><span class="bash">    --http-client-body-temp-path=/var/cache/nginx/client_temp \</span></span><br><span class="line"><span class="bash">    --http-proxy-temp-path=/var/cache/nginx/proxy_temp \</span></span><br><span class="line"><span class="bash">    --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \</span></span><br><span class="line"><span class="bash">    --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \</span></span><br><span class="line"><span class="bash">    --http-scgi-temp-path=/var/cache/nginx/scgi_temp \</span></span><br><span class="line"><span class="bash">    --with-perl_modules_path=/usr/lib/perl5/vendor_perl \</span></span><br><span class="line"><span class="bash">    --user=nginx \</span></span><br><span class="line"><span class="bash">    --group=nginx \</span></span><br><span class="line"><span class="bash">    --with-compat \</span></span><br><span class="line"><span class="bash">    --with-file-aio \</span></span><br><span class="line"><span class="bash">    --with-threads \</span></span><br><span class="line"><span class="bash">    --with-http_addition_module \</span></span><br><span class="line"><span class="bash">    --with-http_auth_request_module \</span></span><br><span class="line"><span class="bash">    --with-http_dav_module \</span></span><br><span class="line"><span class="bash">    --with-http_flv_module \</span></span><br><span class="line"><span class="bash">    --with-http_gunzip_module \</span></span><br><span class="line"><span class="bash">    --with-http_gzip_static_module \</span></span><br><span class="line"><span class="bash">    --with-http_mp4_module \</span></span><br><span class="line"><span class="bash">    --with-http_random_index_module \</span></span><br><span class="line"><span class="bash">    --with-http_realip_module \</span></span><br><span class="line"><span class="bash">    --with-http_secure_link_module \</span></span><br><span class="line"><span class="bash">    --with-http_slice_module \</span></span><br><span class="line"><span class="bash">    --with-http_ssl_module \</span></span><br><span class="line"><span class="bash">    --with-http_stub_status_module \</span></span><br><span class="line"><span class="bash">    --with-http_sub_module \</span></span><br><span class="line"><span class="bash">    --with-http_v2_module \</span></span><br><span class="line"><span class="bash">    --with-mail \</span></span><br><span class="line"><span class="bash">    --with-mail_ssl_module \</span></span><br><span class="line"><span class="bash">    --with-stream \</span></span><br><span class="line"><span class="bash">    --with-stream_realip_module \</span></span><br><span class="line"><span class="bash">    --with-stream_ssl_module \</span></span><br><span class="line"><span class="bash">    --with-stream_ssl_preread_module \</span></span><br><span class="line"><span class="bash">    --with-cc-opt=<span class="string">&#x27;-static -s&#x27;</span> \</span></span><br><span class="line"><span class="bash">    --with-ld-opt=-static &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make install &amp;&amp; \</span></span><br><span class="line"><span class="bash">    cp `<span class="built_in">which</span> nginx` /nginx-$(cat /etc/apk/arch)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> scratch AS bin</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=build /nginx-* /</span></span><br></pre></td></tr></table></figure><p>构建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker buildx build  . --platform linux/amd64,linux/arm64 \</span><br><span class="line">    --target bin --output . \</span><br><span class="line">    --build-arg=NGINX_VERSION=1.21.6</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># ll                          </span><br><span class="line">total 4                                    </span><br><span class="line">drwxr-xr-x 4 root root   62 Jan 26 16:21 ./             </span><br><span class="line">drwxr-xr-x 6 root root   98 Jan 26 15:31 ../   </span><br><span class="line">-rw-r--r-- 1 root root 2718 Jan 26 16:05 Dockerfile </span><br><span class="line">drwxr-xr-x 2 root root   26 Jan 26 16:21 linux_amd64/                                          </span><br><span class="line">drwxr-xr-x 2 root root   27 Jan 26 16:21 linux_arm64/ </span><br><span class="line"># ll linux_a*</span><br><span class="line">linux_amd64:</span><br><span class="line">total 20424</span><br><span class="line">drwxr-xr-x 2 root root       26 Jan 26 16:21 ./</span><br><span class="line">drwxr-xr-x 4 root root       62 Jan 26 16:21 ../</span><br><span class="line">-rwxr-xr-x 1 root root 20910696 Jan 26 16:12 nginx-x86_64*</span><br><span class="line"></span><br><span class="line">linux_arm64:</span><br><span class="line">total 20444</span><br><span class="line">drwxr-xr-x 2 root root       27 Jan 26 16:21 ./</span><br><span class="line">drwxr-xr-x 4 root root       62 Jan 26 16:21 ../</span><br><span class="line">-rwxr-xr-x 1 root root 20932656 Jan 26 16:21 nginx-aarch64*</span><br><span class="line"># ./linux_amd64/nginx-x86_64 -V</span><br><span class="line">nginx version: nginx/1.21.6</span><br><span class="line">built by gcc 10.3.1 20211027 (Alpine 10.3.1_git20211027) </span><br><span class="line">built with OpenSSL 1.1.1l  24 Aug 2021</span><br><span class="line">TLS SNI support enabled</span><br><span class="line">configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --with-perl_modules_path=/usr/lib/perl5/vendor_perl --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=&#x27;-static -s&#x27; --with-ld-opt=-static</span><br><span class="line"># file ./linux_amd64/nginx-x86_64 </span><br><span class="line">./linux_amd64/nginx-x86_64: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, with debug_info, not stripped</span><br><span class="line"># file ./linux_arm64/nginx-aarch64 </span><br><span class="line">./linux_arm64/nginx-aarch64: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), statically linked, with debug_info, not stripped</span><br></pre></td></tr></table></figure><p>符号链接可以 <code>strip -s $(which nginx)</code> 去掉减少大小。</p><h4 id="对接到真实场景"><a href="#对接到真实场景" class="headerlink" title="对接到真实场景"></a>对接到真实场景</h4><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nginx:alpine AS conf</span><br><span class="line"><span class="keyword">FROM</span> alpine AS build</span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> NGINX_VERSION=<span class="number">1.21</span>.<span class="number">6</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /opt</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="keyword">if</span> [ -f /etc/apk/repositories ];<span class="keyword">then</span> sed -i <span class="string">&#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27;</span> /etc/apk/repositories; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="keyword">if</span> [ -f /etc/apt/sources.list ];<span class="keyword">then</span> sed -ri <span class="string">&#x27;s/(deb|security).debian.org/mirrors.aliyun.com/g&#x27;</span> /etc/apt/sources.list; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="keyword">if</span> [ ! -e /etc/nsswitch.conf ];<span class="keyword">then</span> <span class="built_in">echo</span> <span class="string">&#x27;hosts: files dns myhostname&#x27;</span> &gt; /etc/nsswitch.conf; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk add --no-cache --virtual .build-deps \</span></span><br><span class="line"><span class="bash">                gcc \</span></span><br><span class="line"><span class="bash">                libc-dev \</span></span><br><span class="line"><span class="bash">                make \</span></span><br><span class="line"><span class="bash">                openssl-dev \</span></span><br><span class="line"><span class="bash">                pcre2-dev \</span></span><br><span class="line"><span class="bash">                zlib-dev \</span></span><br><span class="line"><span class="bash">              openssl-libs-static zlib-static  \</span></span><br><span class="line"><span class="bash">                linux-headers \</span></span><br><span class="line"><span class="bash">                libxslt-dev \</span></span><br><span class="line"><span class="bash">                gd-dev \</span></span><br><span class="line"><span class="bash">                geoip-dev \</span></span><br><span class="line"><span class="bash">                perl-dev \</span></span><br><span class="line"><span class="bash">                libedit-dev \</span></span><br><span class="line"><span class="bash">                bash \</span></span><br><span class="line"><span class="bash">                alpine-sdk \</span></span><br><span class="line"><span class="bash">                findutils &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget http://nginx.org/download/nginx-<span class="variable">$&#123;NGINX_VERSION&#125;</span>.tar.gz &amp;&amp; tar zxf nginx-<span class="variable">$&#123;NGINX_VERSION&#125;</span>.tar.gz</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> nginx-<span class="variable">$&#123;NGINX_VERSION&#125;</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ./configure \</span></span><br><span class="line"><span class="bash">    --prefix=/etc/nginx \</span></span><br><span class="line"><span class="bash">    --sbin-path=/usr/sbin/nginx \</span></span><br><span class="line"><span class="bash">    --modules-path=/usr/lib/nginx/modules \</span></span><br><span class="line"><span class="bash">    --conf-path=/etc/nginx/nginx.conf \</span></span><br><span class="line"><span class="bash">    --error-log-path=/var/<span class="built_in">log</span>/nginx/error.log \</span></span><br><span class="line"><span class="bash">    --http-log-path=/var/<span class="built_in">log</span>/nginx/access.log \</span></span><br><span class="line"><span class="bash">    --pid-path=/var/run/nginx.pid \</span></span><br><span class="line"><span class="bash">    --lock-path=/var/run/nginx.lock \</span></span><br><span class="line"><span class="bash">    --http-client-body-temp-path=/var/cache/nginx/client_temp \</span></span><br><span class="line"><span class="bash">    --http-proxy-temp-path=/var/cache/nginx/proxy_temp \</span></span><br><span class="line"><span class="bash">    --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \</span></span><br><span class="line"><span class="bash">    --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \</span></span><br><span class="line"><span class="bash">    --http-scgi-temp-path=/var/cache/nginx/scgi_temp \</span></span><br><span class="line"><span class="bash">    --with-perl_modules_path=/usr/lib/perl5/vendor_perl \</span></span><br><span class="line"><span class="bash">    --user=nginx \</span></span><br><span class="line"><span class="bash">    --group=nginx \</span></span><br><span class="line"><span class="bash">    --with-compat \</span></span><br><span class="line"><span class="bash">    --with-file-aio \</span></span><br><span class="line"><span class="bash">    --with-threads \</span></span><br><span class="line"><span class="bash">    --with-http_addition_module \</span></span><br><span class="line"><span class="bash">    --with-http_auth_request_module \</span></span><br><span class="line"><span class="bash">    --with-http_dav_module \</span></span><br><span class="line"><span class="bash">    --with-http_flv_module \</span></span><br><span class="line"><span class="bash">    --with-http_gunzip_module \</span></span><br><span class="line"><span class="bash">    --with-http_gzip_static_module \</span></span><br><span class="line"><span class="bash">    --with-http_mp4_module \</span></span><br><span class="line"><span class="bash">    --with-http_random_index_module \</span></span><br><span class="line"><span class="bash">    --with-http_realip_module \</span></span><br><span class="line"><span class="bash">    --with-http_secure_link_module \</span></span><br><span class="line"><span class="bash">    --with-http_slice_module \</span></span><br><span class="line"><span class="bash">    --with-http_ssl_module \</span></span><br><span class="line"><span class="bash">    --with-http_stub_status_module \</span></span><br><span class="line"><span class="bash">    --with-http_sub_module \</span></span><br><span class="line"><span class="bash">    --with-http_v2_module \</span></span><br><span class="line"><span class="bash">    --with-mail \</span></span><br><span class="line"><span class="bash">    --with-mail_ssl_module \</span></span><br><span class="line"><span class="bash">    --with-stream \</span></span><br><span class="line"><span class="bash">    --with-stream_realip_module \</span></span><br><span class="line"><span class="bash">    --with-stream_ssl_module \</span></span><br><span class="line"><span class="bash">    --with-stream_ssl_preread_module \</span></span><br><span class="line"><span class="bash">    --with-cc-opt=<span class="string">&#x27;-static -s&#x27;</span> \</span></span><br><span class="line"><span class="bash">    --with-ld-opt=-static</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> nginx-<span class="variable">$&#123;NGINX_VERSION&#125;</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mkdir /install_root &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make DESTDIR=/install_root install &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rm -f /install_root/etc/nginx/*.default &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rmdir /install_root/var/run ; <span class="literal">true</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mkdir -p /install_root/var/cache/nginx/ \</span></span><br><span class="line"><span class="bash">      /install_root/usr/lib/nginx/modules \</span></span><br><span class="line"><span class="bash">      /install_root/etc/nginx/conf.d \</span></span><br><span class="line"><span class="bash">      /install_root/usr/share/nginx &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mv /install_root/etc/nginx/html /install_root/usr/share/nginx/ &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ln -sf /dev/stdout /install_root/var/<span class="built_in">log</span>/nginx/access.log &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ln -sf /dev/stderr /install_root/var/<span class="built_in">log</span>/nginx/error.log </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=conf /etc/nginx/nginx.conf /install_root/etc/nginx/nginx.conf</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=conf /etc/nginx/conf.d /install_root/etc/nginx/conf.d</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash">  find /install_root</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=build /install_root /</span></span><br><span class="line"><span class="comment"># alpine create nginx user/group </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> addgroup -g 101 -S nginx &amp;&amp; \</span></span><br><span class="line"><span class="bash">    adduser -S -D -H -u 101 -h /var/cache/nginx -s /sbin/nologin -G nginx -g nginx nginx &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="keyword">if</span> [ ! -e /etc/nsswitch.conf ];<span class="keyword">then</span> <span class="built_in">echo</span> <span class="string">&#x27;hosts: files dns myhostname&#x27;</span> &gt;&gt; /etc/nsswitch.conf; <span class="keyword">fi</span></span></span><br><span class="line"><span class="comment"># debian create nginx user/group </span></span><br><span class="line"><span class="comment"># RUN addgroup --system --gid 101 nginx &amp;&amp; \</span></span><br><span class="line"><span class="comment">#     adduser --system --disabled-login --ingroup nginx --no-create-home --home /nonexistent --gecos &quot;nginx user&quot; --shell /bin/false --uid 101 nginx  &amp;&amp; \</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注意 <code>worker_processes  auto;</code> 在高核心 cpu 上会非常吃配置和浪费配置，特别是 arm64 的国产服务器上，需要改成固定的数字。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.v2ex.com/t/757913">https://www.v2ex.com/t/757913</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;由来&quot;&gt;&lt;a href=&quot;#由来&quot; class=&quot;headerlink&quot; title=&quot;由来&quot;&gt;&lt;/a&gt;由来&lt;/h2&gt;&lt;p&gt;内部有需求需要静态编译 nginx，尝试了下，搞出来了。先是按照官方 nginx Dockerfile 的逻辑走不通，后面下载 nginx </summary>
      
    
    
    
    
    <category term="docker" scheme="http://zhangguanzhang.github.io/tags/docker/"/>
    
    <category term="nginx" scheme="http://zhangguanzhang.github.io/tags/nginx/"/>
    
    <category term="linux" scheme="http://zhangguanzhang.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>EmuELEC 笔记</title>
    <link href="http://zhangguanzhang.github.io/2022/01/22/EmuELEC/"/>
    <id>http://zhangguanzhang.github.io/2022/01/22/EmuELEC/</id>
    <published>2022-01-22T14:28:30.000Z</published>
    <updated>2022-01-22T14:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="EmuELEC-笔记"><a href="#EmuELEC-笔记" class="headerlink" title="EmuELEC 笔记"></a>EmuELEC 笔记</h1><p>后续关于 EmuELEC 的笔记和知识点都会在这里更新，假定看到这篇文章的人都具备一些 Linux 基础，命令，path，分区，挂载之类的知识。</p><h2 id="EmuELEC-介绍"><a href="#EmuELEC-介绍" class="headerlink" title="EmuELEC 介绍"></a>EmuELEC 介绍</h2><p>EmuELEC 是专为 Amlogic（晶晨）S905/S912 方案的盒子开发的游戏系统，它基于 CoreELEC 系统，在 CoreELEC 的基础上移植了 RetroArch 和众多的独立模拟器。EmuELEC 前身为 Sx05RE。Sx05RE 整合了 Lakka、KODI、EmulationStation，常被人简称为三合一。它实际上也是一个 Linux 系统，最新版本开始只支持 arm64 架构了。</p><p>通常我们使用便宜的电视盒子（基本9成都是晶晨的 cpu）来刷 EmuELEC 系统，然后配合手柄（xbox协议，ps、psp和30块钱左右的无线手柄）能玩很多平台的游戏：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">3do    atari2600 atarilynx    coleco  downloadsgameandwatch  gbah     genh      megadrive        n64     nesopenbor     pcfx      pspminis  screenshots  sg-1000 solarus  uzebox      wonderswan</span><br><span class="line">amiga    atari5200 atarist     c128    cps1    dreamcastgamegear      gbc      gw      megadrive-japan  naomi   neshpc    pico-8    psx  scummvm      sgfx splash   vectrex     wonderswancolor</span><br><span class="line">amigacd32   atari7800 atomiswave  c16     cps2    famicomgamegearh     gbch     intellivision  mplayer       nds     ngppc98    pokemini  saturn  sega32x      snes tg16  vic20       x68000</span><br><span class="line">amstradcpc  atari800 bezels      c64     cps3    fbneogb      gbh      mame      msx       neocd   ngpcpcengine    ports     savestates  segacd       snesh tg16cd   videopac    zx81</span><br><span class="line">arcade    atarijaguar  BGM     capcom  daphne  fdsgba      genesis  mastersystem   msx2       neogeo  odysseypcenginecd  psp       sc-3000  sfc       snesmsu1  tic-80   virtualboy  zxspectrum</span><br></pre></td></tr></table></figure><p>arcade、mame、neogeo capcom（这四个是街机）、nes、nds、gba、ps、psp、fc、sfc、很多平台的游戏。我个人是使用 N1 盒子，但是不推荐，很多那种宽带送的电视盒子也行，根据现在的讯息去看哪个合适。国内的话能讨论这方面的有以下几个平台：</p><ul><li><a href="https://www.right.com.cn/forum/forum.php">恩山</a>，恩山是软路由为主，注意电视盒子板块去讨论</li><li><a href="https://www.emuelec.cn/">EmuELEC 中文网</a></li><li><a href="https://tieba.baidu.com/f?kw=emuelec&ie=utf-8">emuelec贴吧</a>，如果你 pc web 贴吧发帖让你下 app 端，你可以编辑好内容后 ctrl + 回车直接绕过这个限制发帖</li><li><a href="https://post.smzdm.com/">什么值得买</a>，该论坛的电视盒子版块也有人会讨论这个</li><li><a href="https://space.bilibili.com/97745521/video">b站的人中日月大佬</a>，他一般提供了整合包，业内也有名气</li></ul><h2 id="刷机"><a href="#刷机" class="headerlink" title="刷机"></a>刷机</h2><p>一般是两种:</p><ul><li>电视盒子解密(并不是所有盒子都能折腾这个)后，在盒子上安装 <code>Reboot to LibreELEC</code> 的 apk ，运行它从安卓电视系统切换到 U 盘启动，从而进入到游戏系统。</li><li>你盒子本身支持从 U 盘启动，你 U 盘写入 EmuELEC 的 img 文件后插到盒子上开机即可。</li></ul><p>刷机软件推荐 <a href="https://www.balena.io/etcher/">balenaEtcher</a>，建议下载 Portable 免安装的版本。EmuELEC 的镜像去搜你设备关键字+EmuELC 找。</p><p>初次打开需要设置手柄，手柄映射图<br><img src="https://raw.githubusercontent.com/zhangguanzhang/Image-Hosting/master/picgo/xbox-set.png"><br><img src="https://raw.githubusercontent.com/zhangguanzhang/Image-Hosting/master/picgo/controller-360.png"></p><h2 id="分区讲解"><a href="#分区讲解" class="headerlink" title="分区讲解"></a>分区讲解</h2><p>EmuELEC 的 img 刷到内存卡或者 U盘里后，windows 会弹出的让你是否格式化，记得点击否，一般是两个分区：</p><ul><li>EMUELEC 的 FAT32 分区 ，内存放有 dtb（device tree）的分区，不同电视盒子的 dtb 文件不一样，一般初次需要我们进里面的目录 device_trees 里把你设备的 xxx-dtb.img 拷贝到根目录的 <code>dtb.img</code></li><li>ext4 的分区， windows 无法识别，单独存放游戏 roms 的分区。也是一些对外开放的配置引入。单独会被挂载成 <code>/storage</code> 目录</li><li>EEROMS , 4.0 后开始新增的的分区，也就是之前的 <code>/storage/roms</code> 单独抽出来的一个单独分区，游戏都会存放在这里。</li></ul><p>前者是系统分区，一般升级的话升级这个就行了。添加游戏啥的可以在后者分区里按照平台添加，后者分区可以在 windows 上使用 <a href="https://www.diskgenius.cn/">DiskGenius</a> 打开。不过你刷好开机以及联网后，其实会自带一个 ssh 和 samba。都可以连上去操作，ssh 登录信息是 <code>root/emuelec</code>。 开机挂载 <code>/storage/roms</code> 的逻辑可以看脚本 <code>cat /usr/bin/mount_romfs.sh</code></p><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">EmuELEC:~ # df -h</span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">devtmpfs                791.1M      4.0K    791.1M   0% /dev</span><br><span class="line">/dev/sda1                 1.0G    694.4M    330.6M  68% /flash</span><br><span class="line">/dev/loop0              673.5M    673.5M         0 100% /</span><br><span class="line">/dev/sda2                26.1G     21.8G      4.3G  84% /storage</span><br><span class="line">tmpfs                   902.1M         0    902.1M   0% /dev/shm</span><br><span class="line">tmpfs                   902.1M      9.2M    892.8M   1% /run</span><br><span class="line">tmpfs                   902.1M         0    902.1M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs                   902.1M      2.6M    899.5M   0% /var</span><br><span class="line">tmpfs                   902.1M         0    902.1M   0% /tmp</span><br><span class="line">none                     26.1G     21.8G      4.3G  84% /tmp/database</span><br><span class="line">none                     26.1G     21.8G      4.3G  84% /tmp/cores</span><br><span class="line">none                     26.1G     21.8G      4.3G  84% /tmp/joypads</span><br><span class="line">none                     26.1G     21.8G      4.3G  84% /tmp/shaders</span><br><span class="line">none                     26.1G     21.8G      4.3G  84% /tmp/overlays</span><br><span class="line">none                     26.1G     21.8G      4.3G  84% /tmp/assets</span><br></pre></td></tr></table></figure><p>启动后, EMUELEC 分区被挂载为 <code>/flash</code>, STORAGE 分区被挂载为 <code>/storage</code>, system.img(也可能是那个 SYSTEM) 通过 <code>/dev/loop0</code> 被挂载为系统根目录 <code>/</code> 。所以, 用户能修改的仅仅是 <code>/flash</code> 和 <code>/storage</code> 目录下的内容<br>root用户的 home 目录被定位到 <code>/storage</code>, 如果需要添加登录后自动执行的命令(例如添加alias), 可以直接在 <code>/storage</code> 目录下新建 <code>.profile</code> 文件来实现。</p><h3 id="wifi"><a href="#wifi" class="headerlink" title="wifi"></a>wifi</h3><p>文件 <code>/storage/.config/emuelec/configs/emuelec.conf</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">## Activate wifi (0,1)</span><br><span class="line">wifi.enabled=1</span><br><span class="line">wifi.ssid=CMCC-5G</span><br><span class="line">wifi.key=zhangguanzhang</span><br><span class="line"># secondary wifi (not configurable via the user interface)</span><br><span class="line">#wifi2.ssid=new ssid</span><br><span class="line">#wifi2.key=new key</span><br><span class="line"># third wifi (not configurable via the user interface)</span><br><span class="line">#wifi3.ssid=new ssid</span><br><span class="line">#wifi3.key=new key</span><br></pre></td></tr></table></figure><p>RA 配置文件 <code>/storage/.config/retroarch/retroarch.cfg</code></p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>下载源码进入 <code>make image</code>，专门平台就加变量编译，例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PROJECT=Amlogic-ce DEVICE=Amlogic-ng ARCH=aarch64 DISTRO=EmuELEC make image</span><br></pre></td></tr></table></figure><p>例如贴吧也有人发自己编译的版本，但是这些比一般会锁 ssh，不让别人修改，当然你懂 Linux 的话可以 img 文件挂载了去改。网上也基本搜不到啥关于长篇大论讲编译的教程。建议还是先看官方的 <a href="https://github.com/EmuELEC/EmuELEC">README.md</a> </p><h2 id="使用问题"><a href="#使用问题" class="headerlink" title="使用问题"></a>使用问题</h2><h3 id="个别-HDMI-屏幕没声音"><a href="#个别-HDMI-屏幕没声音" class="headerlink" title="个别 HDMI 屏幕没声音"></a>个别 HDMI 屏幕没声音</h3><p>没声音的话尝试 EmuELEC setting – 音频 0,0 0,1 后重启试试。</p><h3 id="延迟"><a href="#延迟" class="headerlink" title="延迟"></a>延迟</h3><p>有些人说是手柄问题，有线好于 &gt; 无线，某些牌子无线 &gt; 另外的无线。也有人说电视的原因。<br>我个人是在 ra 里设置 降低延迟的选项，打开以后参数设为 1 和 2都试了下，2好点，但是 2 可能比较吃配置，卡的话就试试 1</p><h2 id="进阶玩法"><a href="#进阶玩法" class="headerlink" title="进阶玩法"></a>进阶玩法</h2><p><a href="https://github.com/EmuELEC/EmuELEC/wiki/bios">https://github.com/EmuELEC/EmuELEC/wiki/bios</a> bios存放路径</p><h3 id="roms-网站"><a href="#roms-网站" class="headerlink" title="roms 网站"></a>roms 网站</h3><ul><li><a href="https://www.oldmanemu.net/">老男人</a></li><li><a href="https://vimm.net/">vimm’s lair</a></li><li><a href="https://wowroms.com/en/all-roms">wowroms</a> 基本啥都有</li><li><a href="https://www.gamulator.com/roms">www.gamulator.com</a></li></ul><h3 id="缩容和提取-roms"><a href="#缩容和提取-roms" class="headerlink" title="缩容和提取 roms"></a>缩容和提取 roms</h3><p>需要缩容是因为 img 里所有分区表大小加起来会超过 U 盘容量。</p><h4 id="windows-缩容和提取-roms"><a href="#windows-缩容和提取-roms" class="headerlink" title="windows 缩容和提取 roms"></a>windows 缩容和提取 roms</h4><p>把 img 文件拖到 <code>DiskGenius</code> 里，然后删掉几个大游戏，特别 psp 里的。删掉后分区表大小并没变小，然后利用分区克隆工具，按照非 EEROMS 的分区在你 U 盘上创建后前面的分区，然后剩下分区给 EEROMS。格式化的时候记得每个分区的卷标名要设置上，<code>EMUELEC</code>、<code>STORAGE</code> 和 <code>EEROMS</code>。提取的话直接复制出来即可。</p><h4 id="Linux-缩容和提取-roms"><a href="#Linux-缩容和提取-roms" class="headerlink" title="Linux 缩容和提取 roms"></a>Linux 缩容和提取 roms</h4><p>帮同事弄的时候他 U 盘小于 64G ，<code>DiskGenius</code> 里分区克隆说不能克隆，气得我在 Linux 上搞。注意容量，先把 64G 的这个 img 文件拷贝到 Linux 上。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ ls -l emuelec4.3正式版-s905x3-58g-3.img </span><br><span class="line">-rw-r--r-- 1 root root 62302191616 Jan 24 19:17 emuelec4.3正式版-s905x3-58g-3.img</span><br><span class="line"><span class="comment"># 查看下 img 分区信息</span></span><br><span class="line">$ parted emuelec4.3正式版-s905x3-58g-3.img u s p</span><br><span class="line">Model:  (file)</span><br><span class="line">Disk /data/emuelec4.3正式版-s905x3-58g-3.img: 121683968s</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: msdos</span><br><span class="line">Disk Flags: </span><br><span class="line"></span><br><span class="line">Number  Start     End         Size        Type     File system  Flags</span><br><span class="line"> 1      8192s     4202495s    4194304s    primary  fat32        boot, lba</span><br><span class="line"> 2      4202496s  8388608s    4186113s    primary  ext4</span><br><span class="line"> 3      8390656s  121683967s  113293312s  primary  fat32        lba</span><br></pre></td></tr></table></figure><h5 id="img-挂载到本地目录"><a href="#img-挂载到本地目录" class="headerlink" title="img 挂载到本地目录"></a>img 挂载到本地目录</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取第一个空闲的 loop 设备</span></span><br><span class="line">LOOP_D=$(losetup --find)</span><br><span class="line"><span class="comment"># 把 img 文件扫描到 loop 设备上</span></span><br><span class="line">losetup --partscan <span class="variable">$LOOP_D</span>  emuelec4.3正式版-s905x3-58g-3.img</span><br><span class="line"><span class="comment"># 这里我的 img 里是 三个分区</span></span><br><span class="line"><span class="comment"># EMUELEC 和 EEROMS 分区都是 fat32 ，里面有中文游戏，需要挂载带上 iocharset=utf8</span></span><br><span class="line">mkdir -p p1 p2 p3</span><br><span class="line">mount  -o iocharset=utf8 <span class="variable">$&#123;LOOP_D&#125;</span>p1 p1</span><br><span class="line">mount  <span class="variable">$&#123;LOOP_D&#125;</span>p2 p2</span><br><span class="line">mount  -o iocharset=utf8 <span class="variable">$&#123;LOOP_D&#125;</span>p3 p3</span><br></pre></td></tr></table></figure><h5 id="克隆文件系统到-U-盘上"><a href="#克隆文件系统到-U-盘上" class="headerlink" title="克隆文件系统到 U 盘上"></a>克隆文件系统到 U 盘上</h5><p>创建 U 盘分区表，start 和 end 按照 img 文件里的信息来，最后分区结尾是 <code>100%</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk <span class="comment"># 找到 U 盘，我这里是 sdc</span></span><br><span class="line">sdc                                     8:32   1  57.6G  0 disk</span><br><span class="line"><span class="comment"># U 盘没分区表的，有的话自己清空下</span></span><br><span class="line"><span class="comment"># 在 U 盘上创建分区表</span></span><br><span class="line">parted /dev/sdc mkpart p fat32 8192s 4202495s</span><br><span class="line">parted /dev/sdc <span class="built_in">set</span> 1 boot on</span><br><span class="line">parted /dev/sdc mkpart p ext4 4202496s 8388608s</span><br><span class="line">parted /dev/sdc mkpart p fat32 8390656s 100% <span class="comment"># 最后一个直接100%</span></span><br></pre></td></tr></table></figure><p>查看下 u 盘分区信息和 img 信息是符合</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ parted /dev/sdc u s p</span><br><span class="line">Model: Kingston DataTraveler 3.0 (scsi)</span><br><span class="line">Disk /dev/sdc: 120845300s</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: msdos</span><br><span class="line">Disk Flags: </span><br><span class="line"></span><br><span class="line">Number  Start     End         Size        Type     File system  Flags</span><br><span class="line"> 1      8192s     4202495s    4194304s    primary               boot, lba</span><br><span class="line"> 2      4202496s  8388608s    4186113s    primary</span><br><span class="line"> 3      8390656s  120844287s  112453632s  primary               lba</span><br></pre></td></tr></table></figure><p>格式化出 U 盘文件系统：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意要带上 LABEL 名：EMUELEC STORAGE EEROMS</span></span><br><span class="line"><span class="comment"># openwrt 上没有 mkfs.vfat, 需要安装 dosfstools 后 ln -sf /usr/sbin/mkfs.fat /usr/sbin/mkfs.vfat</span></span><br><span class="line">mkfs.vfat -F 32 -n EMUELEC /dev/sdc1</span><br><span class="line">mkfs.ext4 -L STORAGE      /dev/sdc2</span><br><span class="line">mkfs.vfat -F 32 -n EEROMS /dev/sdc3</span><br></pre></td></tr></table></figure><p>如果忘记 LABEL，后面打也行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fatlabel /dev/sdc1 EMUELEC</span><br><span class="line">tune2fs -L STORAGE /dev/sdc2</span><br><span class="line">fatlabel /dev/sdc3 EEROMS</span><br><span class="line"># 查看 LABEL</span><br><span class="line">lsblk -o PATH,LABEL</span><br></pre></td></tr></table></figure><p>U 盘文件挂载到本地，并开始复制：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">mkdir -p u&#123;1..3&#125;</span><br><span class="line">mount  -o iocharset=utf8 /dev/sdc1 u1</span><br><span class="line">mount  /dev/sdc2 u2</span><br><span class="line">mount  -o iocharset=utf8 /dev/sdc3 u3</span><br><span class="line"></span><br><span class="line"># 拷贝之前 df -h 看下 p3 的已使用大小是否小于等于 u3 分区表大小</span><br><span class="line"># 如果不是 可以删掉 EEROMS 分区下面 psp 里的大游戏先</span><br><span class="line">rsync -vzrtopgl  p1/ u1/</span><br><span class="line">rsync -vzrtopgl  p2/ u2/</span><br><span class="line">rsync -vzrtopgl  p3/ u3/</span><br><span class="line"></span><br><span class="line">取消 U 盘挂载</span><br><span class="line">```bash</span><br><span class="line">umount u&#123;1..3&#125;</span><br></pre></td></tr></table></figure><h5 id="制作真正缩容的-img"><a href="#制作真正缩容的-img" class="headerlink" title="制作真正缩容的 img"></a>制作真正缩容的 img</h5><p>前面的 img 挂载不要取消，我们来制作一个缩小容量的 img 文件来分享给别人使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 制作一个 57G 的空文件</span><br><span class="line">truncate -s 57G test.img</span><br><span class="line"># 对文件开始分区，分区信息参考下 img</span><br><span class="line">parted test.img mklabel msdos</span><br><span class="line">parted test.img mkpart p fat32 8192s 4202495s</span><br><span class="line">parted test.img set 1 boot on</span><br><span class="line">parted test.img mkpart p ext4 4202496s 8388608s</span><br><span class="line">parted test.img mkpart p fat32 8390656s 100%</span><br></pre></td></tr></table></figure><p>挂载我们的 img 文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">LOOP_D2=$(losetup --find)</span><br><span class="line">losetup --partscan $LOOP_D2  test.img</span><br><span class="line"># 创建分区表</span><br><span class="line">mkfs.vfat -F 32 -n EMUELEC $&#123;LOOP_D2&#125;p1</span><br><span class="line">mkfs.ext4 -L STORAGE $&#123;LOOP_D2&#125;p2</span><br><span class="line">mkfs.vfat -F 32 -n EEROMS $&#123;LOOP_D2&#125;p3</span><br><span class="line"># 挂载</span><br><span class="line">mkdir -p u&#123;1..3&#125;</span><br><span class="line">mount  -o iocharset=utf8 $&#123;LOOP_D2&#125;p1 u1</span><br><span class="line">mount   $&#123;LOOP_D2&#125;p2 u2</span><br><span class="line">mount  -o iocharset=utf8 $&#123;LOOP_D2&#125;p3 u3</span><br></pre></td></tr></table></figure><p>拷贝到我们的新 img 里：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rsync -vzrtopgl  p1/ u1/</span><br><span class="line">rsync -vzrtopgl  p2/ u2/</span><br><span class="line">rsync -vzrtopgl  p3/ u3/</span><br><span class="line">umount u&#123;1..3&#125;</span><br></pre></td></tr></table></figure><p>取消两个 img 文件映射：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">umount p&#123;1..3&#125;</span><br><span class="line">losetup -D  $&#123;LOOP_D2&#125;</span><br><span class="line">losetup -D  $&#123;LOOP_D&#125;</span><br></pre></td></tr></table></figure><p>然后新的 img 文件就可以直接刷 U 盘了。</p><h3 id="外置-roms"><a href="#外置-roms" class="headerlink" title="外置 roms"></a>外置 roms</h3><p>也就是你可能一个 2G 或者 4G 的 U 盘刷纯净系统，然后游戏 roms 都存放在其他地方：</p><ul><li>其他存储介质，例如另一个 u 盘或者移动硬盘。不懂 Linux 的话可以格式化成 fat32，这样 windows 可以识别，分区里新建一个 roms 文件夹，然后 roms 里存放一个空白文件 <code>emuelecroms</code> ，roms 目录里存放各个目录即可。移动硬盘一般是 <code>exfat</code> 分区，linux 和 windows 都能识别。 samba 的话官方推荐使用 systemd mount 挂载，见 <a href="https://github.com/EmuELEC/EmuELEC/wiki/ROMS-on-CIFS-SAMBA-shares">sabma share</a></li><li>网络存储，nas上分享成 samba，或者你自己电脑上开共享。</li><li>阿里云盘 webdav 挂载，我自己研究出来的</li></ul><p>默认行为可以看脚本 <code>cat /usr/bin/mount_romfs.sh</code></p><h4 id="exfat-移动硬盘"><a href="#exfat-移动硬盘" class="headerlink" title="exfat 移动硬盘"></a>exfat 移动硬盘</h4><p>移动硬盘格式化成 exfat 格式，然后游戏 roms 拷贝进去，插上去后会自动挂载一个分区：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">EmuELEC:~ # df -h</span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">devtmpfs                791.1M      4.0K    791.1M   0% /dev</span><br><span class="line">/dev/sda1                 1.0G    694.4M    330.6M  68% /flash</span><br><span class="line">/dev/loop0              673.5M    673.5M         0 100% /</span><br><span class="line">/dev/sda2                26.1G     21.9G      4.2G  84% /storage</span><br><span class="line">tmpfs                   902.1M         0    902.1M   0% /dev/shm</span><br><span class="line">tmpfs                   902.1M     10.3M    891.8M   1% /run</span><br><span class="line">tmpfs                   902.1M         0    902.1M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs                   902.1M      2.6M    899.5M   0% /var</span><br><span class="line">tmpfs                   902.1M         0    902.1M   0% /tmp</span><br><span class="line">none                     26.1G     21.9G      4.2G  84% /tmp/overlays</span><br><span class="line">none                     26.1G     21.9G      4.2G  84% /tmp/joypads</span><br><span class="line">none                     26.1G     21.9G      4.2G  84% /tmp/assets</span><br><span class="line">none                     26.1G     21.9G      4.2G  84% /tmp/cores</span><br><span class="line">none                     26.1G     21.9G      4.2G  84% /tmp/database</span><br><span class="line">none                     26.1G     21.9G      4.2G  84% /tmp/shaders</span><br><span class="line">/dev/sdb1               119.2G     43.1G     76.2G  36% /var/media/ZGZ # 这里我的卷名字是 ZGZ</span><br><span class="line"></span><br><span class="line"># umount 掉 /var/media/ZGZ 后挂载到 /storage/roms</span><br><span class="line">EmuELEC:~ # umount /var/media/ZGZ/</span><br><span class="line">EmuELEC:~ # mount -t exfat -o nonempty /dev/sdb1 /storage/roms</span><br></pre></td></tr></table></figure><h4 id="webdav"><a href="#webdav" class="headerlink" title="webdav"></a>webdav</h4><p>阿里云盘 webdav 是我自己摸索出来的，因为有 aliyundrive-webdav 项目能把阿里云盘抽象成 webdav ，但是我 ssh 上去看了下我的固件里并不行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EmuELEC:~ # mount</span><br><span class="line">mount             mount.exfat       mount.exfat-fuse  mount.fuse        mount.ntfs        mountpoint</span><br></pre></td></tr></table></figure><p>在官方 github 上 <a href="https://github.com/EmuELEC/EmuELEC/issues/793">提了 issue</a> 后，开发者告诉我 <code>installentware</code> 后能使用 opkg，我就整出来了。</p><h5 id="aliyundrive-webdav"><a href="#aliyundrive-webdav" class="headerlink" title="aliyundrive-webdav"></a>aliyundrive-webdav</h5><p>先准备用大佬的 <a href="https://github.com/messense/aliyundrive-webdav">messense/aliyundrive-webdav</a> 把 阿里云盘 抽象成局域网的 webdav。有两种方案，一种是 openwrt 上，一种是非 openwrt 上，非 openwrt 上我是 Linux 跑 docker，windows 自己去 release 上下载 windows 的。Linux 的话 docker-compose 如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">aliyundrive-webdav:</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">aliyundrive-webdav</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">unless-stopped</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;REFRESH_TOKEN=xxxxxx&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">HOST=0.0.0.0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">PORT=8080</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">WEBDAV_AUTH_USER=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">WEBDAV_AUTH_PASSWORD=root</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">messense/aliyundrive-webdav</span></span><br><span class="line">    <span class="attr">command:</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">/usr/bin/aliyundrive-webdav</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--auto-index</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--root=/person/life/Game/EmuELEC/roms</span> <span class="comment"># 阿里云盘上 roms 路径</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--cache-ttl=10</span></span><br></pre></td></tr></table></figure><h5 id="挂载-webdav"><a href="#挂载-webdav" class="headerlink" title="挂载 webdav"></a>挂载 webdav</h5><p>实际上我研究出两种方案，一种是利用 rclone，一种是安装 davfs2 挂载</p><h6 id="rclone"><a href="#rclone" class="headerlink" title="rclone"></a>rclone</h6><p>先ssh 上去 wget <a href="https://github.com/rclone/rclone/releases">下载 linux-arm64.zip</a> 后，<code>unzip -x </code> 解压它后挂载：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加密密码</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;root&quot;</span> | ./rclone obscure -</span><br><span class="line"><span class="comment"># 挂载到当前 roms 目录</span></span><br><span class="line">./rclone mount :webdav: roms --webdav-url http://192.168.101.1:8080 --webdav-user root --webdav-pass DRggunKeWmBO8A9b9T2ZmkPFaR8 --cache-dir /tmp --allow-other --vfs-cache-mode writes --allow-non-empty</span><br></pre></td></tr></table></figure><p>rclone webdav 文档：</p><ul><li><a href="https://rclone.org/webdav/">https://rclone.org/webdav/</a></li><li><a href="https://rclone.org/commands/rclone_obscure/">https://rclone.org/commands/rclone_obscure/</a> # 为啥密码要加密</li></ul><h6 id="mount-t-davfs"><a href="#mount-t-davfs" class="headerlink" title="mount -t davfs"></a>mount -t davfs</h6><p>先 ssh 上去</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行下面这个，一路yes 后重启</span></span><br><span class="line">installentware</span><br></pre></td></tr></table></figure><p>然后你就能使用 opkg 了，安装下 <code>davfs2</code>，源在国外，不能安装就去上面的 <a href="https://github.com/EmuELEC/EmuELEC/issues/793#issuecomment-1018214935">issue 里</a>看我安装时候的 url </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">opkg install davfs2</span><br></pre></td></tr></table></figure><p>当然这样是无法在 EmuELEC 里使用的，就像我提的 issue 里，需要修改几个地方：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把 dav_user 和 dav_group 取消注释，并改成存在的用户，这里我是改成 root</span></span><br><span class="line">vi /opt/etc/davfs2/davfs2.conf </span><br></pre></td></tr></table></figure><p>改完后用 <code>grep -Ev &#39;^\s*$|^\s*#&#39; /opt/etc/davfs2/davfs2.conf</code> 查看是这样的内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dav_user        root            # system wide config file only</span><br><span class="line">dav_group       root            # system wide config file only</span><br></pre></td></tr></table></figure><p>然后更改 secret 的文件权限，否则挂载 webdav 的时候会报错 <code>mount.davfs: file /opt/etc/davfs2/secrets has wrong permissions</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 0600 /opt/etc/davfs2/secrets</span><br></pre></td></tr></table></figure><p>挂载 webdav，挂载完后建议 <code>ls /storage/roms</code>下，初次有一点卡</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t davfs  http://192.168.101.1:8080 /storage/roms</span><br></pre></td></tr></table></figure><p>后续挂载前记得执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /opt/var/run/mount.davfs/storage-roms.pid</span><br></pre></td></tr></table></figure><p>挂载完后进菜单刷新下游戏。</p><p>关于 webdav 的一些文档:</p><ul><li><a href="https://man.archlinux.org/man/mount.davfs.8.en">https://man.archlinux.org/man/mount.davfs.8.en</a></li></ul><p>后续可以参考 samba 写一个 systemd 的 mount</p><h3 id="自制-roms"><a href="#自制-roms" class="headerlink" title="自制 roms"></a>自制 roms</h3><p>我这里是自己打包一个纯净的 N1 img 和网上其他 img 里的 ROMS 复制进去为主。</p><p>N1 是个特殊存在，参照下面两个帖子：</p><ul><li>恩山 <a href="https://www.right.com.cn/forum/thread-4090331-1-1.html">EmuELEC 4.2 自主安装</a>里的，</li><li>贴吧 <a href="https://tieba.baidu.com/p/7619382778?pn=1&p_tk=1322QifLqSShpTFmTFD890NZYhknA/BTlYv+JMFCYG1WaXS0J558KEir1sr/GhyhKoYcYhmNaHzkHIG4uN84DH58wemMHpNVngGfh7poXSCPq1KfAiXaTvOnRW+aIz8lXqSf&p_timestamp=1643350078&p_sign=37ee8f2d0a49b58124628a8003121082&p_signature=f28e253e43066beb6450b9130d8fe53d&__pc2ps_ab=1322QifLqSShpTFmTFD890NZYhknA/BTlYv+JMFCYG1WaXS0J558KEir1sr/GhyhKoYcYhmNaHzkHIG4uN84DH58wemMHpNVngGfh7poXSCPq1KfAiXaTvOnRW+aIz8lXqSf%7C1643350078%7Cf28e253e43066beb6450b9130d8fe53d%7C37ee8f2d0a49b58124628a8003121082&red_tag=0480290028&qq-pf-to=pcqq.group">N1可用的鬼灭之刃EmuELEC v4.3</a></li></ul><p>下载官方的 img 文件，然后 N1 的补丁文件我用在 4.3 的官方文件里去替换是可以的。对比了下我之前的人中日月的固件和官方 img 替换了 N1 补丁文件后，发现内核是一样的都是 <code>3.14.29</code>，说明人中日月打包也只是基础设置+游戏 roms 而已。<br>先官方的 img 文件刷到 U 盘里，然后 windows 上把补丁覆盖到第一个分区。然后插 N1 开机启动后设置如下：</p><ul><li>emuelec 菜单时区，也可以可以 ssh 上去</li><li>ra 的中文乱码，<code>systemctl cat tmp-assets.mount</code> ， <code>cp -a /tmp/assets/* /storage/assets/</code> 后提取中文字体覆盖 <code>/storage/assets/ozone/</code> 下的俩 ttf 后（似乎下面的 pkg 目录也要处理？）。重启机器后选择中文，然后再在 RA 里选择保存下配置。</li><li>自家 wifi 设置啥的</li></ul><p>然后拔下来，插 Linux 上。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ parted /dev/sda u s p</span><br><span class="line">Model: SanDisk Extreme Pro (scsi)</span><br><span class="line">Disk /dev/sda: 250085376s</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: msdos</span><br><span class="line">Disk Flags: </span><br><span class="line"></span><br><span class="line">Number  Start     End         Size        Type     File system  Flags</span><br><span class="line"> 1      8192s     4202495s    4194304s    primary  fat32        boot, lba</span><br><span class="line"> 2      4202496s  8388608s    4186113s    primary  ext4</span><br><span class="line"> 3      8390656s  250085375s  241694720s  primary  fat32        lba</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>有三个分区，先打包一个纯净版，考虑到 U 盘容量问题和现在购买基本都是 16G（jd 上好像最小 8G），打包一个 7350M 的纯净版。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">truncate -s 7350M test.img</span><br></pre></td></tr></table></figure><p>先把设置后的 U 盘内文件系统的东西导出来到 test.img 里：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">mkdir e1 e2 e3</span><br><span class="line">mount  -o iocharset=utf8 /dev/sda1 e1</span><br><span class="line">mount  /dev/sda2 e2</span><br><span class="line">mount  -o iocharset=utf8 /dev/sda1 e3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对文件开始分区，分区信息参考下 img</span></span><br><span class="line">parted test.img mklabel msdos</span><br><span class="line">parted test.img mkpart p fat32 8192s 4202495s</span><br><span class="line">parted test.img <span class="built_in">set</span> 1 boot on</span><br><span class="line">parted test.img mkpart p ext4 4202496s 8388608s</span><br><span class="line">parted test.img mkpart p fat32 8390656s 100%</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理我们的 img 文件</span></span><br><span class="line"></span><br><span class="line">LOOP_D=$(losetup --find)</span><br><span class="line">losetup --partscan <span class="variable">$LOOP_D</span>  test.img</span><br><span class="line"><span class="comment"># 创建分区表</span></span><br><span class="line">mkfs.vfat -F 32 -n EMUELEC <span class="variable">$&#123;LOOP_D&#125;</span>p1</span><br><span class="line">mkfs.ext4 -L STORAGE <span class="variable">$&#123;LOOP_D&#125;</span>p2</span><br><span class="line">mkfs.vfat -F 32 -n EEROMS <span class="variable">$&#123;LOOP_D&#125;</span>p3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载</span></span><br><span class="line">mkdir -p u&#123;1..3&#125;</span><br><span class="line">mount  -o iocharset=utf8 <span class="variable">$&#123;LOOP_D&#125;</span>p1 u1</span><br><span class="line">mount   <span class="variable">$&#123;LOOP_D&#125;</span>p2 u2</span><br><span class="line">mount  -o iocharset=utf8 <span class="variable">$&#123;LOOP_D&#125;</span>p3 u3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝文件</span></span><br><span class="line">rsync -vzrtopgl  e1/ u1/</span><br><span class="line"></span><br><span class="line">rsync -vzrtopgl  e2/ u2/</span><br><span class="line"><span class="comment"># EEROMS</span></span><br><span class="line">rsync -vzrtopgl  e3/ u3/</span><br><span class="line"><span class="comment"># 添加命令别名</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;alias ll=&#x27;ls -l&#x27;&quot;</span> &gt;&gt; u2/.config/profile.d/99-emuelec_functions.conf</span><br><span class="line"><span class="comment"># 也可以自己修改一些文件</span></span><br></pre></td></tr></table></figure><p>拷贝完成后，可以进行一些修改，例如后面的菜单汉化和主题修改。改完了后就可以收尾工作：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">umount e&#123;1..2&#125; u&#123;1..3&#125;</span><br><span class="line">losetup -D $LOOP_D</span><br><span class="line"></span><br><span class="line">mv test.img EmuELEC-4.3-N1-3.img</span><br><span class="line">gzip EmuELEC-4.3-N1-3.img</span><br></pre></td></tr></table></figure><h2 id="一些其他笔记"><a href="#一些其他笔记" class="headerlink" title="一些其他笔记"></a>一些其他笔记</h2><h3 id="ssh-的一些设置"><a href="#ssh-的一些设置" class="headerlink" title="ssh 的一些设置"></a>ssh 的一些设置</h3><p><code>/storage/.config/emuelec/configs/emuelec.conf</code> 里修改时区 <code>system.timezone=Asia/Shanghai</code></p><h4 id="蓝牙相关"><a href="#蓝牙相关" class="headerlink" title="蓝牙相关"></a>蓝牙相关</h4><p>连蓝牙手柄参考：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行后进入 bluetoothctl 交互</span></span><br><span class="line">bluetoothctl</span><br><span class="line"></span><br><span class="line">default-agent</span><br><span class="line">power on</span><br><span class="line">discoverable on</span><br><span class="line">pairable on</span><br><span class="line">scan on</span><br></pre></td></tr></table></figure><p>然后会开始扫描 蓝牙，记录下你的蓝牙手柄 MAC，开始配对</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trust AC:FD:93:CB:3E:BE</span><br><span class="line">pair AC:FD:93:CB:3E:BE</span><br><span class="line">connect AC:FD:93:CB:3E:BE</span><br></pre></td></tr></table></figure><p>移除设备的话</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">remove AC:FD:93:CB:3E:BE</span><br></pre></td></tr></table></figure><h4 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h4><p>去官方仓库找，例如 <a href="https://github.com/EmuELEC/es-theme-alekfull-EmueELEC">EmuELEC/es-theme-alekfull-EmueELEC</a>，进入下面目录下载后解压：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /storage/.config/emulationstation/themes</span><br><span class="line">wget https://github.com/EmuELEC/es-theme-alekfull-EmueELEC/archive/refs/heads/master.zip</span><br><span class="line">unzip -x master.zip &amp;&amp; rm -f master.zip</span><br><span class="line">mv es-theme-alekfull-EmueELEC-* es-theme-alekfull-EmueELEC</span><br></pre></td></tr></table></figure><p>主题设置在 <code>/storage/.config/emulationstation/es_settings.cfg</code> 里的 <code>ThemeSet</code></p><h4 id="菜单汉化的话"><a href="#菜单汉化的话" class="headerlink" title="菜单汉化的话"></a>菜单汉化的话</h4><p>善用 find ，例如我看了下菜单里有部分还是英文，例如 <code>DANGER ZONE</code>，用命令查 <code>find / -type f -exec grep -Eil &#39;DANGER\s+zone&#39; &#123;&#125; \;</code>，找到如下文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/storage/.config/emulationstation/resources/mamenames.xml</span><br><span class="line">/storage/.config/emuelec/configs/locale/de/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/pt_PT/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/ko/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/hu/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/nb_NO/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/pl/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/ca/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/zh_TW/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/pt_BR/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/it/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/he/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/uk_UA/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/ru_RU/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/sv_SE/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/oc_FR/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/eu_ES/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/nl/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/el/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/zh_CN/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/zh_CN/LC_MESSAGES/emulationstation2.po~</span><br><span class="line">/storage/.config/emuelec/configs/locale/cy_GB/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/ja_JP/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/nn_NO/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/es_MX/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/tr/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/es/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/es/LC_MESSAGES/emulationstation2.po~</span><br><span class="line">/storage/.config/emuelec/configs/locale/fr/LC_MESSAGES/emulationstation2.po</span><br><span class="line">/storage/.config/emuelec/configs/locale/ar/LC_MESSAGES/emulationstation2.po</span><br></pre></td></tr></table></figure><p>例如我要汉化 <code>DANGER ZONE</code> 这个菜单，按照下面步骤修改文件内容后发布：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /storage/.config/emuelec/configs/locale/zh_CN/LC_MESSAGES/</span><br><span class="line">vi emulationstation2.po</span><br><span class="line"># msgfmt 在包 gettext 里</span><br><span class="line">msgfmt -o emulationstation2.mo emulationstation2.po</span><br></pre></td></tr></table></figure><h3 id="N1-补丁后开机-CoreELEC-图标解决"><a href="#N1-补丁后开机-CoreELEC-图标解决" class="headerlink" title="N1 补丁后开机 CoreELEC 图标解决"></a>N1 补丁后开机 CoreELEC 图标解决</h3><p>参照 <a href="https://www.qishe.org/3774.html#">N1 启动原版 EmuELEC</a>:</p><p>目前 N1跑 Emuelec 的办法都是替换补丁，补丁里的内核是从 CoreELEC 编译来的，所以启动时会显示 CoreELEC 的 logo，对于洁癖党来说不能忍受，而且一直用这个补丁内核的话，就不能随 EmuELEC 的更新而更新。哪有没有办法直接启动原版呢？答案是肯定的。首先得搞清楚为什么N1不能启动原版的原因。那是因为 EmuELEC 的内核打包成 Android boot image 格式，而 N1 的 uboot 却只支持未经压缩的内核，那我们只要想办法从 EmuELEC 的中解包出来未经压缩的内核和 initramfs 就可以了。<br>从新版的EmuELEC镜像中获取 kernel.img，然后下载 <a href="http://whiteboard.ping.se/Android/Unmkbootimg">这个页面点那个 download 下载 unmkbootimg</a>，解压，在 linux 环境运行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载 unmkbootimg</span></span><br><span class="line">wget http://whiteboard.ping.se/uploads/Android/unmkbootimg.gz</span><br><span class="line">gzip  -d unmkbootimg.gz</span><br><span class="line">chmod a+x unmkbootimg</span><br><span class="line"></span><br><span class="line">./unmkbootimg kernel.img  </span><br><span class="line"><span class="comment"># 会得到类似以下的文件：</span></span><br><span class="line">initramfs.cpio.gz  </span><br><span class="line">zImage</span><br><span class="line"><span class="comment"># 同时记住输出里的  Kernel address</span></span><br><span class="line">To recompile this image, use:</span><br><span class="line">  mkbootimg --kernel zImage --ramdisk initramfs.cpio.gz ...</span><br></pre></td></tr></table></figure><p>如果此时需要修改开机图片的话，可以执行下面操作，这个步骤是通用的</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mkdir initramfs</span><br><span class="line"><span class="built_in">cd</span> initramfs</span><br><span class="line"><span class="comment"># 我看有些 initramfs.cpio.gz 并不是 gzip压缩的，所以下面报错的话先试试 file initramfs.cpio.gz 看看，是 gzip的话就 gzip -d initramfs.cpio.gz</span></span><br><span class="line">cpio -idmv &lt; ../initramfs.cpio.gz</span><br><span class="line"><span class="comment"># 替换 splash/下的 splash-1080.png 即可，必须格式也是，而不是后缀</span></span><br><span class="line">ls -l splash/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换完成后打包回 initramfs.cpio.gz</span></span><br><span class="line"><span class="comment"># find . | cpio --create --format=&#x27;newc&#x27; &gt; ../initramfs.cpio.gz</span></span><br><span class="line">find . -print0 | cpio --null --create --format=newc &gt; ../initramfs.cpio.gz</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="comment"># 把上面 unmkbootimg 输出的 mkbootimg 命令执行</span></span><br><span class="line"><span class="comment"># https://github.com/EmuELEC/EmuELEC/search?q=mkbootimg  https://github.com/EmuELEC/EmuELEC/search?q=ANDROID_BOOTIMG_OPTIONS</span></span><br><span class="line">mkbootimg --kernel zImage --ramdisk initramfs.cpio.gz --base 0x0 --kernel_offset 0x1080000 -o new_kernel.img</span><br></pre></td></tr></table></figure><p>下面的没试过，主要是 N1 的步骤</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># https://www.right.com.cn/forum/thread-6632323-1-1.html</span><br><span class="line"># 把 initramfs.cpio.gz 打包成 uInitrd。</span><br><span class="line">mkimage -A arm64 -O linux -T kernel -C none -d initramfs.cpio.gz uInitrd</span><br><span class="line"></span><br><span class="line">#这里得到的 kernel 就是未压缩的内核，把他改名成 kernel.img。</span><br><span class="line">lzop -d zImage -o kernel.img.new</span><br></pre></td></tr></table></figure><p>大功告成，把 kernel.img 和 uInitrd 替换补丁里的同名文件，启动时就是用原版内核了</p><h3 id="开机启动顺序"><a href="#开机启动顺序" class="headerlink" title="开机启动顺序"></a>开机启动顺序</h3><p><a href="https://blog.csdn.net/michaelchain/article/details/119628601">https://blog.csdn.net/michaelchain/article/details/119628601</a> 参考这个，更多的不写进来了</p><p>这个是在 uboot 中进行管理的, 可以通过 <code>fw_printenv</code> 命令进行查看:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">EmuELEC:~ # fw_printenv</span><br><span class="line">...</span><br><span class="line">baudrate=115200</span><br><span class="line">boot_count=0</span><br><span class="line">bootcmd=if test $&#123;bootfromnand&#125; = 1; then setenv bootfromnand 0; saveenv; else run bootfromsd; run bootfromusb; fi; run storeboot</span><br><span class="line">bootcount_check=echo bootcounts=$&#123;boot_count&#125;; if itest $&#123;boot_count&#125; == 0; then setenv boot_count 1;saveenv;else if itest $&#123;boot_count&#125; == 1; then setenv boot_count 2;saveenv;else if itest $&#123;boot_count&#125; == 2; then setenv boot_count 3;saveenv;else if itest $&#123;boot_count&#125; == 3; then setenv boot_count 4;saveenv;else if itest $&#123;boot_count&#125; == 4; then run recovery_from_flash;fi;fi;fi;fi;fi</span><br><span class="line">bootdelay=0</span><br><span class="line">bootfromnand=0</span><br><span class="line">bootfromsd=mmcinfo; if fatload mmc 0 $&#123;loadaddr&#125; kernel.img; then run sddtb; setenv bootargs $&#123;bootargs&#125; bootfromsd; bootm; fi</span><br><span class="line">bootfromusb=usb start 0; if fatload usb 0 $&#123;loadaddr&#125; kernel.img; then run usbdtb; setenv bootargs $&#123;bootargs&#125; bootfromusb; bootm; fi</span><br><span class="line">bootmode_check=get_rebootmode; echo reboot_mode=$&#123;reboot_mode&#125;;if test $&#123;reboot_mode&#125; = factory_reset; then defenv_reserv;setenv upgrade_step 2; save;fi;</span><br><span class="line">cmdline_keys=if keyman init 0x1234; then if sec_keyunify read mac $&#123;loadaddr&#125; str; then setenv bootargs $&#123;bootargs&#125; mac=$&#123;mac&#125; androidboot.mac=$&#123;mac&#125;;fi;fi;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到其中的 bootfromnand 变量是用于控制设备的启动顺序, 如果值为1, 那么从nand(设备内部存储, eMMC等), 如果值为0, 那么依次从sd, 从usb启动, 在这个过程中如果某个介质可以启动了, 就把这个方式加到bootargs变量的值当中去, 例如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setenv bootargs $&#123;bootargs&#125; bootfromsd;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;EmuELEC-笔记&quot;&gt;&lt;a href=&quot;#EmuELEC-笔记&quot; class=&quot;headerlink&quot; title=&quot;EmuELEC 笔记&quot;&gt;&lt;/a&gt;EmuELEC 笔记&lt;/h1&gt;&lt;p&gt;后续关于 EmuELEC 的笔记和知识点都会在这里更新，假定看到这篇文章的人</summary>
      
    
    
    
    
    <category term="linux" scheme="http://zhangguanzhang.github.io/tags/linux/"/>
    
    <category term="EmuELEC" scheme="http://zhangguanzhang.github.io/tags/EmuELEC/"/>
    
  </entry>
  
  <entry>
    <title>openwrt 的在线升级固件和扩容的研究</title>
    <link href="http://zhangguanzhang.github.io/2021/12/19/openwrt-update/"/>
    <id>http://zhangguanzhang.github.io/2021/12/19/openwrt-update/</id>
    <published>2021-12-19T21:28:30.000Z</published>
    <updated>2021-12-19T21:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>手上有 r2s、N1 和 x86_64 的固件维护，r2s 的参照别人的脚本搞了在线升级固件的脚本，别人的脚本只支持 ext4 升级，而后面我也把 squashfs 格式的固件升级搞出来了。恩山上有的人的固件我也看 x86_64 也可以在线升级，后面我也会去测下 x86_64 的，理论上是通用的。</p><h2 id="升级过程"><a href="#升级过程" class="headerlink" title="升级过程"></a>升级过程</h2><p>以 r2s 为例讲解。参照目前看到的的 <a href="https://github.com/klever1988/nanopi-openwrt/raw/master/scripts/autoupdate.sh">1988 的升级脚本</a> ，最初的人不知道是谁搞的在线升级，因为很久之前就看到有些人的固件能在线升级了。</p><h3 id="升级前准备"><a href="#升级前准备" class="headerlink" title="升级前准备"></a>升级前准备</h3><h4 id="相关命令"><a href="#相关命令" class="headerlink" title="相关命令"></a>相关命令</h4><p>确保固件有下面命令：</p><table><thead><tr><th align="left">command</th><th align="left">package name</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">parted</td><td align="left">parted</td><td align="left">修改分区和获取分区信息</td></tr><tr><td align="left">losetup</td><td align="left">losetup</td><td align="left">loop device 命令，用于挂载固件里的文件分区</td></tr><tr><td align="left">resize2fs</td><td align="left">resize2fs</td><td align="left">resize ext4 需要</td></tr><tr><td align="left">truncate</td><td align="left">coreutils-truncate</td><td align="left">填充和清空文件，这里是填充扩容</td></tr><tr><td align="left">curl</td><td align="left">curl</td><td align="left">下载，以及http 调用一些 api</td></tr><tr><td align="left">wget</td><td align="left">wget</td><td align="left">下载命令</td></tr><tr><td align="left">mksquashfs</td><td align="left">squashfs-tools-mksquashfs</td><td align="left">squashfs格式需要</td></tr><tr><td align="left">unsquashfs</td><td align="left">squashfs-tools-unsquashfs</td><td align="left">squashfs格式需要</td></tr></tbody></table><h4 id="KERNEL-PARTSIZE-和-ROOTFS-PARTSIZE"><a href="#KERNEL-PARTSIZE-和-ROOTFS-PARTSIZE" class="headerlink" title="KERNEL_PARTSIZE 和 ROOTFS_PARTSIZE"></a>KERNEL_PARTSIZE 和 ROOTFS_PARTSIZE</h4><p><code>CONFIG_TARGET_KERNEL_PARTSIZE</code> 和 <code>CONFIG_TARGET_ROOTFS_PARTSIZE</code> 是 <code>.config</code> 文件里的，单位是 <code>M</code>，前者是类似常规大型 linux os 里的 <code>/boot</code> 分区，openwrt 默认就只有这两个分区。</p><p>r2s 的话 <code>KERNEL_PARTSIZE</code> 一般 <code>12M</code> 就够用了，但是很多网上互相抄的人在 r2s 的 <code>.config</code> 里给 32、64 之类的非常浪费。<code>ROOTFS_PARTSIZE</code> 是最终的根分区大小，给小了因为编译带很多插件，导致最终的打包镜像容量不够，我的固件是 <code>635</code>。然后 r2s 是内存卡，一般现在内存大大小都是 4G 以上，也就是刷完固件后，根分区就是 635M ，卡的剩下空间都没使用，当然，x86_64 也是一样的问题。所以就有了这个升级顺带扩容的步骤。</p><h4 id="提前的容量存储新固件"><a href="#提前的容量存储新固件" class="headerlink" title="提前的容量存储新固件"></a>提前的容量存储新固件</h4><p>1988 的固件非常小，下载 300M，从一个新手初次尝试来说，很可能尴尬的情况就是卡刷后 rootfs 是 600M，然后可用就200M，固件压缩后350M，所以我固件在初次扩容升级会暂时新建一个分区，用于存储下载升级的固件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 一般很多固件 /opt 单独挂载，或者属于 / ，所以如果已经在升级阶段扩容了，固件就存 /opt下，没扩容过，就存挂载点 /tmp/update/download</span></span><br><span class="line">if [ $(df  -m /opt | awk &#x27;NR==2&#123;print $4&#125;&#x27;) -lt 2400 ];then</span><br><span class="line">    NEED_GROW=1</span><br><span class="line">    mkdir -p /tmp/update/download</span><br><span class="line">    warning &#x27;检测到当前未扩容，先借用初版固件扩容，后续请再执行升级脚本&#x27;</span><br><span class="line">    df -h</span><br><span class="line">    parted /dev/$block_device p</span><br><span class="line">    # 该文件存 part_num ，防止机器重启后重复新建了分区表</span><br><span class="line">    if [ ! -f &#x27;/opt/.parted&#x27; ];then</span><br><span class="line">        start_sec=$(parted /dev/$block_device unit s print free | awk &#x27;$1~&quot;s&quot;&#123;a=$1&#125;END&#123;print a&#125;&#x27;)</span><br><span class="line">        parted /dev/$block_device mkpart p ext4 $&#123;start_sec&#125; 4G</span><br><span class="line">        part_num=$( parted /dev/$block_device p | awk &#x27;$5==&quot;primary&quot;&#123;a=$1&#125;END&#123;print a&#125;&#x27; )</span><br><span class="line">        sleep 3 # 此处会自动挂载造成蛋疼</span><br><span class="line">        if grep -E /dev/$&#123;block_device&#125;p$&#123;part_num&#125; /proc/mounts;then</span><br><span class="line">            if mountpoint -q  /mnt/$&#123;block_device&#125;p$&#123;part_num&#125;;then</span><br><span class="line">                touch /mnt/$&#123;block_device&#125;p$&#123;part_num&#125;/test &amp;&gt;/dev/null || NEED_MKFS=1</span><br><span class="line">                umount /mnt/$&#123;block_device&#125;p$&#123;part_num&#125;</span><br><span class="line">            fi</span><br><span class="line">            [ -n &quot;$NEED_MKFS&quot; ] &amp;&amp; mkfs.ext4 -F /dev/$&#123;block_device&#125;p$&#123;part_num&#125;</span><br><span class="line">        else</span><br><span class="line">            mkfs.ext4 -F /dev/$&#123;block_device&#125;p$&#123;part_num&#125;</span><br><span class="line">        fi</span><br><span class="line">        echo $&#123;part_num&#125; &gt; /opt/.parted</span><br><span class="line">    else</span><br><span class="line">        part_num=$(cat /opt/.parted)</span><br><span class="line">    fi</span><br><span class="line">    mountpoint -q  /tmp/update/download || mount /dev/$&#123;block_device&#125;p$&#123;part_num&#125; /tmp/update/download</span><br><span class="line">    USER_FILE=/tmp/update/download/openwrt.img.gz</span><br><span class="line">    rm -f $&#123;USER_FILE&#125;</span><br><span class="line">    # 因为初次没扩容，我的固件是存放在 docker 镜像里的，可能拉取 docker 镜像就容量满了，所以我单独有个release 存放编译好的固件，直接下载，用于初次</span><br><span class="line">    wget https://ghproxy.com/https://github.com/zhangguanzhang/Actions-OpenWrt/releases/download/fs/openwrt-rockchip-armv8-friendlyarm_nanopi-r2s-ext4-sysupgrade.img.gz -O $&#123;USER_FILE&#125;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>对于后面的下载新版本固件，1988 的脚本我看他是 github action 每天定时编译发布存 release，感觉后面他可能会被 github 给 ban了。 我脚本里是存 docker hub 的镜像里，我的固件都自带 docker，docker 拉取镜像后提取镜像文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;$&#123;BUILD_DIR&#125;/Dockerfile &lt;&lt; EOF</span><br><span class="line">FROM alpine</span><br><span class="line">LABEL FILE=$file</span><br><span class="line">LABEL NUM=$&#123;GITHUB_RUN_NUMBER&#125;</span><br><span class="line">COPY * /</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>github action 上利用 buildx 构建存储这个镜像，用 LABEL 指定文件路径名，直接 copy 出来：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker pull zhangguanzhang/r2s:$&#123;VER&#125;</span><br><span class="line">CTR_PATH=$( docker inspect zhangguanzhang/r2s:$&#123;VER&#125; --format &#x27;&#123;&#123; .Config.Labels &#125;&#125;&#x27; | grep -Eo &#x27;openwrt-.+img.gz&#x27; )</span><br><span class="line">docker create --name update zhangguanzhang/r2s:$&#123;VER&#125;</span><br><span class="line">docker cp update:/$&#123;CTR_PATH&#125; $&#123;USER_FILE&#125;</span><br><span class="line">docker rm update</span><br><span class="line">docker rmi zhangguanzhang/r2s:$&#123;VER&#125;</span><br></pre></td></tr></table></figure><h3 id="扩容和升级"><a href="#扩容和升级" class="headerlink" title="扩容和升级"></a>扩容和升级</h3><p>固件分为两个文件系统，SquashFS 和 Ext4。</p><p>SquashFS（推荐）：固件文件名带有 “squashfs”，SquashFS 为只读文件系统，支持系统还原（支持物理 Reset按钮 还原），支持后台固件升级，更能避免 SD 卡文件系统触发写保护，适合绝大部分用户使用。</p><p>Ext4：固件文件名带有 “ext4”，Ext4 文件系统具备整个分区可读写性质，更适合熟悉 Linux 系统的用户使用，但意外断电有几率造成分区写入保护。</p><h4 id="ext4"><a href="#ext4" class="headerlink" title="ext4"></a>ext4</h4><p>前面两个章节是下载和存放固件 img.gz ，现在开始扩容和升级，扩容就是利用 truncate 下固件文件的大小，然后修复固件文件里的第二个分区。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 因为最终会把修改后的固件写入到根分区所在的块设备，所以固件需要存放在 /tmp 目录下</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 大小和内存挂钩，所以不要size太大</span></span><br><span class="line">mount -t tmpfs -o remount,size=870m tmpfs /tmp</span><br><span class="line"><span class="meta">#</span><span class="bash"> 后面的 <span class="literal">true</span> 是因为 github action 的打包会影响解压，虽然最终报错，但是解压的固件还是能用的</span></span><br><span class="line">gzip -dc openwrt.img.gz &gt; /tmp/update/openwrt.img || true</span><br><span class="line"></span><br><span class="line">block_device=&#x27;mmcblk0&#x27;</span><br><span class="line">[ ! -d /sys/block/$block_device ] &amp;&amp; block_device=&#x27;mmcblk1&#x27;</span><br><span class="line">bs=`expr $(cat /sys/block/$block_device/size) \* 512`</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改文件大小</span></span><br><span class="line">truncate -s $bs /tmp/update/openwrt.img</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改第二个分区大小，1988用的是 <span class="built_in">echo</span> <span class="string">&quot;, +&quot;</span> | sfdisk -N 2 /tmp/update/openwrt.img 可读性不好</span></span><br><span class="line">parted /tmp/update/openwrt.img resizepart 2 100%</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将镜像文件虚拟成块设备，类似于 windows 的那种双击 iso 后的装载 iso ，对于块设备的操作都会时刻写入到 img 文件里</span></span><br><span class="line">lodev=$(losetup -f)</span><br><span class="line">losetup -P $lodev /tmp/update/openwrt.img</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 挂载 rootfs 解压备份文件</span></span><br><span class="line">mkdir -p /mnt/img</span><br><span class="line">mount -t ext4 $&#123;lodev&#125;p2 /mnt/img</span><br><span class="line"><span class="meta">#</span><span class="bash"> op 的备份命令</span></span><br><span class="line">sysupgrade -b back.tar.gz</span><br><span class="line">tar zxf back.tar.gz -C /mnt/img</span><br><span class="line">    if ! grep -q macaddr /etc/config/network; then</span><br><span class="line">        warning &#x27;注意：由于已知的问题，“网络接口”配置无法继承，重启后需要重新设置WAN拨号和LAN网段信息&#x27;</span><br><span class="line">        rm /mnt/img/etc/config/network;</span><br><span class="line">    fi</span><br><span class="line">mountpoint -q  /mnt/img &amp;&amp; umount /mnt/img</span><br><span class="line"><span class="meta">#</span><span class="bash"> openwrt 存在 auto mount，此处取消挂载</span></span><br><span class="line">grep -q $&#123;lodev&#125;p1 /proc/mounts &amp;&amp; umount $&#123;lodev&#125;p1</span><br><span class="line">grep -q $&#123;lodev&#125;p2 /proc/mounts &amp;&amp; umount $&#123;lodev&#125;p2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修复固件里扩容的分区</span></span><br><span class="line">e2fsck -yf $&#123;lodev&#125;p2 || true</span><br><span class="line">resize2fs $&#123;lodev&#125;p2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 取消 img 文件的挂载</span></span><br><span class="line">losetup -d $lodev</span><br><span class="line"></span><br><span class="line">echo 1 &gt; /proc/sys/kernel/sysrq</span><br><span class="line">echo u &gt; /proc/sysrq-trigger &amp;&amp; umount / || true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这个 ddnz 命令从他那里复制的</span></span><br><span class="line">/tmp/ddnz /tmp/update/openwrt.img /dev/$block_device</span><br><span class="line">printf &#x27;%b\n&#x27; &quot;\033[1;32m[SUCCESS] 刷机完毕，正在重启...\033[0m&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启</span></span><br><span class="line">echo b &gt; /proc/sysrq-trigger</span><br></pre></td></tr></table></figure><h4 id="squashfs"><a href="#squashfs" class="headerlink" title="squashfs"></a>squashfs</h4><p>openwrt 的另一种文件系统固件，就是一个只可读写的压缩的 rootfs 解压开作为 <code>overlay</code> 的 lower dir 只读，提供给用户的是 overlay 的 upper dir 去写入，长按设备上的 reset 按钮恢复出厂设置就是把 overlay 的上层丢弃掉，所以 squashfs 类型的固件带快照功能。当然市面上搜了下也没找到 squashfs 类型的固件在升级的时候扩容的步骤，自己研究了下搞出来了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 挂载 rootfs 解压备份文件</span></span><br><span class="line">mkdir -p /mnt/img</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里会报错 wrong fs <span class="built_in">type</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> mount -t ext4 <span class="variable">$&#123;lodev&#125;</span>p2 /mnt/img</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 被我改成这样</span></span><br><span class="line">mount $&#123;lodev&#125;p2 /mnt/img</span><br><span class="line">IMG_FSTYPE=$(df -T /mnt/img | awk &#x27;NR==2&#123;print $2&#125;&#x27;)</span><br></pre></td></tr></table></figure><p>取到了 <code>IMG_FSTYPE</code> 后走不同的逻辑，这里它的值是 <code>squashfs</code> ，而挂载后的 <code>/mnt/img</code> 是无法写入任何文件的。然后搜了下 <code>squashfs</code> 相关，自己折腾的话需要 <code>mksquashfs</code> 和 <code>unsquashfs</code> 的两个命令玩。一开始是尝试解压 <code>$&#123;lodev&#125;p2</code> ，结果经常 oom ，去找 squashfs-tools 源码作者询问如何限制内存得到下面信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># https://github.com/plougher/squashfs-tools/issues/139#issuecomment-991779738</span><br><span class="line">unsquashfs -da 10 -fr 10 $&#123;lodev&#125;p2</span><br></pre></td></tr></table></figure><p>基本一直卡着，毕竟最后肯定要重新 <code>mksquashfs</code> 打包的，然后直接 cp 得了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;$IMG_FSTYPE&quot; = &#x27;squashfs&#x27; ];then</span><br><span class="line">    info &quot;检测到使用 squashfs 固件，开始导出文件系统&quot;</span><br><span class="line">    # https://github.com/plougher/squashfs-tools/issues/139#issuecomment-991779738</span><br><span class="line">    # unsquashfs -da 10 -fr 10 /dev/loop0p2</span><br><span class="line">    # 这个解压太耗时了，只能拷贝整了</span><br><span class="line">    mkdir -p /mnt/img_sq</span><br><span class="line">    cp -a /mnt/img/* /mnt/img_sq</span><br><span class="line">    umount /mnt/img/</span><br><span class="line">    rm -rf /mnt/img</span><br><span class="line">    mv /mnt/img_sq /mnt/img</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>然后这个目录写入备份文件，然后就打包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mksquashfs /mnt/img /opt/op.squashfs</span><br></pre></td></tr></table></figure><p>结果打包也经常 oom ，看了下命令的帮助，发现有内存限制的，加上也偶尔 oom</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mksquashfs /mnt/img /opt/op.squashfs -mem 20M </span><br></pre></td></tr></table></figure><p>最后逼我用 <code>oom_score_adj</code> 调整 oom 优先级了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo -998 &gt; /proc/$$/oom_score_adj 2&gt;/dev/null || true</span><br></pre></td></tr></table></figure><p>当然，实际打包很多选项的，可以先利用 <code>unsquashfs</code> 看下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">unsquashfs -s $&#123;lodev&#125;p2 &gt; squashfs.info</span><br><span class="line"></span><br><span class="line">comp=$(awk &#x27;$1==&quot;Compression&quot;&#123;print $2&#125;&#x27; squashfs.info)</span><br><span class="line">sq_block_size=$(awk &#x27;$1==&quot;Block&quot;&#123;print $NF&#125;&#x27; squashfs.info)</span><br><span class="line">xattrs=&#x27;-xattrs&#x27; # CONFIG_SELINUX=y</span><br><span class="line">grep -Eq &#x27;Xattrs.+?not&#x27; squashfs.info &amp;&amp; xattrs=&#x27;-no-xattrs&#x27;</span><br><span class="line"></span><br><span class="line">echo -998 &gt; /proc/$$/oom_score_adj 2&gt;/dev/null || true</span><br><span class="line"></span><br><span class="line">mksquashfs /mnt/img /opt/op.squashfs -comp $&#123;comp&#125; \</span><br><span class="line">    -b $[sq_block_size/1024]k $xattrs -mem 20M</span><br></pre></td></tr></table></figure><p>然后写入到块设备上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dd if=/opt/op.squashfs of=$&#123;lodev&#125;p2</span><br></pre></td></tr></table></figure><p>然后卸载 ${lodev} 刷入固件发现无法开机，在 lede 的源码里 find grep 后找到了 mksquashfs 参数来源于源码下 <code>./include/image.mk</code> 的 <code>SQUASHFSOPT</code> 和 <code>define Image/mkfs/squashfs-common</code></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_TARGET_SQUASHFS_BLOCK_SIZE=1024k</span><br><span class="line">SQUASHFS_BLOCKSIZE := <span class="variable">$(CONFIG_TARGET_SQUASHFS_BLOCK_SIZE)</span>k</span><br><span class="line">SQUASHFSOPT := -b <span class="variable">$(SQUASHFS_BLOCKSIZE)</span></span><br><span class="line">SQUASHFSOPT += -p &#x27;/dev d 755 0 0&#x27; -p &#x27;/dev/console c 600 0 0 5 1&#x27;</span><br><span class="line">SQUASHFSOPT += <span class="variable">$(<span class="built_in">if</span> <span class="variable">$(CONFIG_SELINUX)</span>,-xattrs,-no-xattrs)</span></span><br><span class="line">SQUASHFSCOMP := gzip</span><br><span class="line">LZMA_XZ_OPTIONS := -Xpreset 9 -Xe -Xlc 0 -Xlp 2 -Xpb 2</span><br><span class="line"><span class="keyword">ifeq</span> (<span class="variable">$(CONFIG_SQUASHFS_XZ)</span>,y)</span><br><span class="line">  <span class="keyword">ifneq</span> (<span class="variable">$(<span class="built_in">filter</span> arm x86 powerpc sparc,<span class="variable">$(LINUX_KARCH)</span>)</span>,)</span><br><span class="line">    BCJ_FILTER:=-Xbcj <span class="variable">$(LINUX_KARCH)</span>   <span class="comment"># 例如此处  -Xbcj x86</span></span><br><span class="line">  <span class="keyword">endif</span></span><br><span class="line">  SQUASHFSCOMP := xz <span class="variable">$(LZMA_XZ_OPTIONS)</span> <span class="variable">$(BCJ_FILTER)</span></span><br><span class="line"><span class="keyword">endif</span></span><br></pre></td></tr></table></figure><p>本地搞个编译 openwrt 的时候 make 带上 <code>-V=s</code> 开详细信息看到下面信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> /home/guanzhang/lede/staging_dir/host/bin/mksquashfs4 /home/guanzhang/lede/build_dir/target-aarch64_generic_musl/root-rockchip /home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/root.squashfs -nopad -noappend -root-owned -comp xz -Xpreset 9 -Xe -Xlc 0 -Xlp 2 -Xpb 2  -b 1024k -p <span class="string">&#x27;/dev d 755 0 0&#x27;</span> -p <span class="string">&#x27;/dev/console c 600 0 0 5 1&#x27;</span> -no-xattrs -processors 6</span></span><br><span class="line">Pseudo file &quot;/dev&quot; exists in source filesystem &quot;/home/guanzhang/lede/build_dir/target-aarch64_generic_musl/root-rockchip/dev&quot;.</span><br><span class="line">Ignoring, exclude it (-e/-ef) to override.</span><br><span class="line">Parallel mksquashfs: Using 6 processors</span><br><span class="line">Creating 4.0 filesystem on /home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/root.squashfs, block size 1048576.</span><br><span class="line">[=============================================================-] 8430/8430 100%</span><br><span class="line"></span><br><span class="line">Exportable Squashfs 4.0 filesystem, xz compressed, data block size 1048576</span><br><span class="line">compressed data, compressed metadata, compressed fragments,</span><br><span class="line">no xattrs, compressed ids</span><br><span class="line">duplicates are removed</span><br><span class="line">Filesystem size 135525.99 Kbytes (132.35 Mbytes)</span><br><span class="line">25.39% of uncompressed filesystem size (533693.75 Kbytes)</span><br><span class="line">Inode table size 60908 bytes (59.48 Kbytes)</span><br><span class="line">20.00% of uncompressed inode table size (304503 bytes)</span><br><span class="line">Directory table size 85796 bytes (83.79 Kbytes)</span><br><span class="line">38.42% of uncompressed directory table size (223339 bytes)</span><br><span class="line">Number of duplicate files found 1164</span><br><span class="line">Number of inodes 9212</span><br><span class="line">Number of files 8077</span><br><span class="line">Number of fragments 123</span><br><span class="line">Number of symbolic links  647</span><br><span class="line">Number of device nodes 1</span><br><span class="line">Number of fifo nodes 0</span><br><span class="line">Number of socket nodes 0</span><br><span class="line">Number of directories 487</span><br><span class="line">Number of ids (unique uids + gids) 1</span><br><span class="line">Number of uids 1</span><br><span class="line">root (0)</span><br><span class="line">Number of gids 1</span><br><span class="line">root (0)</span><br></pre></td></tr></table></figure><p>大致参数就是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-nopad -noappend -root-owned -comp xz -Xpreset 9 -Xe -Xlc 0 -Xlp 2 -Xpb 2  -b 1024k -p &#x27;/dev d 755 0 0&#x27; -p &#x27;/dev/console c 600 0 0 5 1&#x27; -no-xattrs -processors 6</span><br></pre></td></tr></table></figure><p>但是 openwrt 和 Centos 上安装的 <code>squashfs-tools</code> 的 mksquashfs xz 压缩时候都没有 <code>-Xpreset 9 -Xe -Xlc 0 -Xlp 2 -Xpb 2</code> 这些参数，后面发现了是 openwrt 编译的时候下载 squashfs-tools 后打了 patch 编译后才有的，不过后面测试这几个选项不影响。同时看到了打包的脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PADDING=1 /home/guanzhang/lede/scripts/gen_image_generic.sh /home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/tmp/openwrt-rockchip-armv8-friendlyarm_nanopi-r2s-squashfs-sysupgrade.img.gz 18 /home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/tmp/openwrt-rockchip-armv8-friendlyarm_nanopi-r2s-squashfs-sysupgrade.img.gz.boot 635 /home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/root.squashfs 32768</span><br></pre></td></tr></table></figure><p>得到了参数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+ dd if=/dev/zero of=/home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/tmp/openwrt-rockchip-armv8-friendlyarm_nanopi-r2s-squashfs-sysupgrade.img.gz bs=512 seek=131072 conv=notrunc count=1300480</span><br><span class="line">1300480+0 records in</span><br><span class="line">1300480+0 records out</span><br><span class="line">665845760 bytes (666 MB, 635 MiB) copied, 2.12896 s, 313 MB/s</span><br><span class="line">+ dd if=/home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/root.squashfs of=/home/guanzhang/lede/build_dir/target-aarch64_generic_musl/linux-rockchip_armv8/tmp/openwrt-rockchip-armv8-friendlyarm_nanopi-r2s-squashfs-sysupgrade.img.gz bs=512 seek=131072 conv=notrunc</span><br></pre></td></tr></table></figure><p>可以看到是直接写 img 文件的，这里虽然显示的是 img.gz ，但是如果压缩后的文件的话，那 seek 大小就不对。实际上后面才压缩的，所以我的参数为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">part2_seek=$(parted /tmp/update/openwrt.img u s p | awk &#x27;$1==2&#123;print +$2&#125;&#x27;)</span><br><span class="line">mksquashfs /mnt/img /opt/op.squashfs -nopad -noappend -root-owned \</span><br><span class="line">    -comp $&#123;comp&#125; $&#123;LZMA_XZ_OPTIONS&#125; \</span><br><span class="line">    -b $[sq_block_size/1024]k \</span><br><span class="line">    -p &#x27;/dev d 755 0 0&#x27; -p &#x27;/dev/console c 600 0 0 5 1&#x27; \</span><br><span class="line">    $xattrs -mem 20M </span><br><span class="line"></span><br><span class="line">losetup -l -O NAME -n | grep -Eqw $lodev &amp;&amp; losetup -d $lodev</span><br><span class="line">dd if=/opt/op.squashfs of=/tmp/update/openwrt.img bs=512 seek=$&#123;part2_seek&#125; conv=notrunc</span><br></pre></td></tr></table></figure><p>然后写入即可</p><h2 id="最终参考"><a href="#最终参考" class="headerlink" title="最终参考"></a>最终参考</h2><p>我的脚本当前存放在 test 分支，可能后续切到 main 分支：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">https://github.com/zhangguanzhang/Actions-OpenWrt/blob/test/build/scripts/update.sh</span><br><span class="line"></span><br><span class="line">https://github.com/zhangguanzhang/Actions-OpenWrt/blob/main/build/scripts/update.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://github.com/klever1988/nanopi-openwrt/raw/master/scripts/autoupdate.sh">1988 的升级脚本</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;手上有 r2s、N1 和 x86_64 的固件维护，r2s 的参照别人的脚本搞了在线升级固件的脚本，别人的脚本只支持 ext4 升级，而后面</summary>
      
    
    
    
    
    <category term="openwrt" scheme="http://zhangguanzhang.github.io/tags/openwrt/"/>
    
    <category term="squashfs" scheme="http://zhangguanzhang.github.io/tags/squashfs/"/>
    
  </entry>
  
  <entry>
    <title>docker数据盘损坏后启动报错 Error starting daemon: Error initializing network controller: Error creating default &quot;bridge&quot; network: package not installed</title>
    <link href="http://zhangguanzhang.github.io/2021/12/12/mod-rejected-by-service/"/>
    <id>http://zhangguanzhang.github.io/2021/12/12/mod-rejected-by-service/</id>
    <published>2021-12-12T23:28:30.000Z</published>
    <updated>2021-12-12T23:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>客户现场的数据盘损坏了，修复启动机器后 docker 无法启动</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@db1 docker]# /data/kube/bin/dockerd</span><br><span class="line">WARN[0000] The &quot;graph&quot; config file option is deprecated. Please use &quot;data-root&quot; instead. </span><br><span class="line">WARN[2021-12-11T21:16:07.917969366+08:00] could not change group /var/run/docker.sock to docker: group docker not found </span><br><span class="line">WARN[2021-12-11T21:16:07.942745757+08:00] failed to load plugin io.containerd.snapshotter.v1.btrfs  error=&quot;path /data/kube/docker/containerd/daemon/io.containerd.snapshotter.v1.btrfs must be a btrfs filesystem to be used with the btrfs snapshotter&quot;</span><br><span class="line">WARN[2021-12-11T21:16:07.944020734+08:00] failed to load plugin io.containerd.snapshotter.v1.aufs  error=&quot;modprobe aufs failed: &quot;modprobe: FATAL: Module aufs not found.\n&quot;: exit status 1&quot;</span><br><span class="line">WARN[2021-12-11T21:16:07.944275670+08:00] failed to load plugin io.containerd.snapshotter.v1.zfs  error=&quot;path /data/kube/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter&quot;</span><br><span class="line">WARN[2021-12-11T21:16:07.944314186+08:00] could not use snapshotter btrfs in metadata plugin  error=&quot;path /data/kube/docker/containerd/daemon/io.containerd.snapshotter.v1.btrfs must be a btrfs filesystem to be used with the btrfs snapshotter&quot;</span><br><span class="line">WARN[2021-12-11T21:16:07.944324941+08:00] could not use snapshotter aufs in metadata plugin  error=&quot;modprobe aufs failed: &quot;modprobe: FATAL: Module aufs not found.\n&quot;: exit status 1&quot;</span><br><span class="line">WARN[2021-12-11T21:16:07.944333098+08:00] could not use snapshotter zfs in metadata plugin  error=&quot;path /data/kube/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter&quot;</span><br><span class="line">WARN[2021-12-11T21:16:09.131994686+08:00] Running modprobe bridge br_netfilter failed with message: modprobe: ERROR: could not insert &#x27;bridge&#x27;: Key was rejected by service</span><br><span class="line">modprobe: ERROR: could not insert &#x27;br_netfilter&#x27;: Key was rejected by service</span><br><span class="line">insmod /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko </span><br><span class="line">insmod /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko </span><br><span class="line">, error: exit status 1 </span><br><span class="line">Error starting daemon: Error initializing network controller: Error creating default &quot;bridge&quot; network: package not installed</span><br></pre></td></tr></table></figure><h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><h3 id="相关信息"><a href="#相关信息" class="headerlink" title="相关信息"></a>相关信息</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ dockerd --version</span><br><span class="line">Docker version 18.09.3, build 774a1f4</span><br><span class="line">$ uname -a </span><br><span class="line">Linux db1 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br><span class="line">$ cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.3.1611 (Core) </span><br></pre></td></tr></table></figure><h3 id="处理过程"><a href="#处理过程" class="headerlink" title="处理过程"></a>处理过程</h3><p>先看下是不是把内核模块禁止了，发现没禁止，手动加载也报错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep -r black /etc/modprobe.d/*.conf</span><br><span class="line">$ modprobe overlay</span><br><span class="line">$ modprobe bridge</span><br><span class="line">modprobe: ERROR: could not insert &#x27;bridge&#x27;: Key was rejected by service</span><br></pre></td></tr></table></figure><p>查看下也没开启 <code>enforcemodulesig</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ dmesg | grep enforcemodulesig=1</span><br><span class="line">$ cat /proc/cmdline </span><br><span class="line">BOOT_IMAGE=/vmlinuz-3.10.0-514.el7.x86_64 root=UUID=5ab681a0-7e5c-4ab7-9c88-27d788f725b3 ro crashkernel=auto rhgb quiet LANG=en_US.UTF-8</span><br></pre></td></tr></table></figure><p>但是能查看到内核模块信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ modinfo bridge</span><br><span class="line">filename:       /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko</span><br><span class="line">alias:          rtnl-link-bridge</span><br><span class="line">version:        2.3</span><br><span class="line">license:        GPL</span><br><span class="line">rhelversion:    7.3</span><br><span class="line">srcversion:     FF0448CD85C271287DE1963</span><br><span class="line">depends:        stp,llc</span><br><span class="line">intree:         Y</span><br><span class="line">vermagic:       3.10.0-514.el7.x86_64 SMP mod_unload modversions </span><br><span class="line">signer:         CentOS Linux kernel signing key</span><br><span class="line">sig_key:        D4:88:63:A7:C1:6F:CC:27:41:23:E6:29:8F:74:F0:57:AF:19:FC:54</span><br><span class="line">sig_hashalgo:   sha256</span><br></pre></td></tr></table></figure><p>感觉是内核签名对不上，查看下模块哈希</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ md5sum /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko</span><br><span class="line">62001928100a30bace9bc6493b956e2f  /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko</span><br></pre></td></tr></table></figure><p>找了另一台机器对比下，发现模块损坏了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ uname -a</span><br><span class="line">Linux db2 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br><span class="line">$ modinfo bridge</span><br><span class="line">filename:       /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko</span><br><span class="line">alias:          rtnl-link-bridge</span><br><span class="line">version:        2.3</span><br><span class="line">license:        GPL</span><br><span class="line">rhelversion:    7.3</span><br><span class="line">srcversion:     FF0448CD85C271287DE1963</span><br><span class="line">depends:        stp,llc</span><br><span class="line">intree:         Y</span><br><span class="line">vermagic:       3.10.0-514.el7.x86_64 SMP mod_unload modversions </span><br><span class="line">signer:         CentOS Linux kernel signing key</span><br><span class="line">sig_key:        D4:88:63:A7:C1:6F:CC:27:41:23:E6:29:8F:74:F0:57:AF:19:FC:54</span><br><span class="line">sig_hashalgo:   sha256</span><br><span class="line">$ md5sum /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko</span><br><span class="line">41c62afa67e66d107cc2a9e471910726  /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko</span><br></pre></td></tr></table></figure><p>修复</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/</span><br><span class="line">cp bridge.ko bridge.ko.bak</span><br><span class="line">scp root@xxxx:/lib/modules/3.10.0-514.el7.x86_64/kernel/net/bridge/bridge.ko .</span><br></pre></td></tr></table></figure><p>然后能启动了</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.oracle.com/technical-resources/articles/linux/signed-kernel-modules.html">https://www.oracle.com/technical-resources/articles/linux/signed-kernel-modules.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;客户现场的数据盘损坏了，修复启动机器后 docker 无法启动&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext</summary>
      
    
    
    
    
    <category term="docker" scheme="http://zhangguanzhang.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>1.15 kubelet 在 nodefs 容量富裕下循环 reclaim ephemeral-storage</title>
    <link href="http://zhangguanzhang.github.io/2021/10/29/kubelet-ephemeral-storage-loop-evicted/"/>
    <id>http://zhangguanzhang.github.io/2021/10/29/kubelet-ephemeral-storage-loop-evicted/</id>
    <published>2021-10-29T14:08:06.000Z</published>
    <updated>2021-10-29T14:08:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="故障"><a href="#故障" class="headerlink" title="故障"></a>故障</h2><p>现场 k8s node 很多 pod 都被硬性驱逐显示 <code>Evicted</code> ，现场人员查看分区容量和 inode 都正常，但是一直 <code>reclaim ephemeral-storage</code>。</p><h2 id="处理"><a href="#处理" class="headerlink" title="处理"></a>处理</h2><h3 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">$ uname -a</span><br><span class="line">Linux xxx-2 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</span><br><span class="line">$ cat /etc/os-release</span><br><span class="line">CentOS Linux release 7.4.1708 (Core) </span><br><span class="line">$ kubectl version -o json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;clientVersion&quot;: &#123;</span><br><span class="line">    &quot;major&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;minor&quot;: &quot;15&quot;,</span><br><span class="line">    &quot;gitVersion&quot;: &quot;v1.15.5&quot;,</span><br><span class="line">    &quot;gitCommit&quot;: &quot;20c265fef0741dd71a66480e35bd69f18351daea&quot;,</span><br><span class="line">    &quot;gitTreeState&quot;: &quot;clean&quot;,</span><br><span class="line">    &quot;buildDate&quot;: &quot;2019-10-15T19:16:51Z&quot;,</span><br><span class="line">    &quot;goVersion&quot;: &quot;go1.12.10&quot;,</span><br><span class="line">    &quot;compiler&quot;: &quot;gc&quot;,</span><br><span class="line">    &quot;platform&quot;: &quot;linux/amd64&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;serverVersion&quot;: &#123;</span><br><span class="line">    &quot;major&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;minor&quot;: &quot;15&quot;,</span><br><span class="line">    &quot;gitVersion&quot;: &quot;v1.15.5&quot;,</span><br><span class="line">    &quot;gitCommit&quot;: &quot;20c265fef0741dd71a66480e35bd69f18351daea&quot;,</span><br><span class="line">    &quot;gitTreeState&quot;: &quot;clean&quot;,</span><br><span class="line">    &quot;buildDate&quot;: &quot;2019-10-15T19:07:57Z&quot;,</span><br><span class="line">    &quot;goVersion&quot;: &quot;go1.12.10&quot;,</span><br><span class="line">    &quot;compiler&quot;: &quot;gc&quot;,</span><br><span class="line">    &quot;platform&quot;: &quot;linux/amd64&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">$ docker info</span><br><span class="line">Containers: 5</span><br><span class="line"> Running: 4</span><br><span class="line"> Paused: 0</span><br><span class="line"> Stopped: 1</span><br><span class="line">Images: 40</span><br><span class="line">Server Version: 18.09.3</span><br><span class="line">Storage Driver: overlay2</span><br><span class="line"> Backing Filesystem: xfs</span><br><span class="line"> Supports d_type: true</span><br><span class="line"> Native Overlay Diff: true</span><br><span class="line">Logging Driver: json-file</span><br><span class="line">Cgroup Driver: cgroupfs</span><br><span class="line">Plugins:</span><br><span class="line"> Volume: local</span><br><span class="line"> Network: bridge host macvlan null overlay</span><br><span class="line"> Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line">Swarm: inactive</span><br><span class="line">Runtimes: runc</span><br><span class="line">Default Runtime: runc</span><br><span class="line">Init Binary: docker-init</span><br><span class="line">containerd version: e6b3f5632f50dbc4e9cb6288d911bf4f5e95b18e</span><br><span class="line">runc version: 6635b4f0c6af3810594d2770f662f34ddc15b40d</span><br><span class="line">init version: fec3683</span><br><span class="line">Security Options:</span><br><span class="line"> seccomp</span><br><span class="line">  Profile: default</span><br><span class="line">Kernel Version: 3.10.0-693.el7.x86_64</span><br><span class="line">Operating System: CentOS Linux 7 (Core)</span><br><span class="line">OSType: linux</span><br><span class="line">Architecture: x86_64</span><br><span class="line">CPUs: 32</span><br><span class="line">Total Memory: 62.91GiB</span><br><span class="line">Name: SCJY-2</span><br><span class="line">ID: XZ33:PHUQ:U2CI:7PXH:SYFG:Y6LK:3K3U:XXM6:QJWP:U3B3:MW4M:XPJS</span><br><span class="line">Docker Root Dir: /data/kube/docker</span><br><span class="line">Debug Mode (client): false</span><br><span class="line">Debug Mode (server): false</span><br><span class="line">Registry: https://index.docker.io/v1/</span><br><span class="line">Labels:</span><br><span class="line">Experimental: false</span><br><span class="line">Insecure Registries:</span><br><span class="line"> reg.xxx.lan:5000</span><br><span class="line"> treg.yun.xxx.cn</span><br><span class="line"> 127.0.0.0/8</span><br><span class="line">Registry Mirrors:</span><br><span class="line"> https://registry.docker-cn.com/</span><br><span class="line"> https://docker.mirrors.ustc.edu.cn/</span><br><span class="line">Live Restore Enabled: false</span><br><span class="line">Product License: Community Engine</span><br></pre></td></tr></table></figure><h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><p>向日葵远程上去看了下，根分区容量都是正常的，inode 也是。看了下 <code>uptime -s</code> 重启过，现场说重启过还是没用。重启 kubelet 的话，看了下还是一直 <code>reclaim ephemeral-storage</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">$ du -h</span><br><span class="line">Filesystem                 Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/rootvg-lvroot   30G  5.2G   25G  18% /</span><br><span class="line">devtmpfs                    32G     0   32G   0% /dev</span><br><span class="line">tmpfs                       32G  160K   32G   1% /dev/shm</span><br><span class="line">tmpfs                       32G   26M   32G   1% /run</span><br><span class="line">tmpfs                       32G     0   32G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sdb                   600G   36G  565G   6% /data</span><br><span class="line">/dev/sda1                 1014M  160M  855M  16% /boot</span><br><span class="line">/dev/mapper/rootvg-lvopt    10G   33M   10G   1% /opt</span><br><span class="line">/dev/mapper/rootvg-lvhome 1014M   39M  976M   4% /home</span><br><span class="line">/dev/mapper/rootvg-lvvar   2.0G  1.2G  888M  57% /var</span><br><span class="line">overlay                    600G   36G  565G   6% /data/kube/docker/overlay2/788ee4620da0a3f76ef5f4b24755a68de0e66c8f2425d8332d5a792116d7659f/merged</span><br><span class="line">overlay                    600G   36G  565G   6% /data/kube/docker/overlay2/d2b5f08e9873f5c9365aaf57eeca492734631a3842ccb2f379aa89998b0c7304/merged</span><br><span class="line">overlay                    600G   36G  565G   6% /data/kube/docker/overlay2/c4793b6c3f774cc960ef23e18b61405040698be698306ee993d4d501bdcf485a/merged</span><br><span class="line">overlay                    600G   36G  565G   6% /data/kube/docker/overlay2/b5a0fc544935db77c92bd978db9c1c7018e5e09bba9d2bf53bd300e96c656cec/merged</span><br><span class="line">shm                         64M     0   64M   0% /data/kube/docker/containers/ad86ab9b01e1ce0d62e1f98249274d9bfe75eca6efd8ce0e8f1c591d5570d75f/mounts/shm</span><br><span class="line">shm                         64M     0   64M   0% /data/kube/docker/containers/e3ebeac9a82264869429f44ea6834bcbc94b79013621490c071ef002b4b8e90e/mounts/shm</span><br><span class="line">shm                         64M     0   64M   0% /data/kube/docker/containers/a917bd3b8006198a58900efb5c82c6e162cfc4e732c7e588eaadfb59294ea22b/mounts/shm</span><br><span class="line">shm                         64M     0   64M   0% /data/kube/docker/containers/aa52df1894ad495f4f269d77ddd90954fdc7bbd0fbf25d9d4aa0674a76ff6a6c/mounts/shm</span><br><span class="line">tmpfs                      6.3G   12K  6.3G   1% /run/user/42</span><br><span class="line">tmpfs                      6.3G     0  6.3G   0% /run/user/1003</span><br><span class="line">tmpfs                      6.3G     0  6.3G   0% /run/user/1000</span><br><span class="line"></span><br><span class="line">$ dh -i</span><br><span class="line">Filesystem                   Inodes  IUsed     IFree IUse% Mounted on</span><br><span class="line">/dev/mapper/rootvg-lvroot  15726592 184878  15541714    2% /</span><br><span class="line">devtmpfs                    8242230    527   8241703    1% /dev</span><br><span class="line">tmpfs                       8246150     41   8246109    1% /dev/shm</span><br><span class="line">tmpfs                       8246150    735   8245415    1% /run</span><br><span class="line">tmpfs                       8246150     16   8246134    1% /sys/fs/cgroup</span><br><span class="line">/dev/sdb                  314572800 303816 314268984    1% /data</span><br><span class="line">/dev/sda1                    524288    327    523961    1% /boot</span><br><span class="line">/dev/mapper/rootvg-lvopt    5242880      7   5242873    1% /opt</span><br><span class="line">/dev/mapper/rootvg-lvhome    524288    397    523891    1% /home</span><br><span class="line">/dev/mapper/rootvg-lvvar    1048576  10179   1038397    1% /var</span><br><span class="line">overlay                   314572800 303816 314268984    1% /data/kube/docker/overlay2/788ee4620da0a3f76ef5f4b24755a68de0e66c8f2425d8332d5a792116d7659f/merged</span><br><span class="line">overlay                   314572800 303816 314268984    1% /data/kube/docker/overlay2/d2b5f08e9873f5c9365aaf57eeca492734631a3842ccb2f379aa89998b0c7304/merged</span><br><span class="line">overlay                   314572800 303816 314268984    1% /data/kube/docker/overlay2/c4793b6c3f774cc960ef23e18b61405040698be698306ee993d4d501bdcf485a/merged</span><br><span class="line">overlay                   314572800 303816 314268984    1% /data/kube/docker/overlay2/b5a0fc544935db77c92bd978db9c1c7018e5e09bba9d2bf53bd300e96c656cec/merged</span><br><span class="line">shm                         8246150      1   8246149    1% /data/kube/docker/containers/ad86ab9b01e1ce0d62e1f98249274d9bfe75eca6efd8ce0e8f1c591d5570d75f/mounts/shm</span><br><span class="line">shm                         8246150      1   8246149    1% /data/kube/docker/containers/e3ebeac9a82264869429f44ea6834bcbc94b79013621490c071ef002b4b8e90e/mounts/shm</span><br><span class="line">shm                         8246150      1   8246149    1% /data/kube/docker/containers/a917bd3b8006198a58900efb5c82c6e162cfc4e732c7e588eaadfb59294ea22b/mounts/shm</span><br><span class="line">shm                         8246150      1   8246149    1% /data/kube/docker/containers/aa52df1894ad495f4f269d77ddd90954fdc7bbd0fbf25d9d4aa0674a76ff6a6c/mounts/shm</span><br><span class="line">tmpfs                       8246150      9   8246141    1% /run/user/42</span><br><span class="line">tmpfs                       8246150      1   8246149    1% /run/user/1003</span><br><span class="line">tmpfs                       8246150      1   8246149    1% /run/user/1000</span><br><span class="line"></span><br><span class="line">$ kubectl describe node xx.xx.112.135</span><br><span class="line">...</span><br><span class="line">Capacity:</span><br><span class="line"> cpu:                32</span><br><span class="line"> ephemeral-storage:  2038Mi</span><br><span class="line"> hugepages-2Mi:      0</span><br><span class="line"> memory:             65969200Ki</span><br><span class="line"> pods:               110</span><br><span class="line">Allocatable:</span><br><span class="line"> cpu:                31800m</span><br><span class="line"> ephemeral-storage:  1014Mi</span><br><span class="line"> hugepages-2Mi:      0</span><br><span class="line"> memory:             65469200Ki</span><br><span class="line"> pods:               110</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason                   Age                      From                    Message</span><br><span class="line">  ----     ------                   ----                     ----                    -------</span><br><span class="line">  Warning  EvictionThresholdMet     3m57s (x1434 over 4h3m)  kubelet, xx.xx.112.135  Attempting to reclaim ephemeral-storage</span><br><span class="line">  Normal   Starting                 37s                      kubelet, xx.xx.112.135  Starting kubelet.</span><br><span class="line">  Normal   NodeHasSufficientMemory  37s                      kubelet, xx.xx.112.135  Node xx.xx.112.135 status is now: NodeHasSufficientMemory</span><br><span class="line">  Normal   NodeHasNoDiskPressure    37s (x2 over 37s)        kubelet, xx.xx.112.135  Node xx.xx.112.135 status is now: NodeHasNoDiskPressure</span><br><span class="line">  Normal   NodeHasSufficientPID     37s                      kubelet, xx.xx.112.135  Node xx.xx.112.135 status is now: NodeHasSufficientPID</span><br><span class="line">  Normal   NodeNotReady             37s                      kubelet, xx.xx.112.135  Node xx.xx.112.135 status is now: NodeNotReady</span><br><span class="line">  Normal   NodeAllocatableEnforced  37s                      kubelet, xx.xx.112.135  Updated Node Allocatable <span class="built_in">limit</span> across pods</span><br><span class="line">  Normal   NodeReady                37s                      kubelet, xx.xx.112.135  Node xx.xx.112.135 status is now: NodeReady</span><br><span class="line">  Normal   NodeHasDiskPressure      27s                      kubelet, xx.xx.112.135  Node xx.xx.112.135 status is now: NodeHasDiskPressure</span><br><span class="line">  Warning  EvictionThresholdMet     7s (x4 over 37s)         kubelet, xx.xx.112.135  Attempting to reclaim ephemeral-storage</span><br></pre></td></tr></table></figure><p>看了一会儿后发现上面的 <code>ephemeral-storage</code> 不对，<code>Capacity</code> 居然是 <code>2038Mi</code> 。</p><h3 id="源码的一些探索"><a href="#源码的一些探索" class="headerlink" title="源码的一些探索"></a>源码的一些探索</h3><p>本地开发环境起了下 kubelet 调试了下，一些信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">./build/run.sh make kubelet GOFLAGS=&quot;-v -tags=nokmem&quot; GOGCFLAGS=&quot;all=-N -l&quot;  KUBE_BUILD_PLATFORMS=linux/amd64</span><br><span class="line"></span><br><span class="line">cp  _output/dockerized/bin/linux/amd64/kubelet .</span><br><span class="line"></span><br><span class="line">dlv exec --check-go-version=false ./kubelet  -- --cgroup-driver=systemd</span><br><span class="line"></span><br><span class="line"># 推荐下面两个断点</span><br><span class="line">vendor/github.com/google/cadvisor/container/docker/handler.go#L421</span><br><span class="line"></span><br><span class="line">vendor/github.com/google/cadvisor/container/docker/handler.go:364</span><br><span class="line"></span><br><span class="line">   724:func (self *manager) GetFsInfo(label string) ([]v2.FsInfo, error) &#123;</span><br><span class="line">=&gt; 725:var empty time.Time</span><br><span class="line">   726:// Get latest data from filesystems hanging off root container.</span><br><span class="line">   727:stats, err := self.memoryCache.RecentStats(&quot;/&quot;, empty, empty, 1)</span><br><span class="line">   728:if err != nil &#123;</span><br><span class="line">   729:return nil, err</span><br><span class="line">   730:&#125;</span><br><span class="line">(dlv) so</span><br><span class="line">&gt; k8s.io/kubernetes/vendor/github.com/google/cadvisor/manager.(*manager).getFsInfoByDeviceName() _output/dockerized/go/src/k8s.io/kubernetes/vendor/github.com/google/cadvisor/manager/manager.go:1311 (PC: 0x1fc7180)</span><br><span class="line">Values returned:</span><br><span class="line">~r1: []k8s.io/kubernetes/vendor/github.com/google/cadvisor/info/v2.FsInfo len: 2, cap: 2, [</span><br><span class="line">&#123;</span><br><span class="line">Timestamp: (*time.Time)(0xc0002262d0),</span><br><span class="line">Device: &quot;/dev/sda1&quot;,</span><br><span class="line">Mountpoint: &quot;/&quot;,</span><br><span class="line">Capacity: 75150372864,</span><br><span class="line">Available: 36613033984,</span><br><span class="line">Usage: 38537338880,</span><br><span class="line">Labels: []string len: 2, cap: 2, [</span><br><span class="line">&quot;docker-images&quot;,</span><br><span class="line">&quot;root&quot;,</span><br><span class="line">],</span><br><span class="line">Inodes: *36699584,</span><br><span class="line">InodesFree: *35850609,&#125;,</span><br><span class="line">&#123;</span><br><span class="line">Timestamp: (*time.Time)(0xc000226348),</span><br><span class="line">Device: &quot;tmpfs&quot;,</span><br><span class="line">Mountpoint: &quot;/dev/shm&quot;,</span><br><span class="line">Capacity: 1986203648,</span><br><span class="line">Available: 1986203648,</span><br><span class="line">Usage: 0,</span><br><span class="line">Labels: []string len: 0, cap: 0, [],</span><br><span class="line">Inodes: *484913,</span><br><span class="line">InodesFree: *484912,&#125;,</span><br><span class="line">]</span><br><span class="line">~r2: error nil</span><br></pre></td></tr></table></figure><p>容量这部分我现场通过特性 <code>--feature-gates=LocalStorageCapacityIsolation=false</code> 后删掉 node restart 后 describe 看不到 <code>ephemeral-storage</code> 了，但是还是问题还在，看了下源码，这个容量大小是 <code>vendor/github.com/google/cadvisor/container/docker</code> 下从 docker 获取的，嵌套的 interface 太多了，查看麻烦。现场是已经重启过机器了，docker 我重启和查看日志也没啥有用的地方。</p><h3 id="最终解决"><a href="#最终解决" class="headerlink" title="最终解决"></a>最终解决</h3><p><code>ephemeral-storage</code> 这个 limit 是 1.15 alpha 的，暂时不想折腾了。 尝试换下 kubelet 的 root 目录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl cat kubelet</span><br><span class="line"># /etc/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">...</span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">ExecStart=/data/kube/bin/kubelet \</span><br><span class="line">  ...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>主要修改 <code>WorkingDirectory</code> 和给 kubelet 增加参数 <code>--root-dir</code> 以及 <code>--docker-root</code> ，现场 <code>/data</code> 是单独分区的，切到 <code>/data/kube/kubelet</code> 下，<code>--docker-root</code> 则是 docker 的 <code>data-root</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/systemd/system/kubelet.service</span><br><span class="line">...</span><br><span class="line">WorkingDirectory=/data/kube/kubelet</span><br><span class="line">ExecStart=/data/kube/bin/kubelet \</span><br><span class="line">  --root-dir=/data/kube/kubelet \</span><br><span class="line">  --docker-root=/data/kube/docker \</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure><p>问题解决。后面才发现 /var 是单独分区的，客户现场动过分区表，之前是 /var 没有单独分区，后面他们创建了个 lv 并写在 /etc/fstab 里，并没有挂载和重启。一周前他们重启了下，而且有一些服务在 /var/log 输出日志，所以造成了这次故障。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://github.com/kubernetes/kubernetes/tree/v1.15.5/vendor/github.com/google/cadvisor/manager/manager.go#L724">https://github.com/kubernetes/kubernetes/tree/v1.15.5/vendor/github.com/google/cadvisor/manager/manager.go#L724</a></li><li><a href="https://github.com/kubernetes/kubernetes/tree/v1.15.5/vendor/github.com/google/cadvisor/container/libcontainer/handler.go">https://github.com/kubernetes/kubernetes/tree/v1.15.5/vendor/github.com/google/cadvisor/container/libcontainer/handler.go</a></li><li><a href="https://github.com/kubernetes/kubernetes/tree/v1.15.5/vendor/github.com/docker/docker/pkg/mount/mountinfo_linux.go">https://github.com/kubernetes/kubernetes/tree/v1.15.5/vendor/github.com/docker/docker/pkg/mount/mountinfo_linux.go</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;故障&quot;&gt;&lt;a href=&quot;#故障&quot; class=&quot;headerlink&quot; title=&quot;故障&quot;&gt;&lt;/a&gt;故障&lt;/h2&gt;&lt;p&gt;现场 k8s node 很多 pod 都被硬性驱逐显示 &lt;code&gt;Evicted&lt;/code&gt; ，现场人员查看分区容量和 inode 都正</summary>
      
    
    
    
    
    <category term="kubelet" scheme="http://zhangguanzhang.github.io/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>在非容器环境上实现散装的 IPVS SVC</title>
    <link href="http://zhangguanzhang.github.io/2021/09/28/ipvs-svc/"/>
    <id>http://zhangguanzhang.github.io/2021/09/28/ipvs-svc/</id>
    <published>2021-09-28T19:28:30.000Z</published>
    <updated>2021-09-28T19:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>内部有非 K8S 环境上需要类似 SVC 的负载实现，一开始是用 NGINX 做的，所有 SVC 域名都解析成一个 dummy IP ，然后 NGINX 根据 <code>server_name</code> 去 proxy 不同的 upstream 。 开始还是能用的，结果后面很多服务依赖 <code>host</code> 这个 header ，报错签名错误，而且毕竟这样是在用户态，效率不如内核态高。于是打算搞下之前的打算：把 IPVS 的 <code>ClusterIP</code> 的 SVC 扣到非 K8S 环境上使用。</p><p>kube-proxy 的 SVC 简单讲就是 node 上任何进程访问 <code>SVC IP:SVC PORT</code> 会被 dnat 成 <code>endpoint</code> ，是工作在内核态的四层负载，不会在机器上看到端口监听，而默认非集群的机器是无法访问 SVC IP 。在 K8S 里，endpoint 的 ip 无非就是 <code>POD IP</code>，<code>host IP</code>。前者就是 SVC 选中 POD ，后者例如 <code>kubernetes</code> 这个 SVC ，会 DNAT 成每个 <code>kube-apiserver</code> 的 <code>host IP:6443</code> 端口，也可能是 <code>ExternalName</code> 或者手动创建的 endpoint 。既然 <code>kubernetes</code> 这个 SVC 可以。那我的打算应该也是可以实现的。但是一开始实际按照思路试了下发现不行，网上的文章基本都是在单机 docker 或者现有的 K8S 环境上搞的，漏掉了很多精华和核心思想，这里记录下我的思路和实现过程。</p><h2 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h2><p>前面说的 SVC 现象是和 <code>kube-proxy</code> 的模式无关的。<code>iptables</code> 模式排查不直观，我更倾向于 <code>IPVS</code> 去搞，它更直观，而且支持更多的调度算法。管理 IPVS 规则的话我们需要安装 <code>ipvsadm</code> ，这里我是两台干净的 CentOS 7.8 来做环境。</p><table><thead><tr><th align="left">IP</th></tr></thead><tbody><tr><td align="left">192.168.2.111</td></tr><tr><td align="left">192.168.2.222</td></tr></tbody></table><p>先安装下基础需要的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ipvsadm curl wget tcpdump ipset conntrack-tools</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启转发</span></span><br><span class="line"></span><br><span class="line">sysctl -w net.ipv4.ip_forward=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确认 iptables 规则清空</span></span><br><span class="line">$ iptables -S</span><br><span class="line">-P INPUT ACCEPT</span><br><span class="line">-P FORWARD ACCEPT</span><br><span class="line">-P OUTPUT ACCEPT</span><br><span class="line">$ iptables -t nat -S</span><br><span class="line">-P PREROUTING ACCEPT</span><br><span class="line">-P INPUT ACCEPT</span><br><span class="line">-P OUTPUT ACCEPT</span><br><span class="line">-P POSTROUTING ACCEPT</span><br></pre></td></tr></table></figure><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>先思考下 kube-proxy 的 IPVS ，因为 SVC 端口和 POD 的端口不一样，所以 kube-proxy 使用的 <code>nat</code> 模式。暂且打算添加一个下面类似的 SVC ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IP:                169.254.11.2</span><br><span class="line">Port:              https  80/TCP</span><br><span class="line">TargetPort:        8080/TCP</span><br><span class="line">Endpoints:         192.168.2.111:8080,192.168.2.222:8080</span><br><span class="line">Session Affinity:  None</span><br></pre></td></tr></table></figure><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>web 的话我是使用的 golang 的一个简单 web 二进制起的 <a href="https://github.com/m3ng9i/ran">ran</a> :</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/m3ng9i/ran/releases/download/v0.1.6/ran_linux_amd64.zip</span><br><span class="line">unzip -x ran_linux_amd64.zip</span><br><span class="line">mkdir www</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两个机器创建不同的 index 文件</span></span><br><span class="line"><span class="built_in">echo</span> 192.168.2.111 &gt; www/<span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> 192.168.2.222 &gt; www/<span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">./ran_linux_amd64 -port 8080 -listdir www</span><br></pre></td></tr></table></figure><p>两个机器的这个 web 都起来后我们开个窗口去 <code>192.168.2.111</code> 上继续后面的操作。</p><h3 id="lvs-nat"><a href="#lvs-nat" class="headerlink" title="lvs nat"></a>lvs nat</h3><p>kube-proxy 并没有像 lvs nat 那样有单独的机器做 <code>NAT GW</code>，或者认为每个 node 都是自己的 <code>NAT GW</code>。现在来添加 <code>169.254.11.2:80</code> 这个 SVC ，使用 ipvsadm 添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm --add-service --tcp-service 169.254.11.2:80 --scheduler rr</span><br></pre></td></tr></table></figure><p>先添加本地的 web 作为 real server ，下面含义是添加为一个 nat 类型的 real server ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm --add-server --tcp-service 169.254.11.2:80 \</span><br><span class="line">  --real-server 192.168.2.111:8080 --masquerading --weight 1</span><br></pre></td></tr></table></figure><p>查看下当前列表：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ipvsadm -ln</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  169.254.11.2:80 rr</span><br><span class="line">  -&gt; 192.168.2.111:8080           Masq    1      0          0 </span><br></pre></td></tr></table></figure><p>因为是自己的 <code>NAT GW</code>，所以 VIP 配置在自己身上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip addr add 169.254.11.2/32 dev eth0</span><br></pre></td></tr></table></figure><p>测试下访问看看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br></pre></td></tr></table></figure><p>添加上另一个节点的 8080：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ipvsadm --add-server --tcp-service 169.254.11.2:80 \</span><br><span class="line">  --real-server 192.168.2.222:8080 --masquerading --weight 1</span><br><span class="line"></span><br><span class="line">$ ipvsadm -ln</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  169.254.11.2:80 rr</span><br><span class="line">  -&gt; 192.168.2.111:8080           Masq    1      0          0         </span><br><span class="line">  -&gt; 192.168.2.222:8080           Masq    1      0          0</span><br></pre></td></tr></table></figure><p>测试下访问看看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>发现 curl 在卡住和能访问返回 <code>192.168.2.111</code> 之间切换，没有返回 <code>192.168.2.222</code> 的。查看下 IPVS 的 connection ，发现调度到非本机才会卡住：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ipvsadm -lnc</span><br><span class="line">IPVS connection entries</span><br><span class="line">pro expire state       <span class="built_in">source</span>             virtual            destination</span><br><span class="line">TCP 00:48  SYN_RECV    169.254.11.2:50698 169.254.11.2:80    192.168.2.222:8080</span><br></pre></td></tr></table></figure><p>在 <code>192.168.2.222</code> 上抓包看看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -i eth0 port 8080</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv <span class="keyword">for</span> full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">07:38:26.360716 IP 169.254.11.2.50710 &gt; 192.168.2.222.8080: Flags [S], seq 768065283, win 43690, options [mss 65495,sackOK,TS val 12276183 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:38:26.360762 IP 192.168.2.222.8080 &gt; 169.254.11.2.50710: Flags [S.], seq 2142784980, ack 768065284, win 28960, options [mss 1460,sackOK,TS val 676518144 ecr 12276183,nop,wscale 7], length 0</span><br><span class="line">07:38:27.362848 IP 169.254.11.2.50710 &gt; 192.168.2.222.8080: Flags [S], seq 768065283, win 43690, options [mss 65495,sackOK,TS val 12277186 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:38:27.362884 IP 192.168.2.222.8080 &gt; 169.254.11.2.50710: Flags [S.], seq 2142784980, ack 768065284, win 28960, options [mss 1460,sackOK,TS val 676519146 ecr 12276183,nop,wscale 7], length 0</span><br><span class="line">07:38:28.562629 IP 192.168.2.222.8080 &gt; 169.254.11.2.50710: Flags [S.], seq 2142784980, ack 768065284, win 28960, options [mss 1460,sackOK,TS val 676520346 ecr 12276183,nop,wscale 7], length 0</span><br><span class="line">07:38:29.368811 IP 169.254.11.2.50710 &gt; 192.168.2.222.8080: Flags [S], seq 768065283, win 43690, options [mss 65495,sackOK,TS val 12279192 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:38:29.368853 IP 192.168.2.222.8080 &gt; 169.254.11.2.50710: Flags [S.], seq 2142784980, ack 768065284, win 28960, options [mss 1460,sackOK,TS val 676521152 ecr 12276183,nop,wscale 7], length 0</span><br><span class="line">07:38:31.562633 IP 192.168.2.222.8080 &gt; 169.254.11.2.50710: Flags [S.], seq 2142784980, ack 768065284, win 28960, options [mss 1460,sackOK,TS val 676523346 ecr 12276183,nop,wscale 7], length 0</span><br><span class="line">07:38:33.376829 IP 169.254.11.2.50710 &gt; 192.168.2.222.8080: Flags [S], seq 768065283, win 43690, options [mss 65495,sackOK,TS val 12283200 ecr 0,nop,wscale 7], length 0</span><br><span class="line">07:38:33.376869 IP 192.168.2.222.8080 &gt; 169.254.11.2.50710: Flags [S.], seq 2142784980, ack 768065284, win 28960, options [mss 1460,sackOK,TS val 676525160 ecr 12276183,nop,wscale 7], length 0</span><br><span class="line">07:38:37.562632 IP 192.168.2.222.8080 &gt; 169.254.11.2.50710: Flags [S.], seq 2142784980, ack 768065284, win 28960, options [mss 1460,sackOK,TS val 676529346 ecr 12276183,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure><p>从 <code>Flags</code> 看，就是 tcp 重传，并且 <code>SRC IP</code> 是 VIP 。节点 <code>192.168.2.222.8080</code> 给 <code>169.254.11.2.50710</code> 回包会走到网关上去。网关上抓包也看到确实如此：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -i eth0 host 169.254.11.2</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv <span class="keyword">for</span> full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">19:39:47.487362 IP 192.168.2.222.8080 &gt; 169.254.11.2.50714: Flags [S.], seq 4149799699, ack 251479303, win 28960, options [mss 1460,sackOK,TS val 676599263 ecr 12357303,nop,wscale 7], length 0</span><br><span class="line">19:39:47.487405 IP 192.168.2.222.8080 &gt; 169.254.11.2.50714: Flags [S.], seq 4149799699, ack 251479303, win 28960, options [mss 1460,sackOK,TS val 676599263 ecr 12357303,nop,wscale 7], length 0</span><br><span class="line">19:39:48.487838 IP 192.168.2.222.8080 &gt; 169.254.11.2.50714: Flags [S.], seq 4149799699, ack 251479303, win 28960, options [mss 1460,sackOK,TS val 676600264 ecr 12357303,nop,wscale 7], length 0</span><br><span class="line">19:39:48.487868 IP 192.168.2.222.8080 &gt; 169.254.11.2.50714: Flags [S.], seq 4149799699, ack 251479303, win 28960, options [mss 1460,sackOK,TS val 676600264 ecr 12357303,nop,wscale 7], length 0</span><br><span class="line">19:39:49.569667 IP 192.168.2.222.8080 &gt; 169.254.11.2.50714: Flags [S.], seq 4149799699, ack 251479303, win 28960, options [mss 1460,sackOK,TS val 676601346 ecr 12357303,nop,wscale 7], length 0</span><br><span class="line">19:39:49.569699 IP 192.168.2.222.8080 &gt; 169.254.11.2.50714: Flags [S.], seq 4149799699, ack 251479303, win 28960, options [mss 1460,sackOK,TS val 676601346 ecr 12357303,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure><h4 id="lvs-和-netfilter"><a href="#lvs-和-netfilter" class="headerlink" title="lvs 和 netfilter"></a>lvs 和 netfilter</h4><p>在介绍 lvs 的实现之前，我们需要了解 netfilter ，Linux 的所有数据包都会经过它，而我们使用的 iptables 是用户态提供的操作工具之一。Linux 内核处理进出的数据包分为了 5 个阶段。netfilter 在这 5 个阶段提供了 hook 点，来让注册的 hook 函数来实现对包的过滤和修改。下图的 local process 就是上层的协议栈。</p><p>下面是 IPVS 在 netfilter 里的模型图，IPVS 也是基于 netfilter 框架的，但只工作在 <code>INPUT</code> 链上，通过注册 <code>ip_vs_in</code> 钩子函数来处理请求。因为 VIP 我们配置在机器上（常规的 lvs nat 的 VIP 是在 NAT GW 上，我们这里是自己），我们 curl 的时候就会进到 <code>INPUT</code> 链，<code>ip_vs_in</code> 会匹配然后直接跳转触发 <code>POSTROUTING</code> 链，跳过 iptables 规则。</p><p><img src="https://raw.githubusercontent.com/zhangguanzhang/Image-Hosting/master/picgo/lvs-netfilter.png" alt="lvs-netfilter"></p><p>所以请求流程是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># CIP: client IP    # RIP: real server IP</span><br><span class="line"></span><br><span class="line">CLIENT</span><br><span class="line">   | CIP:CPORT -&gt; VIP:VPORT</span><br><span class="line">   |||</span><br><span class="line">   |\/</span><br><span class="line">       | CIP:CPORT -&gt; VIP:VPORT</span><br><span class="line">   LVS DNAT</span><br><span class="line">      | CIP:CPORT -&gt; RIP:RPORT</span><br><span class="line">      |||</span><br><span class="line">   |\/</span><br><span class="line">   | CIP:CPORT -&gt; RIP:RPORT</span><br><span class="line">   +</span><br><span class="line">REAL SERVER</span><br></pre></td></tr></table></figure><p>lvs 做了 DNAT 并没有做 SNAT ，所以我们利用 iptables 做 SNAT ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A POSTROUTING -m ipvs --vaddr 169.254.11.2 --vport 80 -j MASQUERADE</span><br></pre></td></tr></table></figure><p>访问看看还是不通，抓包看还是没生效，nat 是依赖 <code>conntrack</code> 的，而 IPVS 默认不会记录 conntrack，我们需要开启 IPVS 的 conntrack 才可以让 MASQUERADE 生效。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 让 Netfilter 的 conntrack 状态管理功能也能应用于 IPVS 模块</span></span><br><span class="line">$ <span class="built_in">echo</span> 1 &gt;  /proc/sys/net/ipv4/vs/conntrack</span><br><span class="line">$  curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.222</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.222</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.222</span><br></pre></td></tr></table></figure><p>现在实现了单个 SVC 的，但是仔细思考下还是有问题，如果后续增加另一个 SVC 又得增加一个 iptables 规则了，那就又回到 iptables 的匹配复杂度耗时长上去了。所以我们可以利用 iptables 的 mark 和 ipset 配合减少 iptables 规则。</p><h3 id="利用-ipset-和-iptable-的-mark"><a href="#利用-ipset-和-iptable-的-mark" class="headerlink" title="利用 ipset 和 iptable 的 mark"></a>利用 ipset 和 iptable 的 mark</h3><p><img src="https://raw.githubusercontent.com/zhangguanzhang/Image-Hosting/master/picgo/iptables_netfilter.png" alt="iptables_netfilter"></p><p>iptables 的五链四表如上图所示，我们先删掉原有的规则：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -D POSTROUTING -m ipvs --vaddr 169.254.11.2 --vport 80 -j MASQUERADE</span><br></pre></td></tr></table></figure><p>平时自己家里使用了 openwrt ，之前看了下上面的 iptables 规则设计挺好的，特别是预留了很多链专门给用户在合适的位置插入规则，比如下面的 <code>INPUT</code> 规则：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-A INPUT -i eth0 -m comment --comment <span class="string">&quot;!fw3&quot;</span> -j zone_lan_input</span><br><span class="line">...</span><br><span class="line">-A zone_lan_input -m comment --comment <span class="string">&quot;!fw3: Custom lan input rule chain&quot;</span> -j input_lan_rule</span><br><span class="line">-A zone_lan_input -m conntrack --ctstate DNAT -m comment --comment <span class="string">&quot;!fw3: Accept port redirections&quot;</span> -j ACCEPT</span><br><span class="line">-A zone_lan_input -m comment --comment <span class="string">&quot;!fw3&quot;</span> -j zone_lan_src_ACCEPT</span><br></pre></td></tr></table></figure><p><code>zone_lan_src_ACCEPT</code> 是最后面，<code>zone_lan_input</code> 是最开始，那用户向 <code>input_lan_rule</code> 链里插入规则即可，利用多个链来设计也方便别人。<br>规则设计我们先逆着来思考下，最后肯定是 <code>MASQUERADE</code> 的，得在 nat 表的 <code>POSTROUTING</code> 链创建 <code>MASQUERADE</code> 的规则。</p><p>但是添加之前先思考下，lvs 做了 DNAT 后，最后包走向了 <code>POSTROUTING</code> 链，而且后面我们是有多个 SVC 的。此刻包的 <code>SRC IP</code> 会是 <code>VIP</code>，见上面抓包的结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 假设没做 masq 的时候(刚好调度到非本地的 real server 上</span><br><span class="line">#也就是上面之前不通在目标机器上抓包)包的阶段</span><br><span class="line"></span><br><span class="line">SRC:169.254.11.2:xxxx</span><br><span class="line">DST:169.254.11.2:80</span><br><span class="line">      ||</span><br><span class="line">      || 没经过 POSTROUTING masq snat 的时候</span><br><span class="line">      \/</span><br><span class="line">SRC:169.254.11.2:xxxx</span><br><span class="line">DST:192.168.2.222:80</span><br></pre></td></tr></table></figure><p>而且后续可能是在 docker 环境上部署，可能默认桥接网络下的容器也会去访问 <code>SVC</code>，此刻的 <code>SRC IP</code> 就不会是网卡上的 <code>VIP</code> 了，所以我们在 PREROUTING 阶段 dest IP,dest Port 是 svc 信息则做 masq snat。<br>可以在此刻利用一个 ipset 存储所有的 <code>SVC_IP:SVC_PORT</code> 匹配，然后打上 mark，然后在 <code>POSTROUTING</code> 链去根据 mark 去做 <code>MASQUERADE</code> 。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PREROUTING 阶段处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提供一个入口链，而不是直接添加在 PREROUTING 链上</span></span><br><span class="line">iptables -t nat -N ZGZ-SERVICES</span><br><span class="line">iptables -t nat -A PREROUTING -m comment --comment <span class="string">&quot;zgz service portals&quot;</span> -j ZGZ-SERVICES</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 PREROUTING 子链里去 ipset 匹配，跳转到我们打 mark 的链</span></span><br><span class="line">iptables -t nat -N ZGZ-MARK-MASQ</span><br><span class="line"><span class="comment"># 创建存储所有 `SVC_IP:SVC_PORT` 的 ipset </span></span><br><span class="line">ipset create ZGZ-CLUSTER-IP <span class="built_in">hash</span>:ip,port -exist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 专门 mark 的链</span></span><br><span class="line">iptables -t nat -A ZGZ-MARK-MASQ -j MARK --set-xmark 0x2000/0x2000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匹配 svc ip：svc port 的才跳转到打 mark 的链里</span></span><br><span class="line">iptables -t nat -A ZGZ-SERVICES -m comment --comment <span class="string">&quot;zgz service cluster ip + port for masquerade purpose&quot;</span> -m <span class="built_in">set</span> --match-set ZGZ-CLUSTER-IP dst,dst -j ZGZ-MARK-MASQ</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># POSTROUTING 阶段处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提供一个入口链，而不是直接添加在 POSTROUTING 链上</span></span><br><span class="line">iptables -t nat -N ZGZ-SERVICES-POSTROUTING</span><br><span class="line">iptables -t nat -A POSTROUTING -m comment --comment <span class="string">&quot;zgz postrouting rules&quot;</span> -j ZGZ-SERVICES-POSTROUTING</span><br><span class="line"><span class="comment"># 在 POSTROUTING 阶段，有 mark 标记的就做 snat</span></span><br><span class="line">iptables -t nat -A ZGZ-SERVICES-POSTROUTING -m comment --comment <span class="string">&quot;zgz service traffic requiring SNAT&quot;</span> -m mark --mark 0x2000/0x2000 -j MASQUERADE</span><br></pre></td></tr></table></figure><p>然后添加下 <code>SVC_IP:SVC_PORT</code> 到我们的 ipset 里：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipset add ZGZ-CLUSTER-IP 169.254.11.2,tcp:80 -exist</span><br></pre></td></tr></table></figure><p>上面我们创建的 ipset 里 <code>ip,port</code> 和 iptables 里 <code>--match-set</code> 后面的 <code>dst,dst</code> 组合在一起就是 <code>DEST IP</code> 和 <code>DEST PORT</code> 同时匹配，下面是一些举例：</p><table><thead><tr><th align="left">ipset type</th><th align="left">iptables match-set</th><th align="left">Packet fields</th></tr></thead><tbody><tr><td align="left">hash:net,port,net</td><td align="left">src,dst,dst</td><td align="left">src IP CIDR address, dst port, dst IP CIDR address</td></tr><tr><td align="left">hash:net,port,net</td><td align="left">dst,src,src</td><td align="left">dst IP CIDR address, src port, src IP CIDR address</td></tr><tr><td align="left">hash:ip,port,ip</td><td align="left">src,dst,dst</td><td align="left">src IP address, dst port, dst IP address</td></tr><tr><td align="left">hash:ip,port,ip</td><td align="left">dst,src,src</td><td align="left">dst IP address, src port, src ip address</td></tr><tr><td align="left">hash:mac</td><td align="left">src</td><td align="left">src mac address</td></tr><tr><td align="left">hash:mac</td><td align="left">dst</td><td align="left">dst mac address</td></tr><tr><td align="left">hash:ip,mac</td><td align="left">src,src</td><td align="left">src IP address, src mac address</td></tr><tr><td align="left">hash:ip,mac</td><td align="left">dst,dst</td><td align="left">dst IP address, dst mac address</td></tr><tr><td align="left">hash:ip,mac</td><td align="left">dst,src</td><td align="left">dst IP address, src mac address</td></tr></tbody></table><p>然后访问下还是不通，通过两台机器轮询负载均衡的 curl html 返回内容看到了访问不通的时候都是调度到非本机，也就是此刻的 curl 只经过 <code>OUTPUT</code> 链，过 <code>POSTROUTING</code> 的时候并没有 mark 也就不会做 masq ， 调试了下发现确实会走 <code>OUTPUT</code> 链：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;kern.warning /var/log/iptables.log&#x27;</span> &gt;&gt; /etc/rsyslog.conf</span><br><span class="line">$ systemctl restart rsyslog</span><br><span class="line">$ iptables -t nat -I OUTPUT -m <span class="built_in">set</span> --match-set ZGZ-CLUSTER-IP dst,dst  -j LOG --log-prefix <span class="string">&#x27;**log-test**&#x27;</span></span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">^C</span><br><span class="line">$ cat /var/<span class="built_in">log</span>/iptables.log</span><br><span class="line">Sep 27 23:17:51 centos7 kernel: **log-test**IN= OUT=lo SRC=169.254.11.2 DST=169.254.11.2 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=44864 DF PROTO=TCP SPT=50794 DPT=80 WINDOW=43690 RES=0x00 SYN URGP=0 </span><br><span class="line">Sep 27 23:17:52 centos7 kernel: **log-test**IN= OUT=lo SRC=169.254.11.2 DST=169.254.11.2 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=2010 DF PROTO=TCP SPT=50796 DPT=80 WINDOW=43690 RES=0x00 SYN URGP=0 </span><br></pre></td></tr></table></figure><p>需要添加下面规则，让它也进下 svc 判断和打 mark：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -A OUTPUT -m comment --comment <span class="string">&quot;zgz service portals&quot;</span> -j ZGZ-SERVICES</span><br></pre></td></tr></table></figure><h3 id="keepalived-的自动化实现"><a href="#keepalived-的自动化实现" class="headerlink" title="keepalived 的自动化实现"></a>keepalived 的自动化实现</h3><p>到目前为止都是手动挡，而且没健康检查，其实我们可以利用 keepalived 做个自动挡的。</p><h4 id="安装-keepalived-2"><a href="#安装-keepalived-2" class="headerlink" title="安装 keepalived 2"></a>安装 keepalived 2</h4><p>CentOS7 自带的源里 <code>keepalived</code> 版本很低，我们安装下比自带新的版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install -y http://www.nosuchhost.net/~cheese/fedora/packages/epel-7/x86_64/cheese-release-7-1.noarch.rpm</span><br><span class="line">yum install -y keepalived</span><br><span class="line"><span class="comment"># 备份下自带的配置文件</span></span><br><span class="line">cp /etc/keepalived/keepalived.conf&#123;,.bak&#125;</span><br></pre></td></tr></table></figure><h4 id="配置-keepalived"><a href="#配置-keepalived" class="headerlink" title="配置 keepalived"></a>配置 keepalived</h4><p>我们需要配置下 keepalived ，修改之前先看下默认相关的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl cat keepalived</span><br><span class="line"><span class="comment"># /usr/lib/systemd/system/keepalived.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=LVS and VRRP High Availability Monitor</span><br><span class="line">After=syslog.target network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">KillMode=process</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/keepalived</span><br><span class="line">ExecStart=/usr/sbin/keepalived <span class="variable">$KEEPALIVED_OPTIONS</span></span><br><span class="line">ExecReload=/bin/<span class="built_in">kill</span> -HUP <span class="variable">$MAINPID</span></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">$ cat /etc/sysconfig/keepalived</span><br><span class="line"><span class="comment"># Options for keepalived. See `keepalived --help&#x27; output and keepalived(8) and</span></span><br><span class="line"><span class="comment"># keepalived.conf(5) man pages for a list of all options. Here are the most</span></span><br><span class="line"><span class="comment"># common ones :</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># --vrrp               -P    Only run with VRRP subsystem.</span></span><br><span class="line"><span class="comment"># --check              -C    Only run with Health-checker subsystem.</span></span><br><span class="line"><span class="comment"># --dont-release-vrrp  -V    Dont remove VRRP VIPs &amp; VROUTEs on daemon stop.</span></span><br><span class="line"><span class="comment"># --dont-release-ipvs  -I    Dont remove IPVS topology on daemon stop.</span></span><br><span class="line"><span class="comment"># --dump-conf          -d    Dump the configuration data.</span></span><br><span class="line"><span class="comment"># --log-detail         -D    Detailed log messages.</span></span><br><span class="line"><span class="comment"># --log-facility       -S    0-7 Set local syslog facility (default=LOG_DAEMON)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line">KEEPALIVED_OPTIONS=<span class="string">&quot;-D&quot;</span></span><br></pre></td></tr></table></figure><p><code>/etc/sysconfig/keepalived</code> 里修改为下面：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KEEPALIVED_OPTIONS=&quot;-D --log-console --log-detail --use-file=/etc/keepalived/keepalived.conf&quot;</span><br></pre></td></tr></table></figure><p>我们选择在主配置文件里去 include 子配置文件，keepalivd 接收 <code>kill -HUP</code> 信号触发 reload ，后续自动化添加 SVC 的时候添加子配置文件后发送信号即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">! Configuration File for keepalived</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">global_defs &#123;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"># 记住 keepalived 的任何配置文件不能有 x 权限</span></span><br><span class="line"><span class="string">include /etc/keepalived/conf.d/*.conf</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">mkdir -p /etc/keepalived/conf.d/</span><br></pre></td></tr></table></figure><p>我们写一个脚本，一个是用来添加一个子配置文件里的相关信息到 ipset 里，另一方面也让它在重启或者启动 keepalived 的时候每次能初始化，先添加 systemd 的部分：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/lib/systemd/system/keepalived.service.d</span><br><span class="line">cat &gt; /usr/lib/systemd/system/keepalived.service.d/10.keepalived.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">ExecStartPre=/etc/keepalived/ipvs.sh</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>然后编写脚本 <code>/etc/keepalived/ipvs.sh</code> :</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"></span><br><span class="line">dummy_if=svc</span><br><span class="line">CONF_DIR=/etc/keepalived/conf.d/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">ipset_init</span></span>()&#123;</span><br><span class="line">    ipset create ZGZ-CLUSTER-IP <span class="built_in">hash</span>:ip,port -exist</span><br><span class="line">    ipset flush ZGZ-CLUSTER-IP</span><br><span class="line">    <span class="built_in">local</span> f ip port protocol</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> $(find  <span class="variable">$&#123;CONF_DIR&#125;</span> -maxdepth 1 -<span class="built_in">type</span> f -name <span class="string">&#x27;*.conf&#x27;</span>);<span class="keyword">do</span></span><br><span class="line">        awk <span class="string">&#x27;&#123;if($1==&quot;virtual_server&quot;)&#123;printf $2&quot; &quot;$3&quot; &quot;;flag=1;&#125;;if(flag==1 &amp;&amp; $1==&quot;protocol&quot;)&#123;print $2;flag=0&#125;&#125;&#x27;</span> <span class="string">&quot;<span class="variable">$f</span>&quot;</span> | <span class="keyword">while</span> <span class="built_in">read</span> ip port protocol;<span class="keyword">do</span></span><br><span class="line">            <span class="comment"># SVC IP port 插入 ipset 里</span></span><br><span class="line">            ipset add ZGZ-CLUSTER-IP <span class="variable">$&#123;ip&#125;</span>,<span class="variable">$&#123;protocol,,&#125;</span>:<span class="variable">$&#123;port&#125;</span> -exist</span><br><span class="line">            <span class="comment"># 添加 SVC IP 到 dummy 接口上</span></span><br><span class="line">            <span class="keyword">if</span> ! ip r g <span class="variable">$&#123;ip&#125;</span> | grep -qw lo;<span class="keyword">then</span></span><br><span class="line">                ip addr add <span class="variable">$&#123;ip&#125;</span>/32 dev <span class="variable">$&#123;dummy_if&#125;</span></span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">create_Chain_in_nat</span></span>()&#123;</span><br><span class="line">    <span class="comment"># delete use -X</span></span><br><span class="line">    <span class="built_in">local</span> Chain option</span><br><span class="line">    option=<span class="string">&quot;-t nat --wait&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> Chain <span class="keyword">in</span> <span class="variable">$@</span>;<span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> ! iptables <span class="variable">$option</span> -S | grep -Eq -- <span class="string">&quot;-N\s+<span class="variable">$&#123;Chain&#125;</span>&quot;</span>;<span class="keyword">then</span></span><br><span class="line">        iptables <span class="variable">$option</span> -N <span class="variable">$&#123;Chain&#125;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">create_Rule_in_nat</span></span>()&#123;</span><br><span class="line">    <span class="built_in">local</span> cmd=<span class="string">&#x27;iptables -t nat --wait &#x27;</span></span><br><span class="line">    <span class="keyword">if</span> ! <span class="variable">$&#123;cmd&#125;</span>  --check <span class="string">&quot;<span class="variable">$@</span>&quot;</span> 2&gt;/dev/null;<span class="keyword">then</span></span><br><span class="line">        <span class="variable">$&#123;cmd&#125;</span> -A <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">iptables_init</span></span>()&#123;</span><br><span class="line">    create_Chain_in_nat ZGZ-SERVICES  ZGZ-SERVICES-POSTROUTING ZGZ-SERVICES-MARK-MASQ</span><br><span class="line"></span><br><span class="line">    create_Rule_in_nat ZGZ-SERVICES-MARK-MASQ -j MARK --set-xmark 0x2000/0x2000</span><br><span class="line"></span><br><span class="line">    create_Rule_in_nat ZGZ-SERVICES -m comment --comment <span class="string">&quot;zgz service cluster ip + port for masquerade purpose&quot;</span> -m <span class="built_in">set</span> --match-set ZGZ-CLUSTER-IP dst,dst -j ZGZ-SERVICES-MARK-MASQ</span><br><span class="line"></span><br><span class="line">    create_Rule_in_nat PREROUTING -m comment --comment <span class="string">&quot;zgz service portals&quot;</span> -j ZGZ-SERVICES</span><br><span class="line">    create_Rule_in_nat OUTPUT -m comment --comment <span class="string">&quot;zgz service portals&quot;</span> -j ZGZ-SERVICES</span><br><span class="line"></span><br><span class="line">    create_Rule_in_nat ZGZ-SERVICES-POSTROUTING -m comment --comment <span class="string">&quot;zgz service traffic requiring SNAT&quot;</span> -m mark --mark 0x2000/0x2000 -j MASQUERADE</span><br><span class="line">    create_Rule_in_nat POSTROUTING -m comment --comment <span class="string">&quot;zgz postrouting rules&quot;</span> -j ZGZ-SERVICES-POSTROUTING</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">ipvs_svc_run</span></span>()&#123;</span><br><span class="line">  ip addr flush dev <span class="variable">$&#123;dummy_if&#125;</span></span><br><span class="line">  ipset_init</span><br><span class="line">  iptables_init</span><br><span class="line">  <span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/vs/conntrack</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 无参数则是 keepalived 启动，也可以接收单个配置文件参数</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">main</span></span>()&#123;</span><br><span class="line">  <span class="keyword">if</span> [ ! -d /proc/sys/net/ipv4/conf/<span class="variable">$&#123;dummy_if&#125;</span> ];<span class="keyword">then</span></span><br><span class="line">    ip link add <span class="variable">$&#123;dummy_if&#125;</span> <span class="built_in">type</span> dummy</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$#</span>&quot;</span> -eq 0 ];<span class="keyword">then</span></span><br><span class="line">    ipvs_svc_run</span><br><span class="line">    <span class="built_in">return</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">local</span> file fullFile ip port protocol</span><br><span class="line">  <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$@</span>;<span class="keyword">do</span></span><br><span class="line">    fullFile=<span class="variable">$&#123;CONF_DIR&#125;</span>/<span class="variable">$file</span></span><br><span class="line">      awk <span class="string">&#x27;&#123;if($1==&quot;virtual_server&quot;)&#123;printf $2&quot; &quot;$3&quot; &quot;;flag=1;&#125;;if(flag==1 &amp;&amp; $1==&quot;protocol&quot;)&#123;print $2;flag=0&#125;&#125;&#x27;</span> <span class="string">&quot;<span class="variable">$f</span>&quot;</span> | <span class="keyword">while</span> <span class="built_in">read</span> ip port protocol;<span class="keyword">do</span></span><br><span class="line">          <span class="comment"># SVC IP port 插入 ipset 里</span></span><br><span class="line">          ipset add ZGZ-CLUSTER-IP <span class="variable">$&#123;ip&#125;</span>,<span class="variable">$&#123;protocol,,&#125;</span>:<span class="variable">$&#123;port&#125;</span> -exist</span><br><span class="line">          <span class="comment"># 添加 SVC IP 到 dummy 接口上</span></span><br><span class="line">          <span class="keyword">if</span> ! ip r g <span class="variable">$&#123;ip&#125;</span> | grep -qw lo;<span class="keyword">then</span></span><br><span class="line">              ip addr add <span class="variable">$&#123;ip&#125;</span>/32 dev <span class="variable">$&#123;dummy_if&#125;</span></span><br><span class="line">          <span class="keyword">fi</span></span><br><span class="line">      <span class="keyword">done</span></span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line">  <span class="comment"># 重新 reload </span></span><br><span class="line">  pkill --signal HUP keepalived</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main <span class="variable">$@</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>脚本就如上面所示，读取 keepalived 的 lvs 文件，把 <code>VIP:PORT</code> 加到 ipset 里，VIP 加到 <code>dummy</code> 接口上，之前是加到 eth0 上，但是业务网卡可能会重启影响，dummy 接口和 loopback 类似，它总是 up 的，除非你 down 掉它，SVC 地址配置在它上面不会随着物理接口状态变化而受到影响。删除掉之前 eth0 上的 VIP <code>ip addr del 169.254.11.2/32 dev eth0</code>，然后把前面的转成 keepalived 的配置文件测试下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">chmod a+x /etc/keepalived/ipvs.sh</span><br><span class="line">cat &gt; /etc/keepalived/conf.d/test.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">virtual_server 169.254.11.2 80 &#123;</span></span><br><span class="line"><span class="string">    delay_loop 3</span></span><br><span class="line"><span class="string">    lb_algo rr</span></span><br><span class="line"><span class="string">    lb_kind NAT</span></span><br><span class="line"><span class="string">    protocol TCP</span></span><br><span class="line"><span class="string">    alpha #默认是禁用，会导致在启动daemon时，所有rs都会上来，开启此选项下则是所有的RS在daemon启动的时候是down状态，healthcheck健康检查failed。这有助于其启动时误报错误</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    real_server  192.168.2.111 8080 &#123;</span></span><br><span class="line"><span class="string">        weight 1</span></span><br><span class="line"><span class="string">        HTTP_GET  &#123;</span></span><br><span class="line"><span class="string">            url &#123;</span></span><br><span class="line"><span class="string">              path /404</span></span><br><span class="line"><span class="string">              status_code 404</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">            connect_port    8080</span></span><br><span class="line"><span class="string">            connect_timeout 2</span></span><br><span class="line"><span class="string">            retry 2</span></span><br><span class="line"><span class="string">            delay_before_retry 2</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    real_server  192.168.2.222 8080 &#123;</span></span><br><span class="line"><span class="string">        weight 1</span></span><br><span class="line"><span class="string">        HTTP_GET  &#123;</span></span><br><span class="line"><span class="string">            url &#123;</span></span><br><span class="line"><span class="string">              path /404</span></span><br><span class="line"><span class="string">              status_code 404</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">            connect_port    8080</span></span><br><span class="line"><span class="string">            connect_timeout 2</span></span><br><span class="line"><span class="string">            retry 2</span></span><br><span class="line"><span class="string">            delay_before_retry 2</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>测试下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 先清理掉之前手动添加的</span><br><span class="line">ipvsadm --clear</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart keepalived</span><br><span class="line"></span><br><span class="line">$ curl 169.254.11.2/www/test</span><br><span class="line">192.168.2.222</span><br><span class="line">$ curl 169.254.11.2/www/test</span><br><span class="line">192.168.2.111</span><br><span class="line">$ curl 169.254.11.2/www/test</span><br><span class="line">192.168.2.222</span><br><span class="line">$ curl 169.254.11.2/www/test</span><br><span class="line">192.168.2.111</span><br><span class="line">$ ip a s svc</span><br><span class="line">4: svc: &lt;BROADCAST,NOARP&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ether e6:a3:29:07:fa:57 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 169.254.11.2/32 scope global svc</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>停掉一个 web 后在我们配置的健康检查几秒也剔除了 rs ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">curl: (7) Failed connect to 169.254.11.2:80; Connection refused</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br><span class="line">$ curl 169.254.11.2/www/<span class="built_in">test</span></span><br><span class="line">192.168.2.111</span><br></pre></td></tr></table></figure><h4 id="系统的相关配置"><a href="#系统的相关配置" class="headerlink" title="系统的相关配置"></a>系统的相关配置</h4><p>后面重启后发现不通，发现内核模块没加载，使用 <code>systemd-modules-load</code> 去开机加载：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat  &gt; /etc/modules-load.d/ipvs.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">ip_vs</span></span><br><span class="line"><span class="string">ip_vs_rr</span></span><br><span class="line"><span class="string">ip_vs_wrr</span></span><br><span class="line"><span class="string">ip_vs_sh</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/sysctl.d/90.ipvs.conf &lt;&lt; <span class="string">EOF </span></span><br><span class="line"><span class="string"># https://github.com/moby/moby/issues/31208 </span></span><br><span class="line"><span class="string"># ipvsadm -l --timout</span></span><br><span class="line"><span class="string"># 修复ipvs模式下长连接timeout问题 小于900即可</span></span><br><span class="line"><span class="string">net.ipv4.tcp_keepalive_time=600</span></span><br><span class="line"><span class="string">net.ipv4.tcp_keepalive_intvl=30</span></span><br><span class="line"><span class="string">net.ipv4.vs.conntrack=1</span></span><br><span class="line"><span class="string"># https://github.com/kubernetes/kubernetes/issues/70747 https://github.com/kubernetes/kubernetes/pull/71114</span></span><br><span class="line"><span class="string">net.ipv4.vs.conn_reuse_mode=0</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><h3 id="docker-运行的方案"><a href="#docker-运行的方案" class="headerlink" title="docker 运行的方案"></a>docker 运行的方案</h3><p><code>docker-compose</code> 文件如下，自己把脚本挂载进去即可：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.5&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">keepalived:</span> </span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;registry.aliyuncs.com/zhangguanzhang/keepalived:v2.2.0&#x27;</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">&#x27;keepalived-ipvs&#x27;</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">unless-stopped</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">&quot;keepalived-ipvs&quot;</span></span><br><span class="line">    <span class="attr">labels:</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">app=keepalived</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">cap_drop:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ALL</span></span><br><span class="line">    <span class="attr">cap_add:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">NET_BIND_SERVICE</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/lib/modules:/lib/modules</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/run/xtables.lock:/run/xtables.lock</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./conf.d/:/etc/keepalived/conf.d/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./keepalived.conf:/etc/keepalived/keepalived.conf</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./always-initsh.d:/always-initsh.d</span></span><br><span class="line">    <span class="attr">command:</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">--dont-fork</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--log-console</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--log-detail</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--use-file=/etc/keepalived/keepalived.conf</span></span><br><span class="line">    <span class="attr">logging:</span></span><br><span class="line">      <span class="attr">driver:</span> <span class="string">json-file</span></span><br><span class="line">      <span class="attr">options:</span></span><br><span class="line">        <span class="attr">max-file:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line">        <span class="attr">max-size:</span> <span class="string">20m</span></span><br></pre></td></tr></table></figure><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.filter_rules.html">Interaction between LVS and netfilter</a></li><li><a href="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.LVS-NAT.html#lvs_nat_intro">lvs nat</a></li><li><a href="https://github.com/liexusong/linux-source-code-analyze/blob/master/lvs-principle-and-source-analysis-part2.md">lvs-principle-and-source-analysis</a></li><li><a href="https://www.zsythink.net/archives/1199">朱双印大佬的 iptables 技术系列</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;内部有非 K8S 环境上需要类似 SVC 的负载实现，一开始是用 NGINX 做的，所有 SVC 域名都解析成一个 dummy IP ，然后</summary>
      
    
    
    
    
    <category term="lvs" scheme="http://zhangguanzhang.github.io/tags/lvs/"/>
    
    <category term="ipvsadm" scheme="http://zhangguanzhang.github.io/tags/ipvsadm/"/>
    
    <category term="kube-proxy" scheme="http://zhangguanzhang.github.io/tags/kube-proxy/"/>
    
  </entry>
  
  <entry>
    <title>解决 docker 的 read unix @-&gt;/run/containerd/s/xxx read: connection reset by peer: unknown</title>
    <link href="http://zhangguanzhang.github.io/2021/09/16/read-containerd-con-reset/"/>
    <id>http://zhangguanzhang.github.io/2021/09/16/read-containerd-con-reset/</id>
    <published>2021-09-16T18:14:06.000Z</published>
    <updated>2021-09-16T18:14:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>为了测试关机对集群的影响，关机了几台机器后很多 pod 一直 <code>CrashLoopBackOff</code> 和 <code>RunContainerError</code> 或者一直无法就绪</p><h3 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS76 ~]# docker info</span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: false</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Containers: 404</span><br><span class="line">  Running: 258</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 146</span><br><span class="line"> Images: 110</span><br><span class="line"> Server Version: 19.03.14</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: xfs</span><br><span class="line">  Supports d_type: true</span><br><span class="line">  Native Overlay Diff: true</span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: cgroupfs</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: local</span><br><span class="line">  Network: bridge host ipvlan macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: ea765aba0d05254012b0b9e595e995c09186427f</span><br><span class="line"> runc version: v1.0.0-0-g84113eef6fc2</span><br><span class="line"> init version: fec3683</span><br><span class="line"> Security Options:</span><br><span class="line">  seccomp</span><br><span class="line">   Profile: default</span><br><span class="line"> Kernel Version: 3.10.0-1160.36.2.el7.x86_64</span><br><span class="line"> Operating System: CentOS Linux 7 (Core)</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPUs: 16</span><br><span class="line"> Total Memory: 62.76GiB</span><br><span class="line"> Name: CentOS76</span><br><span class="line"> ID: BJ2X:EX7H:SCME:Q3AD:IP2M:IB2D:E4RL:XA4C:EOMQ:7S3F:DIA6:WQ2C</span><br><span class="line"> Docker Root Dir: /data/kube/docker</span><br><span class="line"> Debug Mode: false</span><br><span class="line"> Registry: https://index.docker.io/v1/</span><br><span class="line"> Labels:</span><br><span class="line"> Experimental: false</span><br><span class="line"> Insecure Registries:</span><br><span class="line">  reg.xxx.lan:5000</span><br><span class="line">  treg.yun.xxx.cn</span><br><span class="line">  127.0.0.0/8</span><br><span class="line"> Registry Mirrors:</span><br><span class="line">  https://registry.docker-cn.com/</span><br><span class="line">  https://docker.mirrors.ustc.edu.cn/</span><br><span class="line"> Live Restore Enabled: false</span><br><span class="line"> Product License: Community Engine</span><br></pre></td></tr></table></figure><h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><p>日志查看如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RunContainerError: failed to start container &quot;90353b19ae6c7209ba1785286c292f2362fa069b578f2e2731e93747c5ba1912&quot;: Error response from daemon: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/90353b19ae6c7209ba1785286c292f2362fa069b578f2e2731e93747c5ba1912/log.json: no such file or directory): runc did not terminate sucessfully: unknown</span><br></pre></td></tr></table></figure><p>还有下面日志：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">runc did not terminate sucessfully: runtime/cgo: pthread_create failed: Resource temporarily unavailable</span><br><span class="line"></span><br><span class="line">container 9853a196008b92033a299e098d73d4268a76ce58faecfe40ca3411857d44a776: unknown error after kill: fork/exec /data/kube/bin/runc: resource temporarily unavailable: : unknown&quot;</span><br></pre></td></tr></table></figure><p>应该资源限制了，看了下默认的 <code>kernel.pid_max</code> 太小：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl -n kernel.pid_max</span><br><span class="line">32768</span><br></pre></td></tr></table></figure><p>后面陆陆续续调整了一些下面的参数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/security/limits.d/21-custom.conf&lt;&lt;EOF</span><br><span class="line">*       soft    nproc   131072</span><br><span class="line">*       hard    nproc   131072</span><br><span class="line">*       soft    nofile  131072</span><br><span class="line">*       hard    nofile  131072</span><br><span class="line">root    soft    nproc   131072</span><br><span class="line">root    hard    nproc   131072</span><br><span class="line">root    soft    nofile  131072</span><br><span class="line">root    hard    nofile  131072</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sed -ri &#x27;s/^#(DefaultLimitCORE)=/\1=100000/&#x27; /etc/systemd/system.conf</span><br><span class="line">sed -ri &#x27;s/^#(DefaultLimitNOFILE)=/\1=100000/&#x27; /etc/systemd/system.conf</span><br></pre></td></tr></table></figure><p>然后重启后 pod 还没有好转，启动一直处于 Create 的容器会有下面错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS76 ~]# docker start 034f</span><br><span class="line">Error response from daemon: read unix @-&gt;/run/containerd/s/2ac09cf054eb19b79336b25efe1aeeaf22bcf0d9559ca79b8459c3490cd6034f: read: connection reset by peer: unknown</span><br><span class="line">Error: failed to start containers: 034f</span><br></pre></td></tr></table></figure><p>手动起容器报错下面的，调整参数后更多是上面的报错。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm nginx:1.19-alpine</span><br><span class="line">docker: Errpr response from daemon: failed to start shim: fork/exec /usr/bin/containerd-shim: resource temporarily unavailable: unknown.</span><br></pre></td></tr></table></figure><p><code> read unix @-&gt;/run/containerd/s</code> 这个按照流程走就是 contained 的问题了，可以从 <a href="https://github.com/docker/docker-ce/blob/d7080c17a580919f5340a15a8e5e013133089680/components/engine/libcontainerd/remote_daemon.go#L244">源码</a> 得知，如果没启动 containerd ，docker 则会 os.Exec 起一个 <code>containerd</code> ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ps aux | grep &#x27;\scontainerd\s&#x27;</span><br><span class="line">root     147580  2.4  0.1 10375568 104588 ?     Ssl  17:06   3:15 containerd --config /var/run/docker/containerd/containerd.toml --log-level warn</span><br></pre></td></tr></table></figure><p>我们的 docker 是官方的 static 二进制安装的，去看了下 rpm 安装的话会分离开，也就是有个 containerd 的 rpm，有一个 <code>containerd.service</code> 服务。 想着看下我们环境上的 containerd 的输出日志，但是源码看的话命令的输出都是绑定到 docker 的输出的。而且命令行参数固定的、无法改为 debug level。</p><p>手动杀掉启动下试试：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -9 147580 &amp;&amp; containerd --config /var/run/docker/containerd/containerd.toml --log-level debug</span><br></pre></td></tr></table></figure><p>另外开个 ssh 窗口发现 pod 状态都正常了。说明了 systemd 启动的 docker 有限制，去 dockerd 的 proc 目录啥的查找了下看没达到文件啥的限制</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS76 ~]# pgrep dockerd</span><br><span class="line">113233</span><br><span class="line">[root@CentOS76 ~]# lsof -p 113233  | wc -l</span><br><span class="line">956</span><br></pre></td></tr></table></figure><p>最后找到问题所在，下面的<code>Tasks: 2043 (limit: 2048)</code> 限制</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS76 ~]# systemctl status docker</span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 四 2021-09-16 16:53:21 CST; 4min 16s ago</span><br><span class="line">     Docs: http://docs.docker.io</span><br><span class="line">  Process: 113228 ExecStopPost=/bin/sh -c /sbin/iptables --wait -D INPUT -i cni0 -j ACCEPT &amp;&gt; /dev/null || : (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 113225 ExecStopPost=/bin/sh -c /sbin/iptables --wait -D FORWARD -s 0.0.0.0/0 -j ACCEPT &amp;&gt; /dev/null || : (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 113236 ExecStartPost=/sbin/iptables --wait -I INPUT -i cni0 -j ACCEPT (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 113234 ExecStartPost=/sbin/iptables --wait -I FORWARD -s 0.0.0.0/0 -j ACCEPT (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 113231 ExecStartPre=/bin/bash -c test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 113233 (dockerd)</span><br><span class="line">    Tasks: 2043 (limit: 2048)</span><br><span class="line">   Memory: 1.1G</span><br><span class="line">   CGroup: /system.slice/docker.service</span><br><span class="line">           ├─ 89710 containerd-shim -namespace</span><br></pre></td></tr></table></figure><p>systemd 的 <code>DefaultTasksMax</code> 是 <code>2048</code> ，另外对比了官方的 <code>docker.service</code> 是不限制 Tasks 的，我们没加：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl cat docker</span><br><span class="line">..</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>加了后重启 docker 就好了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/systemd/system/docker.service</span><br><span class="line">TasksMax=infinity</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://plpan.github.io/docker-exec-%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E4%B9%8B%E6%97%85/">https://plpan.github.io/docker-exec-%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E4%B9%8B%E6%97%85/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;由来&quot;&gt;&lt;a href=&quot;#由来&quot; class=&quot;headerlink&quot; title=&quot;由来&quot;&gt;&lt;/a&gt;由来&lt;/h2&gt;&lt;p&gt;为了测试关机对集群的影响，关机了几台机器后很多 pod 一直 &lt;code&gt;CrashLoopBackOff&lt;/code&gt; 和 &lt;code&gt;R</summary>
      
    
    
    
    
    <category term="docker" scheme="http://zhangguanzhang.github.io/tags/docker/"/>
    
    <category term="containerd" scheme="http://zhangguanzhang.github.io/tags/containerd/"/>
    
  </entry>
  
  <entry>
    <title>[持续更新] - Openwrt USB 网络</title>
    <link href="http://zhangguanzhang.github.io/2021/09/03/openwrt-usb-net/"/>
    <id>http://zhangguanzhang.github.io/2021/09/03/openwrt-usb-net/</id>
    <published>2021-09-03T22:29:08.000Z</published>
    <updated>2021-09-03T22:29:08.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="about"><a href="#about" class="headerlink" title="about"></a>about</h2><p>记录下 openwrt 下 usb 网络的折腾，后续折腾这块内容的话也在这个文章内更新</p><h3 id="N1-上的-usb-网络共享折腾"><a href="#N1-上的-usb-网络共享折腾" class="headerlink" title="N1 上的 usb 网络共享折腾"></a>N1 上的 usb 网络共享折腾</h3><h4 id="固件依赖"><a href="#固件依赖" class="headerlink" title="固件依赖"></a>固件依赖</h4><p>暂时没完全区分 usb 网络共享和 <code>usb-cdc</code> 的关系，所以我编译的时候把很多 <code>usb-net-xxx</code> 都编译进去了</p><p>听其他大佬说编译的时候主要有下面的包:</p><ul><li>安卓: <code>kmod-usb-net kmod-usb-net-rndis</code></li><li>苹果: <code>kmod-usb-net-ipheth usbmuxd</code></li></ul><p>建议下面这些也安装上方便调试:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_PACKAGE_luci-proto-3g=y</span><br><span class="line">CONFIG_PACKAGE_luci-proto-ncm=y</span><br><span class="line">CONFIG_PACKAGE_luci-proto-qmi=y</span><br><span class="line"></span><br><span class="line">CONFIG_BUSYBOX_DEFAULT_LSPCI=y</span><br><span class="line">CONFIG_BUSYBOX_DEFAULT_LSUSB=y</span><br><span class="line">CONFIG_BUSYBOX_DEFAULT_IPROUTE=y</span><br><span class="line"></span><br><span class="line">CONFIG_PACKAGE_usb-modeswitch=y</span><br><span class="line">CONFIG_PACKAGE_usbutils=y</span><br><span class="line">CONFIG_PACKAGE_usbreset=y</span><br><span class="line">CONFIG_PACKAGE_qmi-utils=y</span><br><span class="line">CONFIG_PACKAGE_libqmi=y</span><br><span class="line"></span><br><span class="line">CONFIG_PACKAGE_bind-dig=y</span><br><span class="line">CONFIG_PACKAGE_tcpdump=y</span><br><span class="line"></span><br><span class="line">CONFIG_PACKAGE_pciutils=y</span><br></pre></td></tr></table></figure><p>这些好像是 usb 4g 网卡的包，一般是 <code>E3372</code>(联通4G) 和 <code>E8372</code>(全网通4G版本) ，</p><p>缺省应该都可以用hilink模式，把下面这些驱动装上即可:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hilink mode: hilink mode 的网卡名 是  ethX 也可以说 usb0，ncm模式的则是wwan0， lsusb 或者 usb-mode -l 查看设备识别否</span><br><span class="line">kmod-usb-net-rndis kmod-usb-net kmod-usb2 usb-modeswitch</span><br><span class="line"></span><br><span class="line">NCM mode:</span><br><span class="line">gcom kmod-usb-net-huawei-cdc-ncm  kmod-usb2 usb-modeswitch kmod-usb-serial-wwan</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_PACKAGE_uqmi=y</span><br><span class="line">kmod-usb-acm kmod-usb-net kmod-usb-net-qmi-wwan kmod-usb-ohci kmod-usb-serial kmod-usb-serial-option</span><br></pre></td></tr></table></figure><h4 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h4><p>N1 建议开下无线，虽然辣鸡，但是它只有一个网口，方便我们操作。我是我的 <code>redmi k30s</code> usb 网络共享插给 N1，另一个手机连 N1 无线后 ssh 上去敲命令的。</p><p>先备份下网络配置文件，防止后面搞崩了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /etc/config/network /etc/config/network.bak</span><br></pre></td></tr></table></figure><p>插上去后有个 <code>usb0</code> 网卡</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# ip a s</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: sit0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/sit 0.0.0.0 brd 0.0.0.0</span><br><span class="line">3: ip6tnl0@NONE: &lt;NOARP&gt; mtu 1452 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/tunnel6 :: brd :: permaddr d636:b99c:d56d::</span><br><span class="line">4: eth0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc mq master br-lan state DOWN group default qlen 1000</span><br><span class="line">    link/ether 0e:02:db:93:b8:20 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">5: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">6: dummy0: &lt;BROADCAST,NOARP&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ether f2:09:65:33:97:88 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">7: bond0: &lt;BROADCAST,MULTICAST,MASTER&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ether 7e:ad:dd:05:72:66 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">8: wlan0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel master br-lan state UP group default qlen 1000</span><br><span class="line">    link/ether 0e:02:db:93:b8:1f brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::c02:dbff:fe93:b81f/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">9: br-lan: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 0e:02:db:93:b8:20 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.1.1/24 brd 192.168.1.255 scope global br-lan</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fd4e:8614:5748::1/60 scope global noprefixroute</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::c02:dbff:fe93:b820/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">10: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default</span><br><span class="line">    link/ether 02:42:14:ab:d8:da brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.31.0.1/24 brd 172.31.0.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">11: usb0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ether 82:e0:7e:db:2c:25 brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure><p>使用 <code>udhcpc</code> 发送 dhcp 请求</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# udhcpc -i usb0</span><br><span class="line">udhcpc: started, v1.33.1</span><br><span class="line">udhcpc: sending discover</span><br><span class="line">udhcpc: sendto: Network is down</span><br><span class="line">udhcpc: read error: Network is down, reopening socket</span><br><span class="line">udhcpc: sending discover</span><br></pre></td></tr></table></figure><p>查看下 usb，确实有我的 手机，居然要手动 up 它</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# lsusb</span><br><span class="line">Bus 001 Device 004: ID 2717:ff80 Xiaomi M2007J3SC</span><br><span class="line">Bus 002 Device 001: ID 1d6b:0003 Linux 5.13.13-flippy-63+ xhci-hcd xHCI Host Controller</span><br><span class="line">Bus 001 Device 001: ID 1d6b:0002 Linux 5.13.13-flippy-63+ xhci-hcd xHCI Host Controller</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# ip link set usb0 up</span><br><span class="line">root@OpenWrt:~# ip a s usb0</span><br><span class="line"></span><br><span class="line">13: usb0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether 0a:01:0f:46:3a:e6 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::801:fff:fe46:3ae6/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">root@OpenWrt:~# udhcpc -i usb0</span><br><span class="line">udhcpc: started, v1.33.1</span><br><span class="line">udhcpc: sending discover</span><br><span class="line">udhcpc: sending select for 192.168.42.128</span><br><span class="line">udhcpc: lease of 192.168.42.128 obtained, lease time 3599</span><br><span class="line">udhcpc: ip addr add 192.168.42.128/255.255.255.0 broadcast 192.168.42.255 dev usb0</span><br><span class="line">udhcpc: setting default routers: 192.168.42.129</span><br></pre></td></tr></table></figure><p>请求过程中也把默认路由设置为它了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# ip r g 1</span><br><span class="line">1.0.0.0 via 192.168.42.129 dev usb0 src 192.168.42.128 uid 0</span><br><span class="line">    cache</span><br><span class="line">root@OpenWrt:~# ping baudu.com</span><br><span class="line">^C</span><br><span class="line">root@OpenWrt:~# ping 114.114.114.114</span><br><span class="line">PING 114.114.114.114 (114.114.114.114): 56 data bytes</span><br><span class="line">64 bytes from 114.114.114.114: seq=0 ttl=64 time=73.218 ms</span><br><span class="line">64 bytes from 114.114.114.114: seq=1 ttl=70 time=45.460 ms</span><br><span class="line">64 bytes from 114.114.114.114: seq=2 ttl=71 time=43.823 ms</span><br><span class="line">64 bytes from 114.114.114.114: seq=3 ttl=81 time=40.963 ms</span><br><span class="line">^C</span><br><span class="line">--- 114.114.114.114 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max = 40.963/50.866/73.218 ms</span><br><span class="line">root@OpenWrt:~#</span><br></pre></td></tr></table></figure><p>去 web 上，网络接口，把 wan 的口子(如果没有就添加)，<code>dhcp客户端</code>，接口设选 <code>usb0</code>。添加后设置下新添加接口的 <code>防火墙设置</code> ，将其设置为 <code>wan: </code></p><h4 id="参考"><a href="#参考" class="headerlink" title="参考:"></a>参考:</h4><ul><li><a href="https://www.right.com.cn/forum/thread-220887-1-1.html">https://www.right.com.cn/forum/thread-220887-1-1.html</a></li><li><a href="https://iyzm.net/openwrt/775.html">https://iyzm.net/openwrt/775.html</a></li><li><a href="https://blog.umoe.vip/2020/12/31/bb3180dd6d20/">https://blog.umoe.vip/2020/12/31/bb3180dd6d20/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;about&quot;&gt;&lt;a href=&quot;#about&quot; class=&quot;headerlink&quot; title=&quot;about&quot;&gt;&lt;/a&gt;about&lt;/h2&gt;&lt;p&gt;记录下 openwrt 下 usb 网络的折腾，后续折腾这块内容的话也在这个文章内更新&lt;/p&gt;
&lt;h3 id=&quot;N1</summary>
      
    
    
    
    <category term="openwrt" scheme="http://zhangguanzhang.github.io/categories/openwrt/"/>
    
    
    <category term="usb-net" scheme="http://zhangguanzhang.github.io/tags/usb-net/"/>
    
  </entry>
  
  <entry>
    <title>fio 静态编译和基础使用</title>
    <link href="http://zhangguanzhang.github.io/2021/09/02/fio/"/>
    <id>http://zhangguanzhang.github.io/2021/09/02/fio/</id>
    <published>2021-09-02T14:28:30.000Z</published>
    <updated>2021-09-02T14:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2><p>amd64,arm64 的静态编译和基础使用</p><h3 id="buildx-使用"><a href="#buildx-使用" class="headerlink" title="buildx 使用"></a>buildx 使用</h3><p>见文章 <a href="https://github.com/zhangguanzhang/docker-need-to-know/blob/master/2.docker-image/dockerfile/buildx.md">buildx 使用</a></p><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>buildx Dockerfile 构建:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu as build</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /opt</span></span><br><span class="line"><span class="keyword">ARG</span> VER=fio-<span class="number">3.29</span></span><br><span class="line"><span class="comment">#ARG DEBIAN_FRONTEND=noninteractive</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="keyword">if</span> [  -e /etc/apt/sources.list ];<span class="keyword">then</span> sed -ri <span class="string">&#x27;s/[a-zA-Z0-9.]+(debian.org|ubuntu.com)/mirrors.aliyun.com/g&#x27;</span> /etc/apt/sources.list; <span class="keyword">fi</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">export</span> DEBIAN_FRONTEND=noninteractive &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get update &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get install -y git gcc make cmake libaio1 libaio-dev zlib1g zlib1g-dev </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/axboe/fio.git &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">cd</span> fio  &amp;&amp; \</span></span><br><span class="line"><span class="bash">    git checkout <span class="variable">$&#123;VER&#125;</span> </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> fio  &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ./configure --build-static &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make &amp;&amp; make install  &amp;&amp; \</span></span><br><span class="line"><span class="bash">    cp `<span class="built_in">which</span> fio` /fio-$(dpkg --print-architecture)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> scratch AS bin</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=build /fio-* /</span></span><br></pre></td></tr></table></figure><p>构建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker buildx build  . --platform linux/amd64,linux/arm64 \</span><br><span class="line">    --target bin --output . \</span><br><span class="line">    --build-arg=VER=fio-3.29</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ ll</span><br><span class="line">total 4</span><br><span class="line">-rw-r--r-- 1 root root 660 Feb  9 21:32 Dockerfile</span><br><span class="line">drwxr-xr-x 2 root root  23 Feb  9 21:44 linux_amd64</span><br><span class="line">drwxr-xr-x 2 root root  23 Feb  9 21:44 linux_arm64</span><br><span class="line">$ tree .</span><br><span class="line">.</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── linux_amd64</span><br><span class="line">│   └── fio-amd64</span><br><span class="line">└── linux_arm64</span><br><span class="line">    └── fio-arm64</span><br><span class="line">$ ldd linux_amd64/fio-amd64 linux_arm64/fio-arm64 </span><br><span class="line">linux_amd64/fio-amd64:</span><br><span class="line">not a dynamic executable</span><br><span class="line">linux_arm64/fio-arm64:</span><br><span class="line">not a dynamic executable</span><br><span class="line">$ file linux_amd64/fio-amd64 linux_arm64/fio-arm64 </span><br><span class="line">linux_amd64/fio-amd64: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, BuildID[sha1]=30dddb2ae5ca67f3533b8e54aa0900ee701c7b01, for GNU/Linux 3.2.0, not stripped</span><br><span class="line">linux_arm64/fio-arm64: ELF 64-bit LSB executable, ARM aarch64, version 1 (GNU/Linux), statically linked, BuildID[sha1]=6a644c0696153f99d2d527948e0400720742a002, for GNU/Linux 3.7.0, not stripped</span><br><span class="line">$ </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>符号链接可以 <code>strip -s $(which nginx)</code> 去掉减少大小。</p><h3 id="fio-测速说明"><a href="#fio-测速说明" class="headerlink" title="fio 测速说明"></a>fio 测速说明</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--eta-newline=5s   5s切到新的行继续输出速度状态</span><br><span class="line">--filename        写入到哪个文件，必须使用绝对路径</span><br><span class="line">--rw=write         前面没带rand就是顺序，此处是顺序写，例如rw则是顺序读写，randwrite则是随机写，测速推荐顺序写</span><br><span class="line">--ioengine         libaio 是多线程内核态，速度很快，不推荐用它测速，推荐使用 psync 单线程测速</span><br><span class="line">--runtime          秒数，测速的时间</span><br><span class="line">--time_based      时间算速度</span><br><span class="line">--output-format=json  如果有取输出的话，可以带上这个，带上这个就是结束后输出json，上面的 --eta-newline 就没有意义了</span><br></pre></td></tr></table></figure><p>测速注意文件落地路径，ioengine 不要用 libaio 这种内核态的并发读写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./fio --name TEST --eta-newline=5s \</span><br><span class="line">  --filename=/root/fio-tempfile.dat \</span><br><span class="line">   --rw=write --size=2g --io_size=2g --blocksize=4k \</span><br><span class="line">   --ioengine=psync --fsync=1 --iodepth=8 --direct=1 \</span><br><span class="line">   --numjobs=1 --runtime=300 --group_reporting --time_based </span><br></pre></td></tr></table></figure><p>例如这个是个人电脑 Linux 的测速，不会是那种 vcenter 和虚拟化上受其他虚机和存储池的影响，这台 Linux 分区是 hdd 和 SDD 做的 lvm，最终的 avg 是 avg=837.02。现场测速记得参数 –filename= 改成 data 实际路径测速文件 ，下面数据结果可以参考下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">root@pve:~# fio --name TEST --eta-newline=5s --filename=/root/fio-tempfile.dat \</span><br><span class="line">  --rw=write --size=500m --io_size=2g --blocksize=4k  \</span><br><span class="line">  --ioengine=psync --fsync=1 --iodepth=8 --direct=1 \</span><br><span class="line">  --numjobs=1 --runtime=300 --group_reporting --time_based </span><br><span class="line">TEST: (g=0): rw=write, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=8</span><br><span class="line">fio-3.12</span><br><span class="line">Starting 1 process</span><br><span class="line">Jobs: 1 (f=1): [W(1)][2.3%][w=3275KiB/s][w=818 IOPS][eta 04m:53s]</span><br><span class="line">Jobs: 1 (f=1): [W(1)][4.3%][w=3383KiB/s][w=845 IOPS][eta 04m:47s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][6.3%][w=3295KiB/s][w=823 IOPS][eta 04m:41s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][8.3%][w=3263KiB/s][w=815 IOPS][eta 04m:35s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][10.3%][w=3304KiB/s][w=826 IOPS][eta 04m:29s]</span><br><span class="line">Jobs: 1 (f=1): [W(1)][12.3%][w=3324KiB/s][w=831 IOPS][eta 04m:23s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][14.3%][w=3523KiB/s][w=880 IOPS][eta 04m:17s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][16.3%][w=3368KiB/s][w=842 IOPS][eta 04m:11s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][18.3%][w=3407KiB/s][w=851 IOPS][eta 04m:05s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][20.3%][w=3395KiB/s][w=848 IOPS][eta 03m:59s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][22.3%][w=3335KiB/s][w=833 IOPS][eta 03m:53s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][24.3%][w=3335KiB/s][w=833 IOPS][eta 03m:47s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][26.3%][w=3467KiB/s][w=866 IOPS][eta 03m:41s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][28.3%][w=3328KiB/s][w=832 IOPS][eta 03m:35s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][30.3%][w=3284KiB/s][w=821 IOPS][eta 03m:29s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][32.3%][w=3295KiB/s][w=823 IOPS][eta 03m:23s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][34.3%][w=3399KiB/s][w=849 IOPS][eta 03m:17s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][36.3%][w=3391KiB/s][w=847 IOPS][eta 03m:11s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][38.3%][w=3347KiB/s][w=836 IOPS][eta 03m:05s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][40.3%][w=3331KiB/s][w=832 IOPS][eta 02m:59s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][42.3%][w=3211KiB/s][w=802 IOPS][eta 02m:53s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][44.3%][w=3351KiB/s][w=837 IOPS][eta 02m:47s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][46.3%][w=3267KiB/s][w=816 IOPS][eta 02m:41s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][48.3%][w=3320KiB/s][w=830 IOPS][eta 02m:35s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][50.3%][w=3419KiB/s][w=854 IOPS][eta 02m:29s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][52.3%][w=3344KiB/s][w=836 IOPS][eta 02m:23s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][54.3%][w=3427KiB/s][w=856 IOPS][eta 02m:17s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][56.3%][w=3388KiB/s][w=847 IOPS][eta 02m:11s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][58.3%][w=3516KiB/s][w=879 IOPS][eta 02m:05s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][60.3%][w=3320KiB/s][w=830 IOPS][eta 01m:59s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][62.3%][w=3184KiB/s][w=796 IOPS][eta 01m:53s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][64.3%][w=3468KiB/s][w=867 IOPS][eta 01m:47s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][66.3%][w=3399KiB/s][w=849 IOPS][eta 01m:41s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][68.3%][w=3540KiB/s][w=885 IOPS][eta 01m:35s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][70.3%][w=3304KiB/s][w=826 IOPS][eta 01m:29s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][72.3%][w=3187KiB/s][w=796 IOPS][eta 01m:23s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][74.3%][w=3428KiB/s][w=857 IOPS][eta 01m:17s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][76.3%][w=3751KiB/s][w=937 IOPS][eta 01m:11s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][78.3%][w=3336KiB/s][w=834 IOPS][eta 01m:05s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][80.3%][w=3456KiB/s][w=864 IOPS][eta 00m:59s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][82.3%][w=3259KiB/s][w=814 IOPS][eta 00m:53s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][84.3%][w=3416KiB/s][w=854 IOPS][eta 00m:47s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][86.3%][w=3384KiB/s][w=846 IOPS][eta 00m:41s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][88.3%][w=3299KiB/s][w=824 IOPS][eta 00m:35s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][90.3%][w=3427KiB/s][w=856 IOPS][eta 00m:29s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][92.3%][w=3176KiB/s][w=794 IOPS][eta 00m:23s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][94.3%][w=3295KiB/s][w=823 IOPS][eta 00m:17s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][96.3%][w=3359KiB/s][w=839 IOPS][eta 00m:11s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][98.3%][w=3532KiB/s][w=883 IOPS][eta 00m:05s] </span><br><span class="line">Jobs: 1 (f=1): [W(1)][100.0%][w=3351KiB/s][w=837 IOPS][eta 00m:00s]</span><br><span class="line">TEST: (groupid=0, jobs=1): err= 0: pid=6687: Mon Jan 24 11:42:39 2022</span><br><span class="line">  write: IOPS=837, BW=3348KiB/s (3429kB/s)(981MiB/300001msec); 0 zone resets</span><br><span class="line">    clat (usec): min=29, max=5771, avg=107.72, stdev=56.50</span><br><span class="line">     lat (usec): min=29, max=5772, avg=108.00, stdev=56.50</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[   34],  5.00th=[   42], 10.00th=[   47], 20.00th=[   73],</span><br><span class="line">     | 30.00th=[   82], 40.00th=[  102], 50.00th=[  113], 60.00th=[  128],</span><br><span class="line">     | 70.00th=[  137], 80.00th=[  143], 90.00th=[  147], 95.00th=[  151],</span><br><span class="line">     | 99.00th=[  163], 99.50th=[  169], 99.90th=[  184], 99.95th=[  208],</span><br><span class="line">     | 99.99th=[ 3261]</span><br><span class="line">   bw (  KiB/s): min= 2760, max= 3872, per=100.00%, avg=3348.14, stdev=140.52, samples=600</span><br><span class="line">   iops        : min=  690, max=  968, avg=837.02, stdev=35.13, samples=600</span><br><span class="line">  lat (usec)   : 50=10.97%, 100=27.52%, 250=61.48%, 500=0.01%, 750=0.01%</span><br><span class="line">  lat (usec)   : 1000=0.01%</span><br><span class="line">  lat (msec)   : 2=0.01%, 4=0.02%, 10=0.01%</span><br><span class="line">  fsync/fdatasync/sync_file_range:</span><br><span class="line">    sync (usec): min=383, max=27349, avg=1084.44, stdev=480.22</span><br><span class="line">    sync percentiles (usec):</span><br><span class="line">     |  1.00th=[  701],  5.00th=[  725], 10.00th=[  742], 20.00th=[  766],</span><br><span class="line">     | 30.00th=[  799], 40.00th=[  816], 50.00th=[  832], 60.00th=[  840],</span><br><span class="line">     | 70.00th=[  947], 80.00th=[ 1696], 90.00th=[ 1811], 95.00th=[ 1876],</span><br><span class="line">     | 99.00th=[ 1975], 99.50th=[ 2040], 99.90th=[ 2180], 99.95th=[ 3458],</span><br><span class="line">     | 99.99th=[ 9634]</span><br><span class="line">  cpu          : usr=1.09%, sys=4.30%, ctx=678813, majf=0, minf=13</span><br><span class="line">  IO depths    : 1=200.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=0,251136,0,251136 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=8</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: bw=3348KiB/s (3429kB/s), 3348KiB/s-3348KiB/s (3429kB/s-3429kB/s), io=981MiB (1029MB), run=300001-300001msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">    dm-1: ios=0/725828, merge=0/0, ticks=0/282020, in_queue=282020, util=99.90%, aggrios=240/651563, aggrmerge=0/74672, aggrticks=583/280037, aggrin_queue=620, aggrutil=99.90%</span><br><span class="line">  sdb: ios=240/651563, merge=0/74672, ticks=583/280037, in_queue=620, util=99.90%</span><br></pre></td></tr></table></figure><p><a href="https://etcd.io/docs/v3.5/op-guide/hardware/">https://etcd.io/docs/v3.5/op-guide/hardware/</a> etcd 文档上写着：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">etcd 对磁盘写入延迟非常敏感。通常需要 50 个顺序 IOPS（例如，7200 RPM 磁盘）。对于负载较重的集群，建议使用 500 顺序 IOPS（例如，典型的本地 SSD 或高性能虚拟化块设备）。请注意，大多数云提供商发布并发 IOPS 而不是顺序 IOPS；发布的并发 IOPS 可以是顺序 IOPS 的 10 倍。要测量实际的顺序 IOPS，我们建议使用磁盘基准测试工具，例如 diskbench 或 fio。</span><br><span class="line">如果要取输出里的部分值，那就带上 --output-format=json</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./fio --name TEST --eta-newline=5s --filename=/root/fio-tempfile.dat \</span><br><span class="line">  --rw=write --size=2g --io_size=2g --blocksize=4k \</span><br><span class="line">  --ioengine=psync --fsync=1 --iodepth=8 --direct=1 --numjobs=1 \</span><br><span class="line">  --runtime=300 --group_reporting --time_based \</span><br><span class="line">  --output-format=json</span><br></pre></td></tr></table></figure><p>正常来说 普通 7200 的硬盘 IOPS 也就是 60 左右，500 的 IOPS 基本就得用 jbod 或者 raid10，或者更高的 SSD 了。<br>如果测得低的话可以肯定是 io 不行，高的话也不一定真的快，硬盘可能有缓存，可能会虚高。所以fio的需要长时间测试，推荐 3 分钟以上。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;由来&quot;&gt;&lt;a href=&quot;#由来&quot; class=&quot;headerlink&quot; title=&quot;由来&quot;&gt;&lt;/a&gt;由来&lt;/h2&gt;&lt;p&gt;amd64,arm64 的静态编译和基础使用&lt;/p&gt;
&lt;h3 id=&quot;buildx-使用&quot;&gt;&lt;a href=&quot;#buildx-使用&quot; cla</summary>
      
    
    
    
    
    <category term="docker" scheme="http://zhangguanzhang.github.io/tags/docker/"/>
    
    <category term="linux" scheme="http://zhangguanzhang.github.io/tags/linux/"/>
    
    <category term="fio" scheme="http://zhangguanzhang.github.io/tags/fio/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu18下io调度算法是cfq导致mysql非常慢</title>
    <link href="http://zhangguanzhang.github.io/2021/09/01/ubuntu18-and-cfq/"/>
    <id>http://zhangguanzhang.github.io/2021/09/01/ubuntu18-and-cfq/</id>
    <published>2021-09-01T20:04:01.000Z</published>
    <updated>2021-09-01T20:04:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录线上一次 io 调度算法导致的 mysql 读写慢问题</p><span id="more"></span><h2 id="问题由来"><a href="#问题由来" class="headerlink" title="问题由来"></a>问题由来</h2><p>同样的部署包，都是容器化的，配置和宿主机也是一样在同一台机器上，虚机的盘存储也是同一个里，mysql 的 docker 镜像是一样，配置文件也是完全一样。<br>在 ubuntu16 上我们初始化 mysql 表时间为 x ，而在 ubuntu 18 上则是 2倍以上的时间，甚至 10 倍。<br>ubuntu 的 <code>systemd-resolved</code> 我们 k8s 已经处理了的。不存在啥反向解析问题。一开始 NUMA 绑定关系不一样，调整一样后还是存在，最后查到相关资料是和 io 调度算法有关系：</p><p><a href="https://codeistry.wordpress.com/2020/01/16/ubuntu-18-04-poor-disk-read-performance/">https://codeistry.wordpress.com/2020/01/16/ubuntu-18-04-poor-disk-read-performance/</a></p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>长话短说，ubuntu 16 是 <code>deadline</code> ，18 则是 <code>cfq</code> ，后者太平均了，不适合 mysql 这种 io 密集型的业务。<code>noop</code> 则适合 ssd 和 flash 之类的。</p><p>可以下面快照查看某个路径所在的 io 调度算法:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DB_DATA_PATH=/data/mysql_data</span><br><span class="line"></span><br><span class="line">DEVICE=$( findmnt -T $&#123;DB_DATA_PATH&#125; -o SOURCE --noheadings )</span><br><span class="line">DEVICE=$&#123;DEVICE##*/&#125;</span><br><span class="line">DEVICE=$( tr -d &#x27;0-9&#x27; &lt;&lt;&lt; &quot;$&#123;DEVICE&#125;&quot;)</span><br><span class="line"># 查看 io 调度算法</span><br><span class="line">cat /sys/block/$&#123;DEVICE&#125;/queue/scheduler</span><br></pre></td></tr></table></figure><p>直接 <code>echo deadline &gt; /sys/block/sdb/queue/scheduler</code> 可以调整，不需要重启，但是重启失效，而调整内核参数 <code>elevator=deadline</code> 的话则是全局，如果机器上其他块设备是 ssd 则不合适，所以我们可以用 systemd 的 oneshot 调整，<code>/etc/fstab</code> 是 <code>systemd-remount-fs.service</code> 负责挂载的。我们的分区肯定是它挂载的，所以在它后面去执行，大概下面这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/systemd/system/mysql-block.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=set block scheduler for mysql</span><br><span class="line">After=systemd-remount-fs.service</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;</span><br><span class="line">Type=oneshot</span><br><span class="line">ConditionPathExists=/sys/block/sdb</span><br><span class="line">ExecStart=/bin/bash -c &#x27;echo deadline &gt; /sys/block/sdb/queue/scheduler&#x27;</span><br><span class="line">RemainAfterExit=yes</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl enable mysql-block.service</span><br></pre></td></tr></table></figure><p>如果底层是 ssd ，但是做了 raid，无法通过 <code>rotational</code> 来判断是不是 ssd，直插使用的话为 <code>0</code> 就是 ssd。可以下面查看</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/block/sda/queue/rotational</span><br><span class="line"># or</span><br><span class="line">lsblk -d -o name,rota</span><br></pre></td></tr></table></figure><h2 id="一些数据对比"><a href="#一些数据对比" class="headerlink" title="一些数据对比"></a>一些数据对比</h2><p>我们机器系统盘和数据盘，系统盘没改，测试 io 速度：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1804:~# fio --name TEST --eta-newline=5s --filename=fio-tempfile.dat \</span><br><span class="line">   --rw=randwrite --size=500m --io_size=2g --blocksize=4k \</span><br><span class="line">   --ioengine=libaio --fsync=1 --iodepth=1 --direct=1 --numjobs=1 --runtime=60 --group_reporting</span><br><span class="line"></span><br><span class="line">TEST: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 process</span><br><span class="line">TEST: Laying out IO file (1 file / 500MiB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)][13.3%][r=0KiB/s,w=306KiB/s][r=0,w=76 IOPS][eta 00m:52s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][23.3%][r=0KiB/s,w=361KiB/s][r=0,w=90 IOPS][eta 00m:46s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][51.7%][r=0KiB/s,w=362KiB/s][r=0,w=90 IOPS][eta 00m:29s] </span><br><span class="line">Jobs: 1 (f=1): [w(1)][61.7%][r=0KiB/s,w=172KiB/s][r=0,w=43 IOPS][eta 00m:23s] </span><br><span class="line">Jobs: 1 (f=1): [w(1)][71.7%][r=0KiB/s,w=396KiB/s][r=0,w=99 IOPS][eta 00m:17s] </span><br><span class="line">Jobs: 1 (f=1): [w(1)][81.7%][r=0KiB/s,w=436KiB/s][r=0,w=109 IOPS][eta 00m:11s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][90.0%][r=0KiB/s,w=420KiB/s][r=0,w=105 IOPS][eta 00m:06s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=416KiB/s][r=0,w=104 IOPS][eta 00m:00s]</span><br><span class="line">TEST: (groupid=0, jobs=1): err= 0: pid=24257: Thu Sep  2 11:30:06 2021</span><br><span class="line">  write: IOPS=92, BW=370KiB/s (379kB/s)(21.7MiB/60006msec)</span><br><span class="line">    slat (usec): min=18, max=10744, avg=50.73, stdev=175.78</span><br><span class="line">    clat (usec): min=4, max=187002, avg=10094.71, stdev=7746.13</span><br><span class="line">     lat (usec): min=244, max=187062, avg=10146.12, stdev=7742.92</span><br><span class="line">    clat percentiles (msec):</span><br><span class="line">     |  1.00th=[    9],  5.00th=[    9], 10.00th=[    9], 20.00th=[    9],</span><br><span class="line">     | 30.00th=[    9], 40.00th=[    9], 50.00th=[    9], 60.00th=[    9],</span><br><span class="line">     | 70.00th=[   10], 80.00th=[   10], 90.00th=[   12], 95.00th=[   18],</span><br><span class="line">     | 99.00th=[   42], 99.50th=[   64], 99.90th=[  107], 99.95th=[  133],</span><br><span class="line">     | 99.99th=[  188]</span><br><span class="line">   bw (  KiB/s): min=    3, max=  404, per=36.51%, avg=135.07, stdev=151.88, samples=97</span><br><span class="line">   iops        : min=    0, max=  101, avg=33.30, stdev=38.04, samples=97</span><br><span class="line">  lat (usec)   : 10=0.04%, 100=0.11%, 250=0.11%, 500=0.02%</span><br><span class="line">  lat (msec)   : 10=88.37%, 20=7.97%, 50=2.56%, 100=0.68%, 250=0.14%</span><br><span class="line">  cpu          : usr=0.33%, sys=0.79%, ctx=11118, majf=0, minf=10</span><br><span class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued rwt: total=0,5556,0, short=0,0,0, dropped=0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=1</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: bw=370KiB/s (379kB/s), 370KiB/s-370KiB/s (379kB/s-379kB/s), io=21.7MiB (22.8MB), run=60006-60006msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sda: ios=0/16781, merge=0/11771, ticks=0/63856, in_queue=63744, util=94.50%</span><br></pre></td></tr></table></figure><p>iops avg 是 33.30 , <code>/data</code> 目录是已经调整成 <code>deadline</code> 了，测下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1804:~# cd /data/</span><br><span class="line">root@ubuntu1804:/data# fio --name TEST --eta-newline=5s --filename=fio-tempfile.dat   --rw=randwrite --size=500m --io_size=2g --blocksize=4k   --ioengine=libaio --fsync=1 --iodepth=1 --direct=1 --numjobs=1 --runtime=60 --group_reporting</span><br><span class="line"></span><br><span class="line">TEST: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 process</span><br><span class="line">TEST: Laying out IO file (1 file / 500MiB)</span><br><span class="line">Jobs: 1 (f=1): [w(1)][11.7%][r=0KiB/s,w=4681KiB/s][r=0,w=1170 IOPS][eta 00m:53s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][21.7%][r=0KiB/s,w=6553KiB/s][r=0,w=1638 IOPS][eta 00m:47s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][31.1%][r=0KiB/s,w=4536KiB/s][r=0,w=1134 IOPS][eta 00m:42s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][41.0%][r=0KiB/s,w=2516KiB/s][r=0,w=629 IOPS][eta 00m:36s] </span><br><span class="line">Jobs: 1 (f=1): [w(1)][50.8%][r=0KiB/s,w=3772KiB/s][r=0,w=943 IOPS][eta 00m:30s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][60.7%][r=0KiB/s,w=8476KiB/s][r=0,w=2119 IOPS][eta 00m:24s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][85.0%][r=0KiB/s,w=7158KiB/s][r=0,w=1789 IOPS][eta 00m:09s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][95.0%][r=0KiB/s,w=6984KiB/s][r=0,w=1746 IOPS][eta 00m:03s]</span><br><span class="line">Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=3449KiB/s][r=0,w=862 IOPS][eta 00m:00s]</span><br><span class="line">TEST: (groupid=0, jobs=1): err= 0: pid=26679: Thu Sep  2 11:32:17 2021</span><br><span class="line">  write: IOPS=1462, BW=5851KiB/s (5992kB/s)(343MiB/60010msec)</span><br><span class="line">    slat (usec): min=25, max=270564, avg=275.98, stdev=3972.28</span><br><span class="line">    clat (nsec): min=1240, max=190800k, avg=140324.02, stdev=2041880.18</span><br><span class="line">     lat (usec): min=71, max=283124, avg=416.73, stdev=4716.37</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[    44],  5.00th=[    50], 10.00th=[    53], 20.00th=[    59],</span><br><span class="line">     | 30.00th=[    73], 40.00th=[    82], 50.00th=[    87], 60.00th=[    92],</span><br><span class="line">     | 70.00th=[    99], 80.00th=[   109], 90.00th=[   129], 95.00th=[   157],</span><br><span class="line">     | 99.00th=[   334], 99.50th=[   465], 99.90th=[  4555], 99.95th=[ 31327],</span><br><span class="line">     | 99.99th=[105382]</span><br><span class="line">   bw (  KiB/s): min=   93, max=11799, per=72.15%, avg=4221.47, stdev=3043.93, samples=93</span><br><span class="line">   iops        : min=   23, max= 2949, avg=1055.01, stdev=760.91, samples=93</span><br><span class="line">  lat (usec)   : 2=0.04%, 4=0.11%, 10=0.19%, 20=0.07%, 50=5.46%</span><br><span class="line">  lat (usec)   : 100=65.80%, 250=26.62%, 500=1.27%, 750=0.18%, 1000=0.06%</span><br><span class="line">  lat (msec)   : 2=0.07%, 4=0.03%, 10=0.03%, 20=0.01%, 50=0.03%</span><br><span class="line">  lat (msec)   : 100=0.02%, 250=0.01%</span><br><span class="line">  cpu          : usr=1.95%, sys=43.40%, ctx=175616, majf=0, minf=39</span><br><span class="line">  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued rwt: total=0,87784,0, short=0,0,0, dropped=0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=1</span><br><span class="line"></span><br><span class="line">Run status group 0 (all jobs):</span><br><span class="line">  WRITE: bw=5851KiB/s (5992kB/s), 5851KiB/s-5851KiB/s (5992kB/s-5992kB/s), io=343MiB (360MB), run=60010-60010msec</span><br><span class="line"></span><br><span class="line">Disk stats (read/write):</span><br><span class="line">  sdb: ios=30/263733, merge=0/186890, ticks=948/55212, in_queue=55912, util=79.04%</span><br></pre></td></tr></table></figure><p>iops avg 是 1055.01</p><h2 id="blktrace"><a href="#blktrace" class="headerlink" title="blktrace"></a>blktrace</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apt-get install blktrace</span><br><span class="line"># 生成采集文件</span><br><span class="line">blktrace -d /dev/sdb</span><br><span class="line"># 合并成一个二进制文件</span><br><span class="line">blkparse -i sdb -d sdb.blktrace.bin</span><br><span class="line"># btt 协助统计分析</span><br><span class="line">btt -i sdb.blktrace.bin -l sdb.d2c_latencybtt -i sdb.blktrace.bin -q sdb.q2c_latency</span><br><span class="line"></span><br><span class="line">Q2G – 生成IO请求所消耗的时间，包括remap和split的时间</span><br><span class="line">G2I – IO请求进入IO Scheduler所消耗的时间，包括merge的时间 </span><br><span class="line">I2D – IO请求在IO Scheduler中等待的时间</span><br><span class="line">D2C – IO请求在driver和硬件上所消耗的时间</span><br><span class="line">Q2C – 整个IO请求所消耗的时间(G2I + I2D + D2C = Q2C)，相当于iostat的await</span><br><span class="line">其中D2C可以作为硬件性能的指标，I2D可以作为IO Scheduler性能的指标</span><br><span class="line">上述命令其实还会产生一些.dat文件，可以看到iops信息</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://codeistry.wordpress.com/2020/01/16/ubuntu-18-04-poor-disk-read-performance/">Ubuntu 18.04 : Poor disk read performance</a></li><li><a href="https://developer.aliyun.com/article/698568">blktrace 用法</a></li><li><a href="https://www.cnblogs.com/cobbliu/p/5389556.html">ubuntu io 调度算法介绍</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录线上一次 io 调度算法导致的 mysql 读写慢问题&lt;/p&gt;</summary>
    
    
    
    <category term="ubuntu18" scheme="http://zhangguanzhang.github.io/categories/ubuntu18/"/>
    
    
    <category term="ubuntu18" scheme="http://zhangguanzhang.github.io/tags/ubuntu18/"/>
    
  </entry>
  
  <entry>
    <title>干掉烦人的 open /run/xtables.lock: is a directory</title>
    <link href="http://zhangguanzhang.github.io/2021/08/27/k8s-runxtables.lock/"/>
    <id>http://zhangguanzhang.github.io/2021/08/27/k8s-runxtables.lock/</id>
    <published>2021-08-27T14:28:30.000Z</published>
    <updated>2021-08-27T14:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h2><p>suse 这辣鸡系统，使用官方文档 docker-static 的二进制安装的话会无法起来，所以我们在 suse 上用的是很久之前的 rpm 安装的 docker。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/os-release </span><br><span class="line">NAME=&quot;SLES&quot;</span><br><span class="line">VERSION=&quot;12-SP5&quot;</span><br><span class="line">VERSION_ID=&quot;12.5&quot;</span><br><span class="line">PRETTY_NAME=&quot;SUSE Linux Enterprise Server 12 SP5&quot;</span><br><span class="line">ID=&quot;sles&quot;</span><br><span class="line">ANSI_COLOR=&quot;0;32&quot;</span><br><span class="line">CPE_NAME=&quot;cpe:/o:suse:sles:12:sp5&quot;</span><br><span class="line"></span><br><span class="line">$ rpm -qa | grep docker</span><br><span class="line">docker-17.09.1_ce-98.18.1.x86_64</span><br><span class="line">docker-libnetwork-0.7.0.1+gitr2066_7b2b1feb1de4-10.1.x86_64</span><br><span class="line">docker-runc-1.0.0rc4+gitr3338_3f2f8b84a77f-1.3.1.x86_64</span><br><span class="line"></span><br><span class="line">$ docker info</span><br><span class="line">Containers: 62</span><br><span class="line"> Running: 35</span><br><span class="line"> Paused: 0</span><br><span class="line"> Stopped: 27</span><br><span class="line">Images: 89</span><br><span class="line">Server Version: 17.09.1-ce</span><br><span class="line">Storage Driver: btrfs</span><br><span class="line"> Build Version: Btrfs v3.18.2+20150430</span><br><span class="line"> Library Version: 101</span><br><span class="line">Logging Driver: json-file</span><br><span class="line">Cgroup Driver: cgroupfs</span><br><span class="line">Plugins:</span><br><span class="line"> Volume: local</span><br><span class="line"> Network: bridge host macvlan null overlay</span><br><span class="line"> Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog</span><br><span class="line">Swarm: inactive</span><br><span class="line">Runtimes: oci runc</span><br><span class="line">Default Runtime: runc</span><br><span class="line">Init Binary: docker-init</span><br><span class="line">containerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0</span><br><span class="line">runc version: 3f2f8b84a77f73d38244dd690525642a72156c64</span><br><span class="line">init version: v0.1.3_catatonit (expected: 949e6facb77383876aeff8a6944dde66b3089574)</span><br><span class="line">Security Options:</span><br><span class="line"> apparmor</span><br><span class="line">Kernel Version: 4.12.14-120-default</span><br><span class="line">Operating System: SUSE Linux Enterprise Server 12 SP5</span><br><span class="line">OSType: linux</span><br><span class="line">Architecture: x86_64</span><br><span class="line">CPUs: 16</span><br><span class="line">Total Memory: 62.67GiB</span><br><span class="line">Name: SUSESP5</span><br><span class="line">ID: GZWM:UWPN:INDR:SICH:UD6H:RKPG:WRYK:5YDY:6723:I2HR:UPWI:KI6W</span><br><span class="line">Docker Root Dir: /data/kube/docker</span><br><span class="line">Debug Mode (client): false</span><br><span class="line">Debug Mode (server): false</span><br><span class="line">Registry: https://index.docker.io/v1/</span><br><span class="line">Experimental: false</span><br><span class="line">Insecure Registries:</span><br><span class="line"> reg.xxx.lan:5000</span><br><span class="line"> treg.yun.xxx.cn</span><br><span class="line"> 127.0.0.0/8</span><br><span class="line">Registry Mirrors:</span><br><span class="line"> https://registry.docker-cn.com/</span><br><span class="line"> https://docker.mirrors.ustc.edu.cn/</span><br><span class="line">Live Restore Enabled: false</span><br><span class="line"></span><br><span class="line">WARNING: No swap limit support</span><br></pre></td></tr></table></figure><p>问题是部署后业务无法解析域名，排查了下是 svc 的 iptables 规则没生成，最后在 kube-proxy （二进制部署的）的日志发现如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Aug 27 10:41:58 SUSESP5 kube-proxy[1666]: E0827 10:41:58.480578    1666 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:41:58 SUSESP5 kube-proxy[1666]: I0827 10:41:58.480614    1666 proxier.go:876] Sync failed; retrying in 18s</span><br><span class="line">Aug 27 10:42:16 SUSESP5 kube-proxy[1666]: E0827 10:42:16.502207    1666 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:42:16 SUSESP5 kube-proxy[1666]: I0827 10:42:16.502266    1666 proxier.go:876] Sync failed; retrying in 18s</span><br><span class="line">Aug 27 10:42:24 SUSESP5 kube-proxy[1666]: E0827 10:42:24.806734    1666 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:42:24 SUSESP5 kube-proxy[1666]: I0827 10:42:24.806768    1666 proxier.go:876] Sync failed; retrying in 18s</span><br></pre></td></tr></table></figure><p>我们的 ipset 容器 <code>-v</code> 挂载了这个 iptables 的锁文件，众所周知 -v 的 src 如果不存在就会被 <code>mkdir -p</code> 。找了个干净的环境，确认了下 iptables 命令（即使啥选项都不带都）会生成该锁文件:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ rm -f /run/xtables.lock</span><br><span class="line">$ ll /run/xtables.lock</span><br><span class="line">ls: cannot access &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">$ iptables</span><br><span class="line">iptables v1.8.2 (legacy): no command specified</span><br><span class="line">Try `iptables -h&#x27; or &#x27;iptables --help&#x27; for more information.</span><br><span class="line">$ ll /run/xtables.lock</span><br><span class="line">-rw------- 1 root root 0 Aug 27 10:27 /run/xtables.lock</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>说个题外话，我们其他 os 上没有这个问题</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>其实昨天就在 kube-proxy 的 systemd 里加了下面，但是今天重启测试了下还是发生了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /run/xtables.lock &amp;&amp; rmdir /run/xtables.lock || true&#x27;</span><br></pre></td></tr></table></figure><p>手动删除目录的话，因为 kube-proxy 时刻调用 iptables ，删除后该锁文件就会被创建。但是总不能每次开机弄下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ rmdir /run/xtables.lock</span><br><span class="line">$ ll /run/xtables.lock</span><br><span class="line">ls: cannot access &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">$ ll /run/xtables.lock</span><br><span class="line">-rw------- 1 root root 0 Aug 27 10:43 /run/xtables.lock</span><br></pre></td></tr></table></figure><p>我们在 suse 的安装下给 systemd 加了个子配置文件，这个 <code>ExecStartPre</code> 是解决另一个问题的，为啥这样自己去猜。所以一开始是我的想法是再加个 <code>ExecStartPre</code> 解决</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line">$ vi /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /run/xtables.lock &amp;&amp; rmdir /run/xtables.lock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;iptables -V &amp;&gt;/dev/null || true&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">$ reboot</span><br></pre></td></tr></table></figure><p>重启后开机还是这样。。。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Aug 27 10:47:31 SUSESP5 kube-proxy[1680]: I0827 10:47:31.265099    1680 shared_informer.go:247] Caches are synced for node config</span><br><span class="line">Aug 27 10:47:31 SUSESP5 kube-proxy[1680]: I0827 10:47:31.865070    1680 shared_informer.go:247] Caches are synced for service config</span><br><span class="line">Aug 27 10:47:31 SUSESP5 kube-proxy[1680]: E0827 10:47:31.893976    1680 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:47:31 SUSESP5 kube-proxy[1680]: I0827 10:47:31.894015    1680 proxier.go:876] Sync failed; retrying in 18s</span><br><span class="line">Aug 27 10:47:32 SUSESP5 kube-proxy[1680]: E0827 10:47:32.632956    1680 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:47:32 SUSESP5 kube-proxy[1680]: I0827 10:47:32.632986    1680 proxier.go:876] Sync failed; retrying in 18s</span><br><span class="line">Aug 27 10:47:39 SUSESP5 kube-proxy[1680]: E0827 10:47:39.109972    1680 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:47:39 SUSESP5 kube-proxy[1680]: I0827 10:47:39.110010    1680 proxier.go:876] Sync failed; retrying in 18s</span><br><span class="line">Aug 27 10:47:39 SUSESP5 kube-proxy[1680]: E0827 10:47:39.128309    1680 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:47:39 SUSESP5 kube-proxy[1680]: I0827 10:47:39.128340    1680 proxier.go:876] Sync failed; retrying in 18s</span><br><span class="line">Aug 27 10:47:40 SUSESP5 kube-proxy[1680]: E0827 10:47:40.150827    1680 proxier.go:1595] Failed to execute iptables-restore: failed to open iptables lock /run/xtables.lock: open /run/xtables.lock: is a directory</span><br><span class="line">Aug 27 10:47:40 SUSESP5 kube-proxy[1680]: I0827 10:47:40.150873    1680 proxier.go:876] Sync failed; retrying in 18s</span><br></pre></td></tr></table></figure><p>确认了下子配置文件是生效了的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl cat docker</span><br><span class="line"># /etc/systemd/system/docker.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=http://docs.docker.com</span><br><span class="line">After=network.target containerd.socket containerd.service lvm2-monitor.service SuSEfirewall2.service</span><br><span class="line">Requires=containerd.socket containerd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/etc/sysconfig/docker</span><br><span class="line"></span><br><span class="line"># While Docker has support for socket activation (-H fd://), this is not</span><br><span class="line"># enabled by default because enabling socket activation means that on boot your</span><br><span class="line"># containers won&#x27;t start until someone tries to administer the Docker daemon.</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/dockerd --containerd /run/containerd/containerd.sock --add-runtime oci=/usr/sbin/docker-runc $DOCKER_NETWORK_OPTIONS $DOCKER_OPTS</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line"></span><br><span class="line"># Having non-zero Limit*s causes performance problems due to accounting overhead</span><br><span class="line"># in the kernel. We recommend using cgroups to do container-local accounting.</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line"></span><br><span class="line"># Uncomment TasksMax if your systemd version supports it.</span><br><span class="line"># Only systemd 226 and above support this property.</span><br><span class="line">TasksMax=infinity</span><br><span class="line"></span><br><span class="line"># Set delegate yes so that systemd does not reset the cgroups of docker containers</span><br><span class="line"># Only systemd 218 and above support this property.</span><br><span class="line">Delegate=yes</span><br><span class="line"></span><br><span class="line"># This is not necessary because of how we set up containerd.</span><br><span class="line">#KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /run/xtables.lock &amp;&amp; rmdir /run/xtables.lock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;iptables -V &amp;&gt;/dev/null || true&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br></pre></td></tr></table></figure><p>看下状态，确定是执行了的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl status docker</span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /etc/systemd/system/docker.service.d</span><br><span class="line">           └─10.docker.conf</span><br><span class="line">   Active: active (running) since Fri 2021-08-27 10:47:31 CST; 50s ago</span><br><span class="line">     Docs: http://docs.docker.com</span><br><span class="line">  Process: 1685 ExecStartPre=/bin/bash -c iptables -V &amp;&gt;/dev/null || true (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1681 ExecStartPre=/bin/bash -c test -d /run/xtables.lock &amp;&amp; rmdir /run/xtables.lock || true (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1675 ExecStartPre=/bin/bash -c test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 1740 (dockerd)</span><br><span class="line">    Tasks: 81</span><br><span class="line">   Memory: 318.9M</span><br><span class="line">      CPU: 11.734s</span><br><span class="line">   CGroup: /system.slice/docker.service</span><br><span class="line">           └─1740 /usr/bin/dockerd --containerd /run/containerd/containerd.sock --add-runtime oci=/usr/sbin/docker-runc</span><br></pre></td></tr></table></figure><p>一开始怀疑是不是顺序问题，测试了下是对的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /run/xtables.lock &amp;&amp; rmdir /run/xtables.lock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;iptables -V &amp;&gt;/dev/null || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;echo 1 &gt;&gt; /root/test.file&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;echo 2 &gt;&gt; /root/test.file&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;echo 3 &gt;&gt; /root/test.file&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;echo 4 &gt;&gt; /root/test.file&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;echo 5 &gt;&gt; /root/test.file&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">$ reboot</span><br><span class="line"></span><br><span class="line">$ cat /root/test.file </span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">$ systemctl status docker</span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /etc/systemd/system/docker.service.d</span><br><span class="line">           └─10.docker.conf</span><br><span class="line">   Active: active (running) since Fri 2021-08-27 11:03:18 CST; 28s ago</span><br><span class="line">     Docs: http://docs.docker.com</span><br><span class="line">  Process: 1777 ExecStartPre=/bin/bash -c echo 5 &gt;&gt; /root/test.file (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1769 ExecStartPre=/bin/bash -c echo 4 &gt;&gt; /root/test.file (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1766 ExecStartPre=/bin/bash -c echo 3 &gt;&gt; /root/test.file (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1758 ExecStartPre=/bin/bash -c echo 2 &gt;&gt; /root/test.file (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1750 ExecStartPre=/bin/bash -c echo 1 &gt;&gt; /root/test.file (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1684 ExecStartPre=/bin/bash -c iptables -V &amp;&gt;/dev/null || true (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1681 ExecStartPre=/bin/bash -c test -d /run/xtables.lock &amp;&amp; rmdir /run/xtables.lock || true (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 1676 ExecStartPre=/bin/bash -c test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 1783 (dockerd)</span><br><span class="line">    Tasks: 77</span><br><span class="line">   Memory: 304.5M</span><br><span class="line">      CPU: 10.183s</span><br><span class="line">   CGroup: /system.slice/docker.service</span><br><span class="line">           └─1783 /usr/bin/dockerd --containerd /run/containerd/containerd.sock --add-runtime oci=/usr/sbin/docker-runc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ ll /run/xtables.lock</span><br><span class="line">total 0</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>去掉 iptables 的输出重定向看看执行了没</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;rmdir /run/xtables.lock &amp;&gt;/dev/null &amp;&amp; iptables -V || true&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">$ reboot</span><br></pre></td></tr></table></figure><p>确实执行了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ journalctl -xe -u docker |&amp; grep iptables</span><br><span class="line">Aug 27 11:08:20 SUSESP5 bash[1705]: iptables v1.4.21</span><br></pre></td></tr></table></figure><p>有点绝了，然后试了下 audit 审计，但是查不出啥信息，只能继续查了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &#x27;-w /run/xtables.lock -prw &#x27; &gt; /etc/audit/rules.d/zgz.rules</span><br></pre></td></tr></table></figure><p>加个 <code>stat</code> 看看</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;stat /run/xtables.lock&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;rmdir /run/xtables.lock &amp;&gt;/dev/null &amp;&amp; iptables -V || true&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">$ reboot</span><br><span class="line"></span><br><span class="line">$ journalctl -xe -u docker |&amp; grep /run/xta</span><br><span class="line">Aug 27 11:08:25 SUSESP5 dockerd[1765]: time=&quot;2021-08-27T11:08:25.564282010+08:00&quot; level=error msg=&quot;Failed to start container e74f20c98617fa60b13981513b434cdb3139f2e3b406ec521b48ec81958cebe0: oci runtime error: container_linux.go:265: starting container process caused \&quot;process_linux.go:368: container init caused \\&quot;rootfs_linux.go:57: mounting \\\\&quot;/run/xtables.lock\\\\&quot; to rootfs \\\\&quot;/data/kube/docker/btrfs/subvolumes/7035bbf1baba2ef7cee552cd2fdda6841a22d4bdb62bd66b81f4b62c78b65735\\\\&quot; at \\\\&quot;/data/kube/docker/btrfs/subvolumes/7035bbf1baba2ef7cee552cd2fdda6841a22d4bdb62bd66b81f4b62c78b65735/run/xtables.lock\\\\&quot; caused \\\\&quot;not a directory\\\\&quot;\\&quot;\&quot;</span><br><span class="line">Aug 27 11:11:32 SUSESP5 dockerd[1679]: time=&quot;2021-08-27T11:11:32.556235556+08:00&quot; level=error msg=&quot;Failed to start container e74f20c98617fa60b13981513b434cdb3139f2e3b406ec521b48ec81958cebe0: oci runtime error: container_linux.go:265: starting container process caused \&quot;process_linux.go:368: container init caused \\&quot;rootfs_linux.go:57: mounting \\\\&quot;/run/xtables.lock\\\\&quot; to rootfs \\\\&quot;/data/kube/docker/btrfs/subvolumes/7035bbf1baba2ef7cee552cd2fdda6841a22d4bdb62bd66b81f4b62c78b65735\\\\&quot; at \\\\&quot;/data/kube/docker/btrfs/subvolumes/7035bbf1baba2ef7cee552cd2fdda6841a22d4bdb62bd66b81f4b62c78b65735/run/xtables.lock\\\\&quot; caused \\\\&quot;not a directory\\\\&quot;\\&quot;\&quot;</span><br><span class="line">Aug 27 11:33:03 SUSESP5 dockerd[1705]: time=&quot;2021-08-27T11:33:03.048807247+08:00&quot; level=error msg=&quot;Failed to start container e74f20c98617fa60b13981513b434cdb3139f2e3b406ec521b48ec81958cebe0: oci runtime error: container_linux.go:265: starting container process caused \&quot;process_linux.go:368: container init caused \\&quot;rootfs_linux.go:57: mounting \\\\&quot;/run/xtables.lock\\\\&quot; to rootfs \\\\&quot;/data/kube/docker/btrfs/subvolumes/7035bbf1baba2ef7cee552cd2fdda6841a22d4bdb62bd66b81f4b62c78b65735\\\\&quot; at \\\\&quot;/data/kube/docker/btrfs/subvolumes/7035bbf1baba2ef7cee552cd2fdda6841a22d4bdb62bd66b81f4b62c78b65735/run/xtables.lock\\\\&quot; caused \\\\&quot;not a directory\\\\&quot;\\&quot;\&quot;</span><br><span class="line">Aug 27 11:36:28 SUSESP5 bash[1684]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">Aug 27 11:36:38 SUSESP5 bash[2265]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">Aug 27 11:36:48 SUSESP5 bash[2272]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">Aug 27 11:36:59 SUSESP5 bash[2295]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">Aug 27 11:37:09 SUSESP5 bash[2327]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">Aug 27 11:37:19 SUSESP5 bash[2356]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">Aug 27 11:37:29 SUSESP5 bash[2385]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br><span class="line">Aug 27 11:37:40 SUSESP5 bash[2475]: stat: cannot stat &#x27;/run/xtables.lock&#x27;: No such file or directory</span><br></pre></td></tr></table></figure><p>从日志看出 rmdir 之前路径 <code>/run/xtables.lock</code> 确实不存在，那就不用逻辑或了，直接下面这样始终执行 iptables </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;rmdir /run/xtables.lock &amp;&gt;/dev/null || true; iptables -V 1&gt;/dev/null&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line">$ reboot</span><br></pre></td></tr></table></figure><p>结果还是变成目录，猜测了下应该试 suse 上的 iptables 某些情况不会生成锁文件。所以后面加个 touch 得了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ stat /run/xtables.lock</span><br><span class="line">  File: &#x27;/run/xtables.lock&#x27;</span><br><span class="line">  Size: 40        Blocks: 0          IO Block: 4096   directory</span><br><span class="line">Device: 16h/22dInode: 14292       Links: 2</span><br><span class="line">Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Access: 2021-08-27 11:41:08.309257362 +0800</span><br><span class="line">Modify: 2021-08-27 11:41:08.309257362 +0800</span><br><span class="line">Change: 2021-08-27 11:41:08.309257362 +0800</span><br><span class="line"> Birth: -</span><br><span class="line"></span><br><span class="line">$ vi /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;rmdir /run/xtables.lock &amp;&gt;/dev/null || true; iptables -V 1&gt;/dev/null; touch -m 0600 /run/xtables.lock&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">$ reboot</span><br></pre></td></tr></table></figure><p>结果可以了，但是 touch 的权限不生效</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ stat /run/xtables.lock </span><br><span class="line">  File: &#x27;/run/xtables.lock&#x27;</span><br><span class="line">  Size: 0         Blocks: 0          IO Block: 4096   regular empty file</span><br><span class="line">Device: 16h/22dInode: 12019       Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Access: 2021-08-27 11:50:30.056416389 +0800</span><br><span class="line">Modify: 2021-08-27 11:50:30.056416389 +0800</span><br><span class="line">Change: 2021-08-27 11:50:30.056416389 +0800</span><br><span class="line"> Birth: -</span><br></pre></td></tr></table></figure><p>最终的解决办法，加个 chmod ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/systemd/system/docker.service.d/10.docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;test -d /var/run/docker.sock &amp;&amp; rmdir /var/run/docker.sock || true&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;rmdir /run/xtables.lock &amp;&gt;/dev/null || true; iptables -V 1&gt;/dev/null; touch /run/xtables.lock&#x27;</span><br><span class="line">ExecStartPre=/bin/bash -c &#x27;chmod 0600 /run/xtables.lock&#x27;</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">$ reboot</span><br><span class="line"></span><br><span class="line">$ stat /run/xtables.lock</span><br><span class="line">  File: &#x27;/run/xtables.lock&#x27;</span><br><span class="line">  Size: 0         Blocks: 0          IO Block: 4096   regular empty file</span><br><span class="line">Device: 16h/22dInode: 26741       Links: 1</span><br><span class="line">Access: (0600/-rw-------)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Access: 2021-08-27 12:18:53.097143334 +0800</span><br><span class="line">Modify: 2021-08-27 12:18:53.097143334 +0800</span><br><span class="line">Change: 2021-08-27 12:18:53.101143334 +0800</span><br><span class="line"> Birth: -</span><br></pre></td></tr></table></figure><p>理论上可以用<code>ConditionPathIsDirectory=!/run/xtables.lock</code>，但是我就不去试了。主要是排错思路分享下。</p><h2 id="2021、08、30"><a href="#2021、08、30" class="headerlink" title="2021、08、30"></a>2021、08、30</h2><p>suse 这个 iptables 锁文件没生成可能是因为 iptables 是 1.40 版本开始加入了锁文件，suse sp12 和 Centos7.8 这个上面的 iptables 的版本是 v1.4.21 。测试了下 iptables -V 不会生成，而 1.8 版本的 iptables 带不带任何选项下都会没锁则创建锁文件。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h2&gt;&lt;p&gt;suse 这辣鸡系统，使用官方文档 docker-static 的二进制安装的话会无法起来，所以我们在 suse 上用的是很</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>flannel下集群有个节点网络不通的一次排查</title>
    <link href="http://zhangguanzhang.github.io/2021/08/25/flannel-a-host-net-tmout/"/>
    <id>http://zhangguanzhang.github.io/2021/08/25/flannel-a-host-net-tmout/</id>
    <published>2021-08-25T15:08:06.000Z</published>
    <updated>2021-08-25T15:08:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="故障"><a href="#故障" class="headerlink" title="故障"></a>故障</h2><p>问题和版本没关系，客户的 node 信息啥的后面排错里有。有个节点通信有问题，其余节点都没问题。</p><h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><h3 id="惯例信息"><a href="#惯例信息" class="headerlink" title="惯例信息"></a>惯例信息</h3><p>先看下 <code>flannel</code> 的 <code>vxlan</code> 的 <code>vtep</code> 信息，客户是双网卡的，但是默认路由是这个网卡，不用管另外的网卡了。下面信息看了下 <code>VtepMAC</code> 和 <code>public-ip</code> 都正常。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node -o yaml | grep -B4 public</span><br><span class="line">    annotations:</span><br><span class="line">      flannel.alpha.coreos.com/backend-data: &#x27;&#123;&quot;VtepMAC&quot;:&quot;76:21:69:41:de:fe&quot;&#125;&#x27;</span><br><span class="line">      flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">      flannel.alpha.coreos.com/kube-subnet-manager: &quot;true&quot;</span><br><span class="line">      flannel.alpha.coreos.com/public-ip: 10.25.1.51</span><br><span class="line">--</span><br><span class="line">    annotations:</span><br><span class="line">      flannel.alpha.coreos.com/backend-data: &#x27;&#123;&quot;VtepMAC&quot;:&quot;b6:61:5c:8d:d9:eb&quot;&#125;&#x27;</span><br><span class="line">      flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">      flannel.alpha.coreos.com/kube-subnet-manager: &quot;true&quot;</span><br><span class="line">      flannel.alpha.coreos.com/public-ip: 10.25.1.52</span><br><span class="line">--</span><br><span class="line">    annotations:</span><br><span class="line">      flannel.alpha.coreos.com/backend-data: &#x27;&#123;&quot;VtepMAC&quot;:&quot;1e:8c:3e:12:fc:0f&quot;&#125;&#x27;</span><br><span class="line">      flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">      flannel.alpha.coreos.com/kube-subnet-manager: &quot;true&quot;</span><br><span class="line">      flannel.alpha.coreos.com/public-ip: 10.25.1.53</span><br><span class="line">--</span><br><span class="line">    annotations:</span><br><span class="line">      flannel.alpha.coreos.com/backend-data: &#x27;&#123;&quot;VtepMAC&quot;:&quot;ba:fe:64:36:6e:a1&quot;&#125;&#x27;</span><br><span class="line">      flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">      flannel.alpha.coreos.com/kube-subnet-manager: &quot;true&quot;</span><br><span class="line">      flannel.alpha.coreos.com/public-ip: 10.25.1.54</span><br><span class="line">--</span><br><span class="line">    annotations:</span><br><span class="line">      flannel.alpha.coreos.com/backend-data: &#x27;&#123;&quot;VtepMAC&quot;:&quot;8e:c1:4d:18:e5:d6&quot;&#125;&#x27;</span><br><span class="line">      flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">      flannel.alpha.coreos.com/kube-subnet-manager: &quot;true&quot;</span><br><span class="line">      flannel.alpha.coreos.com/public-ip: 10.25.1.55</span><br><span class="line">--</span><br><span class="line">    annotations:</span><br><span class="line">      flannel.alpha.coreos.com/backend-data: &#x27;&#123;&quot;VtepMAC&quot;:&quot;fe:95:e6:bf:a0:62&quot;&#125;&#x27;</span><br><span class="line">      flannel.alpha.coreos.com/backend-type: vxlan</span><br><span class="line">      flannel.alpha.coreos.com/kube-subnet-manager: &quot;true&quot;</span><br><span class="line">      flannel.alpha.coreos.com/public-ip: 10.25.1.56</span><br></pre></td></tr></table></figure><p>coredns 的 pod ip 和 node 分布情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system get pod -o wide</span><br><span class="line">NAME                                  READY   STATUS    RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">coredns-5757945748-cr67w              1/1     Running   0          19h   172.27.2.7   10.25.1.56   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5757945748-krwfd              1/1     Running   0          19h   172.27.1.4   10.25.1.55   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5757945748-zf4zm              1/1     Running   0          19h   172.27.3.7   10.25.1.54   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h3 id="排查-1"><a href="#排查-1" class="headerlink" title="排查"></a>排查</h3><p>curl 下 coredns 的 metrics 接口试试，只有 <code>10.25.1.51</code> 和其他节点无法通信。会导致下面的 curl 卡住。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl  172.27.1.4:9153</span><br></pre></td></tr></table></figure><p>目标机器 <code>10.25.1.55</code> 上通过 flannel.1 接口抓我们的 curl 包:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -i flannel.1 host 172.27.1.4 and port 9153 -vv</span><br><span class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">10:07:46.203094 IP (tos 0x0, ttl 64, id 56025, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.27.0.0.57888 &gt; 172.27.1.4.9153: Flags [S], cksum 0x6804 (correct), seq 879302783, win 28200, options [mss 1410,sackOK,TS val 56279718 ecr 0,nop,wscale 7], length 0</span><br><span class="line">10:07:46.203173 IP (tos 0x0, ttl 63, id 0, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.27.1.4.9153 &gt; 172.27.0.0.57888: Flags [S.], cksum 0x5969 (incorrect -&gt; 0x163b), seq 4197245653, ack 879302784, win 27960, options [mss 1410,sackOK,TS val 431774697 ecr 56279718,nop,wscale 7], length 0</span><br><span class="line">10:07:47.204797 IP (tos 0x0, ttl 64, id 56026, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.27.0.0.57888 &gt; 172.27.1.4.9153: Flags [S], cksum 0x641a (correct), seq 879302783, win 28200, options [mss 1410,sackOK,TS val 56280720 ecr 0,nop,wscale 7], length 0</span><br><span class="line">10:07:47.204880 IP (tos 0x0, ttl 63, id 0, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.27.1.4.9153 &gt; 172.27.0.0.57888: Flags [S.], cksum 0x5969 (incorrect -&gt; 0x1251), seq 4197245653, ack 879302784, win 27960, options [mss 1410,sackOK,TS val 431775699 ecr 56279718,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure><p>看着是回复了报文 <code>172.27.1.4.9153 &gt; 172.27.0.0.57888</code>，在我们 curl 的机器 <code>10.25.1.51</code>上 <code>lsof -nPi :57888</code> 看到的确实是卡住的 curl 命令 pid 。<code>10.25.1.51</code> 上也同时抓包看下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -i flannel.1 host 172.27.1.4 and port 9153 -vv</span><br><span class="line">tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">10:08:57.241129 IP (tos 0x0, ttl 64, id 34444, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.27.0.0.57966 &gt; 172.27.1.4.9153: Flags [S], cksum 0x5969 (incorrect -&gt; 0x2fb2), seq 276913734, win 28200, options [mss 1410,sackOK,TS val 56350922 ecr 0,nop,wscale 7], length 0</span><br><span class="line">10:08:58.242423 IP (tos 0x0, ttl 64, id 34445, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.27.0.0.57966 &gt; 172.27.1.4.9153: Flags [S], cksum 0x5969 (incorrect -&gt; 0x2bc8), seq 276913734, win 28200, options [mss 1410,sackOK,TS val 56351924 ecr 0,nop,wscale 7], length 0</span><br><span class="line">10:09:00.246423 IP (tos 0x0, ttl 64, id 34446, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    172.27.0.0.57966 &gt; 172.27.1.4.9153: Flags [S], cksum 0x5969 (incorrect -&gt; 0x23f4), seq 276913734, win 28200, options [mss 1410,sackOK,TS val 56353928 ecr 0,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure><p>没收到包，从 <code>eth1</code> 抓下 <code>flannel</code> 的 <code>8475</code> 端口(配置里我们改了 flannel 的端口)试试:</p><p>目标机器 <code>10.25.1.55</code> 上抓包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -i eth1 host 10.25.1.51 and port 8475 -vvv</span><br><span class="line">tcpdump: listening on eth1, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">10:09:40.966705 IP (tos 0x0, ttl 64, id 50110, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.51.42770 &gt; 10.25.1.55.8475: [no cksum] UDP, length 82</span><br><span class="line">10:09:40.966869 IP (tos 0x0, ttl 64, id 46192, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.55.48472 &gt; 10.25.1.51.8475: [no cksum] UDP, length 82</span><br><span class="line">10:09:41.968322 IP (tos 0x0, ttl 64, id 50327, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.51.42770 &gt; 10.25.1.55.8475: [no cksum] UDP, length 82</span><br><span class="line">10:09:41.968440 IP (tos 0x0, ttl 64, id 46957, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.55.48472 &gt; 10.25.1.51.8475: [no cksum] UDP, length 82</span><br><span class="line">10:09:43.099646 IP (tos 0x0, ttl 64, id 47316, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.55.48472 &gt; 10.25.1.51.8475: [no cksum] UDP, length 82</span><br><span class="line">10:09:43.972322 IP (tos 0x0, ttl 64, id 51119, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.51.42770 &gt; 10.25.1.55.8475: [no cksum] UDP, length 82</span><br><span class="line">10:09:43.972454 IP (tos 0x0, ttl 64, id 47934, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.55.48472 &gt; 10.25.1.51.8475: [no cksum] UDP, length 82</span><br><span class="line">^C</span><br></pre></td></tr></table></figure><p>目标机器 <code>10.25.1.51</code> 上抓包:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -i eth1 host 10.25.1.55 and port 8475 -vvv</span><br><span class="line">tcpdump: listening on eth1, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">10:10:21.702308 IP (tos 0x0, ttl 64, id 6079, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.51.59558 &gt; 10.25.1.55.8475: [no cksum] UDP, length 82</span><br><span class="line">10:10:22.702441 IP (tos 0x0, ttl 64, id 6117, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.51.59558 &gt; 10.25.1.55.8475: [no cksum] UDP, length 82</span><br><span class="line">10:10:24.706444 IP (tos 0x0, ttl 64, id 7699, offset 0, flags [none], proto UDP (17), length 110)</span><br><span class="line">    10.25.1.51.59558 &gt; 10.25.1.55.8475: [no cksum] UDP, length 82</span><br></pre></td></tr></table></figure><p>完全没报文过来，看了下 <code>flannel</code> 的接口流量压根就没收到任何包:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ifconfig flannel.1</span><br><span class="line">flannel.1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 172.27.0.0  netmask 255.255.255.255  broadcast 0.0.0.0</span><br><span class="line">        inet6 fe80::7421:69ff:fe41:defe  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 76:21:69:41:de:fe  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 28900  bytes 2113052 (2.0 MiB)</span><br><span class="line">        TX errors 0  dropped 8 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p>说明报文从 <code>10.25.1.55</code> 发出后没到 51 上，让客户开通 <code>udp 8475 10.25.1.0/24</code> 整个段的东西向安全组后就正常了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ curl  172.27.1.4:9153</span><br><span class="line">^C</span><br><span class="line">$ curl  172.27.1.4:9153</span><br><span class="line">404 page not found</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;故障&quot;&gt;&lt;a href=&quot;#故障&quot; class=&quot;headerlink&quot; title=&quot;故障&quot;&gt;&lt;/a&gt;故障&lt;/h2&gt;&lt;p&gt;问题和版本没关系，客户的 node 信息啥的后面排错里有。有个节点通信有问题，其余节点都没问题。&lt;/p&gt;
&lt;h2 id=&quot;排查&quot;&gt;&lt;a hr</summary>
      
    
    
    
    
    <category term="flannel" scheme="http://zhangguanzhang.github.io/tags/flannel/"/>
    
    <category term="kubernetes" scheme="http://zhangguanzhang.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>一次 cni-plugins 导致集群 dns 无法解析的排错</title>
    <link href="http://zhangguanzhang.github.io/2021/08/24/cni-plugins-bridge-err/"/>
    <id>http://zhangguanzhang.github.io/2021/08/24/cni-plugins-bridge-err/</id>
    <published>2021-08-24T13:08:06.000Z</published>
    <updated>2021-08-24T13:08:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>环境是 1.15.5 的 x86_64 的 k8s 。命令输出被我查看日志给冲掉了，大致描述下。<br>中间件 kafka 无法连上 zookeeper ，看了下日志报错域名无法解析。看了下 coredns 都挂了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system get po -o wide -l k8s-app=kube-dns</span><br><span class="line">NAME                       READY   STATUS             RESTARTS   AGE     IP           NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">coredns-5757945748-l2d2g   0/1     CrashLoopBackOff   254        3d11h   172.27.0.2   10.25.1.55   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5757945748-w5pfx   0/1     CrashLoopBackOff   254        3d11h   172.27.0.5   10.25.1.55   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5757945748-wfndd   0/1     CrashLoopBackOff   254        3d11h   172.27.0.3   10.25.1.55   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>查看了日志是报错无法连 kubernetes svc <code>https://172.26.0.1:443/xxxx</code> ，报错 <code>No route to host</code></p><h2 id="排错"><a href="#排错" class="headerlink" title="排错"></a>排错</h2><h3 id="基本排查"><a href="#基本排查" class="headerlink" title="基本排查"></a>基本排查</h3><p>去节点 <code>10.25.1.55</code> 上 <code>docker ps -a | grep coredns</code> 找 pause 的容器 id ，<code>docker inspect xxxxx | grep -m1 -i pid</code> 取进程 pid。然后 nsenter 进去</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ nsenter --net --target 14659 </span><br><span class="line">$ ip a s </span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth0@if10: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP </span><br><span class="line">    link/ether 42:7d:b0:83:a9:aa brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.27.0.5/16 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>curl 了下 svc ip <code>https://172.26.0.1</code> 发现报错 <code>No route to host</code>。然后直接用 ep 也就是 kube-apiserver 的真实 ip和端口访问下，发现不通</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curk -kvL https://10.25.1.51:6443</span><br></pre></td></tr></table></figure><p>然后 ping 下宿主机发现也不通。看了下转发都开了。然后也看了下也没安全软件。</p><h3 id="桥接"><a href="#桥接" class="headerlink" title="桥接"></a>桥接</h3><p>然后看了下桥接发现了问题所在，先写下正常环境桥接信息。我们 flannel，不是二进制，容器都是在 cni-plugins 下桥接在 cni0 上的。下面找个正常环境的 coredns 做下信息展示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 取容器 pid</span><br><span class="line">$ docker inspect d30 | grep -m1 -i pid</span><br><span class="line">            &quot;Pid&quot;: 9079,</span><br><span class="line"></span><br><span class="line">$ nsenter --net --target 9079 ip a s </span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth0@if210: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default </span><br><span class="line">    link/ether 06:3e:42:00:91:33 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.27.0.74/24 brd 172.27.0.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>注意看 <code>if</code> 后面的数字，宿主机上查看下是哪个 <code>veth</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ip link | grep -E &#x27;^210&#x27;</span><br><span class="line">210: vetha1ca1d55@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default</span><br></pre></td></tr></table></figure><p>使用 brctl 看下 cni0 下是有这个的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brctl show cni0 | grep vetha1ca1d55</span><br><span class="line">vetha1ca1d55</span><br></pre></td></tr></table></figure><h4 id="机器异常的桥接信息"><a href="#机器异常的桥接信息" class="headerlink" title="机器异常的桥接信息"></a>机器异常的桥接信息</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ nsenter --net --target 14659 ip a s </span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth0@if10: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP </span><br><span class="line">    link/ether 42:7d:b0:83:a9:aa brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.27.0.5/16 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">$ ip -o link</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT qlen 1\    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1400 qdisc pfifo_fast state UP mode DEFAULT qlen 1000\    link/ether fa:16:3e:35:09:13 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000\    link/ether fa:16:3e:e2:4d:8d brd ff:ff:ff:ff:ff:ff</span><br><span class="line">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT \    link/ether 02:42:3c:a2:d7:3b brd ff:ff:ff:ff:ff:ff</span><br><span class="line">6: vethda399ca1@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT \    link/ether a2:95:74:65:29:6d brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">7: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT \    link/ether 0a:e5:a5:9a:66:8b brd ff:ff:ff:ff:ff:ff</span><br><span class="line">8: veth96d8f326@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT \    link/ether 92:a5:9c:7c:dd:cb brd ff:ff:ff:ff:ff:ff link-netnsid 1</span><br><span class="line">9: vethdf8eb371@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT \    link/ether 4a:fb:37:c3:f2:7e brd ff:ff:ff:ff:ff:ff link-netnsid 2</span><br><span class="line">10: veth44ce32f4@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT \    link/ether 6e:96:73:2b:4e:52 brd ff:ff:ff:ff:ff:ff link-netnsid 3</span><br><span class="line">11: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT qlen 1000\    link/ether 2a:f9:74:b7:11:b8 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">12: veth0f91b3a3@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT \    link/ether 0a:36:90:dc:0a:97 brd ff:ff:ff:ff:ff:ff link-netnsid 4</span><br></pre></td></tr></table></figure><p>查看了下 cni0 压根对不上 <code>veth44ce32f4</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ ip a s cni0</span><br><span class="line">11: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP qlen 1000</span><br><span class="line">    link/ether 2a:f9:74:b7:11:b8 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.27.1.1/24 scope global cni0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::28f9:74ff:feb7:11b8/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">$ brctl show</span><br><span class="line">bridge name     bridge id               STP enabled     interfaces</span><br><span class="line">cni0            8000.2af974b711b8       no              veth0f91b3a3</span><br><span class="line">docker0         8000.02423ca2d73b       no</span><br></pre></td></tr></table></figure><p>应该是桥接错了，重新创建下发现好了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system delete pod -l k8s-app=kube-dns</span><br><span class="line">pod &quot;coredns-5757945748-l2d2g&quot; deleted</span><br><span class="line">pod &quot;coredns-5757945748-wfndd&quot; deleted</span><br><span class="line">pod &quot;coredns-5757945748-wjrdf&quot; deleted</span><br><span class="line">$ kubectl -n kube-system get po -o wide -l k8s-app=kube-dns</span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">coredns-5757945748-4smll   1/1     Running   0          29s   172.27.1.3   10.25.1.55   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5757945748-d9wqk   1/1     Running   0          29s   172.27.3.6   10.25.1.54   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5757945748-dtvfl   1/1     Running   0          29s   172.27.2.6   10.25.1.56   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>现场拿了下 cni-plugins 的校验值去查了下，我们使用的是 <code>v0.7.0</code> 版本。有必要升级下了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;环境是 1.15.5 的 x86_64 的 k8s 。命令输出被我查看日志给冲掉了，大致描述下。&lt;br&gt;中间件 kafka 无法连上 zoo</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://zhangguanzhang.github.io/tags/kubernetes/"/>
    
    <category term="cni-plugins" scheme="http://zhangguanzhang.github.io/tags/cni-plugins/"/>
    
  </entry>
  
  <entry>
    <title>kubelet 为系统配置预留资源</title>
    <link href="http://zhangguanzhang.github.io/2021/08/16/reserve-compute-resources/"/>
    <id>http://zhangguanzhang.github.io/2021/08/16/reserve-compute-resources/</id>
    <published>2021-08-16T10:08:06.000Z</published>
    <updated>2021-08-16T10:08:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>我们环境有部分 pod 特殊，单独节点部署，oom 的时候会搞挂一些系统进程，这几天折腾了下配置了下 kubelet 相关的 <code>reserved</code>。主要是 kubelet 的配置文件一些参数，不写 systemd 里，全部写配置文件里。版本是如下，因为我们不单单是 <code>x86_64</code> ，由于还有其他的架构以及会部署在客户的现场，为了减少维护，所以我们都是除了 <code>flanneld</code> 和 <code>coredns</code> 以外。k8s 相关的二进制的形式部署的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl version -o json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;clientVersion&quot;: &#123;</span><br><span class="line">    &quot;major&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;minor&quot;: &quot;20&quot;,</span><br><span class="line">    &quot;gitVersion&quot;: &quot;v1.20.6&quot;,</span><br><span class="line">    &quot;gitCommit&quot;: &quot;8a62859e515889f07e3e3be6a1080413f17cf2c3&quot;,</span><br><span class="line">    &quot;gitTreeState&quot;: &quot;clean&quot;,</span><br><span class="line">    &quot;buildDate&quot;: &quot;2021-04-15T03:28:42Z&quot;,</span><br><span class="line">    &quot;goVersion&quot;: &quot;go1.15.10&quot;,</span><br><span class="line">    &quot;compiler&quot;: &quot;gc&quot;,</span><br><span class="line">    &quot;platform&quot;: &quot;linux/amd64&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;serverVersion&quot;: &#123;</span><br><span class="line">    &quot;major&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;minor&quot;: &quot;20&quot;,</span><br><span class="line">    &quot;gitVersion&quot;: &quot;v1.20.6&quot;,</span><br><span class="line">    &quot;gitCommit&quot;: &quot;8a62859e515889f07e3e3be6a1080413f17cf2c3&quot;,</span><br><span class="line">    &quot;gitTreeState&quot;: &quot;clean&quot;,</span><br><span class="line">    &quot;buildDate&quot;: &quot;2021-04-15T03:19:55Z&quot;,</span><br><span class="line">    &quot;goVersion&quot;: &quot;go1.15.10&quot;,</span><br><span class="line">    &quot;compiler&quot;: &quot;gc&quot;,</span><br><span class="line">    &quot;platform&quot;: &quot;linux/amd64&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>阅读本篇文章之前，推荐先浏览器同时打开这两篇官方文档后稍微看完再看本篇文章:</p><ul><li><a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/">官方文档</a> 和 </li><li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/node-allocatable.md">最初的设计文档</a></li></ul><h3 id="相关说明"><a href="#相关说明" class="headerlink" title="相关说明"></a>相关说明</h3><p>相关术语就是 <code>enforceNodeAllocatable</code> ，它的默认值是 <code>[&quot;pods&quot;]</code> ，也就是 pod 能够使用节点上所有资源。但是节点上除了自己以外还有 kubelet ，kube 的三个组件，container runtime engine，以及 systemd 纳管的一些系统进程。如果有个 node 达到资源满了被驱逐，可能会漂移到其他节点上，把其他节点也搞挂了，形成连锁雪崩的情况。根据 <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/node-allocatable.md">官方文档最开始的设计</a> 一个 node 的 allocate 为下面的情况，<code>Allocatable</code> 为 pod 的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Allocatable] = [Node Capacity] - [Kube-Reserved] - [System-Reserved] - [Hard-Eviction-Threshold]</span><br></pre></td></tr></table></figure><p>转换下就是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Node Capacity] = [Allocatable] + [Kube-Reserved] + [System-Reserved] + [Hard-Eviction-Threshold]</span><br></pre></td></tr></table></figure><p>节点上的 <code>Allocatable</code> 被定义为 pod 的可用计算资源量。 调度器不会超额申请 Allocatable。 目前支持 <code>CPU</code>, <code>memory</code> 和 <code>ephemeral-storage</code> 这几个参数。上面的 <code>Hard-Eviction</code> 是有默认值的。而由于下面默认值，我们需要加上 kube 和 system 的 reserved 。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">enforceNodeAllocatable:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">kube-reserved</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">system-reserved</span></span><br></pre></td></tr></table></figure><h2 id="尝试"><a href="#尝试" class="headerlink" title="尝试"></a>尝试</h2><p>加了上面俩后发现不生效，最后去看 yaml 里相关设置的参考后以及部分源码后摸索出来了。但是其实官方这块是有文档的: <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/">官方文档</a> 和 <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/node-allocatable.md">最初的设计文档</a></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">enforceNodeAllocatable:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">kube-reserved</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">system-reserved</span></span><br><span class="line"><span class="attr">evictionHard:</span></span><br><span class="line">  <span class="attr">imagefs.available:</span> <span class="string">&quot;15%&quot;</span></span><br><span class="line">  <span class="attr">memory.available:</span> <span class="string">&quot;200Mi&quot;</span></span><br><span class="line">  <span class="attr">nodefs.available:</span> <span class="string">&quot;10%&quot;</span></span><br><span class="line">  <span class="attr">nodefs.inodesFree:</span> <span class="string">&quot;5%&quot;</span></span><br><span class="line"><span class="attr">kubeReserved:</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">inventory_hostname</span> <span class="string">in</span> <span class="string">groups</span>[<span class="string">&#x27;kube_master&#x27;</span>] <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">400m</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">896Mi</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">256Mi</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">ephemeral-storage:</span> <span class="string">500Mi</span></span><br><span class="line"><span class="attr">systemReserved:</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">  <span class="attr">ephemeral-storage:</span> <span class="string">2Gi</span></span><br></pre></td></tr></table></figure><p>这个模板判断的灵感是来源于 kubespray ，<a href="https://github.com/kubernetes-sigs/kubespray/blob/master/roles/kubernetes/node/defaults/main.yml">defaults/main.yml</a> 和 <a href="https://github.com/kubernetes-sigs/kubespray/blob/master/roles/kubernetes/node/templates/kubelet-config.v1beta1.yaml.j2">templates/kubelet-config.v1beta1.yaml.j2</a><br>我们环境都是二进制，所以 master 上 kube 会多配置些。但是这样配置了看了下无法生效，看了下必须要配置 cgroup path。也就是下面的:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">enforceNodeAllocatable:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">kube-reserved</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">system-reserved</span></span><br><span class="line"><span class="attr">evictionHard:</span></span><br><span class="line">  <span class="attr">imagefs.available:</span> <span class="string">&quot;15%&quot;</span></span><br><span class="line">  <span class="attr">memory.available:</span> <span class="string">&quot;200Mi&quot;</span></span><br><span class="line">  <span class="attr">nodefs.available:</span> <span class="string">&quot;10%&quot;</span></span><br><span class="line">  <span class="attr">nodefs.inodesFree:</span> <span class="string">&quot;5%&quot;</span></span><br><span class="line"><span class="attr">kubeReserved:</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">inventory_hostname</span> <span class="string">in</span> <span class="string">groups</span>[<span class="string">&#x27;kube_master&#x27;</span>] <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">400m</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">896Mi</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">256Mi</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">ephemeral-storage:</span> <span class="string">500Mi</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kubeReservedCgroup:</span> <span class="string">/kube.slice</span></span><br><span class="line"><span class="attr">systemReserved:</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">  <span class="attr">ephemeral-storage:</span> <span class="string">2Gi</span></span><br><span class="line"><span class="attr">systemReservedCgroup:</span> <span class="string">/system.slice</span></span><br></pre></td></tr></table></figure><p>根据官方文档的示例值是俩不同的 path，但是市面上有不少人这方面的文章互相抄袭，他们会把 <code>kubeReservedCgroup: /system.slice/kube.slice</code> 嵌套下。配置了上面的后会发现依然无法启动报错下面的:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to start ContainerManager Failed to enforce Kube Reserved Cgroup Limits on &quot;/kube.slice&quot;: [&quot;kubelet&quot;] cgroup does not exist</span><br></pre></td></tr></table></figure><p>最后找了下相关源码 <a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/cgroup_manager_linux.go#L257">pkg/kubelet/cm/cgroup_manager_linux.go 的 func (m *cgroupManagerImpl) Exists(name CgroupName) bool </a> 方法，我们只关心下面的几个 cgroup 就行了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">allowlistControllers := sets.NewString(&quot;cpu&quot;, &quot;cpuacct&quot;, &quot;cpuset&quot;, &quot;memory&quot;, &quot;systemd&quot;, &quot;pids&quot;)</span><br><span class="line"></span><br><span class="line">if _, ok := m.subsystems.MountPoints[&quot;hugetlb&quot;]; ok &#123;</span><br><span class="line">allowlistControllers.Insert(&quot;hugetlb&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>市面上都是手动创建的不推荐，推荐在 kubelet 的 service 加个 <code>ExecStartPre</code> 和脚本判断处理。</p><h2 id="最终配置"><a href="#最终配置" class="headerlink" title="最终配置"></a>最终配置</h2><p>kubelet 的 service 文件参考:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=&#123;&#123; data_dir &#125;&#125;/kube/kubelet</span><br><span class="line">ExecStartPre=/bin/bash &#123;&#123; data_dir &#125;&#125;/kube/kubelet/kubelet-cg.sh</span><br><span class="line">ExecStart=&#123;&#123; bin_dir &#125;&#125;/kubelet \</span><br><span class="line">  --config=&#123;&#123; data_dir &#125;&#125;/kube/kubelet/kubelet-config.yaml \</span><br><span class="line">  --root-dir=&#123;&#123; data_dir &#125;&#125;/kube/kubelet \</span><br><span class="line">  --docker-root=&#123;&#123; data_dir &#125;&#125;/kube/docker \</span><br><span class="line">  --cni-bin-dir=&#123;&#123; bin_dir &#125;&#125; \</span><br><span class="line">  --cni-conf-dir=/etc/cni/net.d \</span><br><span class="line">  --hostname-override=&#123;&#123; inventory_hostname &#125;&#125; \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">  --network-plugin=cni \</span><br><span class="line">  --experimental-dockershim-root-directory=&#123;&#123; data_dir &#125;&#125;/kube/dockershim \</span><br><span class="line">  --pod-infra-container-image=registry.aliyuncs.com/k8sxio/pause:3.5 \</span><br><span class="line">  --register-node=true \</span><br><span class="line">  --v=2 \</span><br><span class="line">  --node-ip=&#123;&#123; inventory_hostname &#125;&#125;</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>我们的环境目前还是 cgroupfs ， systemd 的可能需要你自己去摸索了。下面是 <code>kubelet-cg.sh</code> 和 <code>kubelet-config.yaml</code>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/kubelet/config/v1beta1/types.go</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeletConfiguration</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubelet.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="comment"># Default: []</span></span><br><span class="line"><span class="attr">allowedUnsafeSysctls:</span> []</span><br><span class="line"><span class="attr">address:</span> &#123;&#123; <span class="string">inventory_hostname</span> &#125;&#125;</span><br><span class="line"><span class="attr">authentication:</span></span><br><span class="line">  <span class="attr">anonymous:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheTTL:</span> <span class="string">2m0s</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">x509:</span></span><br><span class="line">    <span class="attr">clientCAFile:</span> &#123;&#123; <span class="string">ca_dir</span> &#125;&#125;<span class="string">/ca.pem</span></span><br><span class="line"><span class="attr">authorization:</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">Webhook</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheAuthorizedTTL:</span> <span class="string">5m0s</span></span><br><span class="line">    <span class="attr">cacheUnauthorizedTTL:</span> <span class="string">30s</span></span><br><span class="line"><span class="attr">tlsCertFile:</span> &#123;&#123; <span class="string">ca_dir</span> &#125;&#125;<span class="string">/kubelet.pem</span></span><br><span class="line"><span class="attr">tlsPrivateKeyFile:</span> &#123;&#123; <span class="string">ca_dir</span> &#125;&#125;<span class="string">/kubelet-key.pem</span></span><br><span class="line"><span class="attr">cgroupDriver:</span> <span class="string">cgroupfs</span></span><br><span class="line"><span class="attr">cgroupsPerQOS:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">clusterDNS:</span></span><br><span class="line">  <span class="bullet">-</span> &#123;&#123; <span class="string">CLUSTER_DNS_SVC_IP</span> &#125;&#125;</span><br><span class="line"><span class="attr">clusterDomain:</span> &#123;&#123; <span class="string">CLUSTER_DNS_DOMAIN</span> &#125;&#125;</span><br><span class="line"><span class="attr">configMapAndSecretChangeDetectionStrategy:</span> <span class="string">Watch</span></span><br><span class="line"><span class="attr">containerLogMaxFiles:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">containerLogMaxSize:</span> <span class="string">10Mi</span></span><br><span class="line"><span class="attr">contentType:</span> <span class="string">application/vnd.kubernetes.protobuf</span></span><br><span class="line"><span class="attr">cpuCFSQuota:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Default: &quot;100ms&quot; The value must be between 1 us and 1 second</span></span><br><span class="line"><span class="attr">cpuCFSQuotaPeriod:</span> <span class="string">100ms</span></span><br><span class="line"><span class="attr">cpuManagerPolicy:</span> <span class="string">none</span></span><br><span class="line"><span class="attr">cpuManagerReconcilePeriod:</span> <span class="string">10s</span></span><br><span class="line"><span class="attr">enableControllerAttachDetach:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Default: true</span></span><br><span class="line"><span class="attr">enableDebuggingHandlers:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Default: true</span></span><br><span class="line"><span class="attr">enableSystemLogHandler:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Default: [&quot;pods&quot;]</span></span><br><span class="line"><span class="comment"># https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/node-allocatable.md</span></span><br><span class="line"><span class="comment"># pkg/kubelet/cm/node_container_manager_linux.go:67</span></span><br><span class="line"><span class="attr">enforceNodeAllocatable:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">kube-reserved</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">system-reserved</span></span><br><span class="line"><span class="comment"># Default: 10</span></span><br><span class="line"><span class="attr">eventBurst:</span> <span class="number">100</span></span><br><span class="line"><span class="comment"># Default: 5</span></span><br><span class="line"><span class="attr">eventRecordQPS:</span> <span class="number">50</span></span><br><span class="line"><span class="comment"># Default:</span></span><br><span class="line"><span class="comment">#   memory.available:  &quot;100Mi&quot;</span></span><br><span class="line"><span class="comment">#   nodefs.available:  &quot;10%&quot;</span></span><br><span class="line"><span class="comment">#   nodefs.inodesFree: &quot;5%&quot;</span></span><br><span class="line"><span class="comment">#   imagefs.available: &quot;15%&quot;</span></span><br><span class="line"><span class="attr">evictionHard:</span></span><br><span class="line">  <span class="attr">imagefs.available:</span> <span class="string">&quot;15%&quot;</span></span><br><span class="line">  <span class="attr">memory.available:</span> <span class="string">&quot;200Mi&quot;</span></span><br><span class="line">  <span class="attr">nodefs.available:</span> <span class="string">&quot;10%&quot;</span></span><br><span class="line">  <span class="attr">nodefs.inodesFree:</span> <span class="string">&quot;5%&quot;</span></span><br><span class="line"><span class="attr">evictionPressureTransitionPeriod:</span> <span class="string">5m0s</span></span><br><span class="line"><span class="attr">failSwapOn:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Default: &quot;20s&quot;</span></span><br><span class="line"><span class="attr">fileCheckFrequency:</span> <span class="string">10s</span></span><br><span class="line"><span class="comment"># Default: &quot;promiscuous-bridge&quot;</span></span><br><span class="line"><span class="attr">hairpinMode:</span> <span class="string">promiscuous-bridge</span></span><br><span class="line"><span class="attr">healthzPort:</span> <span class="number">10248</span></span><br><span class="line"><span class="comment"># Default: &quot;127.0.0.1&quot;</span></span><br><span class="line"><span class="attr">healthzBindAddress:</span> &#123;&#123; <span class="string">inventory_hostname</span> &#125;&#125;</span><br><span class="line"><span class="comment"># Default: &quot;20s&quot;, staticPodUrl 才有用</span></span><br><span class="line"><span class="attr">httpCheckFrequency:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">imageGCHighThresholdPercent:</span> <span class="number">85</span></span><br><span class="line"><span class="attr">imageGCLowThresholdPercent:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">imageMinimumGCAge:</span> <span class="string">2m0s</span></span><br><span class="line"><span class="comment"># Default: 15</span></span><br><span class="line"><span class="attr">iptablesDropBit:</span> <span class="number">15</span></span><br><span class="line"><span class="comment"># Default: 14</span></span><br><span class="line"><span class="attr">iptablesMasqueradeBit:</span> <span class="number">14</span></span><br><span class="line"><span class="comment"># Default: 10</span></span><br><span class="line"><span class="attr">kubeAPIBurst:</span> <span class="number">100</span></span><br><span class="line"><span class="comment"># Default: 5</span></span><br><span class="line"><span class="attr">kubeAPIQPS:</span> <span class="number">50</span></span><br><span class="line"><span class="comment"># https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/</span></span><br><span class="line"><span class="comment"># https://github.com/kubernetes-sigs/kubespray/blob/master/roles/kubernetes/node/defaults/main.yml</span></span><br><span class="line"><span class="comment"># https://github.com/kubernetes-sigs/kubespray/blob/master/roles/kubernetes/node/templates/kubelet-config.v1beta1.yaml.j2</span></span><br><span class="line"><span class="comment"># Default: nil</span></span><br><span class="line"><span class="attr">kubeReserved:</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">inventory_hostname</span> <span class="string">in</span> <span class="string">groups</span>[<span class="string">&#x27;kube_master&#x27;</span>] <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">400m</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">896Mi</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">256Mi</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">ephemeral-storage:</span> <span class="string">500Mi</span></span><br><span class="line"><span class="comment"># pkg/kubelet/cm/cgroup_manager_linux.go:257 func (m *cgroupManagerImpl) Exists(name CgroupName) bool &#123;</span></span><br><span class="line"><span class="attr">kubeReservedCgroup:</span> <span class="string">/kube.slice</span></span><br><span class="line"><span class="attr">systemReserved:</span></span><br><span class="line">  <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">  <span class="attr">ephemeral-storage:</span> <span class="string">2Gi</span></span><br><span class="line"><span class="attr">systemReservedCgroup:</span> <span class="string">/system.slice</span></span><br><span class="line"><span class="attr">makeIPTablesUtilChains:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Default: 1000000</span></span><br><span class="line"><span class="attr">maxOpenFiles:</span> <span class="number">1000000</span></span><br><span class="line"><span class="comment"># Default: 110</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">set</span> <span class="string">nodeLen</span> <span class="string">=</span> <span class="string">groups</span>[<span class="string">&#x27;kube_node&#x27;</span>] <span class="string">|</span> <span class="string">length</span> <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">nodeLen</span> <span class="string">==</span> <span class="number">1</span> <span class="string">%</span>&#125;</span><br><span class="line"><span class="attr">maxPods:</span> <span class="number">253</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">elif</span> <span class="string">nodeLen</span> <span class="string">&lt;</span> <span class="number">3</span> <span class="string">%</span>&#125;</span><br><span class="line"><span class="attr">maxPods:</span> <span class="number">200</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">elif</span> <span class="string">nodeLen</span> <span class="string">&gt;=</span> <span class="number">3</span> <span class="string">and</span> <span class="string">nodeLen</span> <span class="string">&lt;=6</span> <span class="string">%</span>&#125;</span><br><span class="line"><span class="attr">maxPods:</span> <span class="number">150</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;</span><br><span class="line"><span class="attr">maxPods:</span> <span class="number">110</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line"><span class="comment"># Default: 40</span></span><br><span class="line"><span class="attr">nodeLeaseDurationSeconds:</span> <span class="number">40</span> <span class="comment"># 看源码乘以了0.25 作为更新间隔了</span></span><br><span class="line"><span class="comment"># Default: &quot;5m&quot; # 节点状态没有更改时候的上报频率，如果有更改就立即更新。NodeLease 启用下它才有用。如果设置了 nodeStatusUpdateFrequency 则它的默认值等于它来向后兼容</span></span><br><span class="line"><span class="attr">nodeStatusReportFrequency:</span> <span class="string">1m0s</span></span><br><span class="line"><span class="attr">nodeStatusUpdateFrequency:</span> <span class="string">10s</span></span><br><span class="line"><span class="attr">oomScoreAdj:</span> <span class="number">-999</span></span><br><span class="line"><span class="attr">podPidsLimit:</span> <span class="number">-1</span></span><br><span class="line"><span class="attr">port:</span> <span class="number">10250</span></span><br><span class="line"><span class="attr">readOnlyPort:</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># Default: 10</span></span><br><span class="line"><span class="attr">registryBurst:</span> <span class="number">20</span></span><br><span class="line"><span class="comment"># Default: 5</span></span><br><span class="line"><span class="attr">registryPullQPS:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">resolvConf:</span> &#123;<span class="string">%</span> <span class="string">if</span> <span class="string">ansible_distribution</span> <span class="string">==</span> <span class="string">&quot;Ubuntu&quot;</span> <span class="string">and</span> <span class="string">ansible_distribution_major_version|int</span> <span class="string">&gt;</span> <span class="number">16</span> <span class="string">%</span>&#125;<span class="string">/run/systemd/resolve/resolv.conf</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;<span class="string">/etc/resolv.conf</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line"><span class="attr">rotateCertificates:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Default: &quot;2m&quot;</span></span><br><span class="line"><span class="attr">runtimeRequestTimeout:</span> <span class="string">2m0s</span></span><br><span class="line"><span class="attr">serializeImagePulls:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">staticPodPath:</span> <span class="string">/etc/kubernetes/manifests</span></span><br><span class="line"><span class="comment"># Default: &quot;4h&quot;</span></span><br><span class="line"><span class="attr">streamingConnectionIdleTimeout:</span> <span class="string">20m0s</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># shutdownGracePeriod: 30s</span></span><br><span class="line"><span class="comment"># shutdownGracePeriodCriticalPods: 10s    # 1.21后的特性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Default: &quot;1m&quot; # sync for ConfigMaps and Secrets.</span></span><br><span class="line"><span class="attr">syncFrequency:</span> <span class="string">1m0s</span></span><br><span class="line"><span class="attr">volumeStatsAggPeriod:</span> <span class="string">1m0s</span></span><br><span class="line"><span class="attr">volumePluginDir:</span> <span class="string">/usr/libexec/kubernetes/kubelet-plugins/volume/exec/</span></span><br><span class="line"><span class="attr">tlsCipherSuites:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">TLS_RSA_WITH_AES_128_GCM_SHA256</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">TLS_RSA_WITH_AES_256_GCM_SHA384</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">TLS_RSA_WITH_AES_128_CBC_SHA</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">TLS_RSA_WITH_AES_256_CBC_SHA</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">check_and_create</span></span>()&#123;</span><br><span class="line"><span class="comment"># pkg/kubelet/cm/cgroup_manager_linux.go:257  func (m *cgroupManagerImpl) Exists(name CgroupName) bool &#123;</span></span><br><span class="line">    <span class="built_in">local</span> cg_controller=<span class="variable">$1</span></span><br><span class="line">    <span class="keyword">if</span> mountpoint -q /sys/fs/cgroup/<span class="variable">$&#123;cg_controller&#125;</span>;<span class="keyword">then</span></span><br><span class="line">        mkdir -p /sys/fs/cgroup/<span class="variable">$&#123;cg_controller&#125;</span>/system.slice</span><br><span class="line">        mkdir -p /sys/fs/cgroup/<span class="variable">$&#123;cg_controller&#125;</span>/kube.slice</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">check_and_create cpu</span><br><span class="line">check_and_create cpuacct</span><br><span class="line">check_and_create cpuset</span><br><span class="line">check_and_create memory</span><br><span class="line">check_and_create systemd</span><br><span class="line">check_and_create pids</span><br><span class="line">check_and_create hugetlb</span><br></pre></td></tr></table></figure><p>关于 pod 数量这块和大佬讨论了下，<code>maxPods</code> 大了的话实际上例如 docker 撑不住，所以没必要太大，我的判断逻辑是节点数量少的时候也就是我们内部的测试环境下，pod 数量调大，客户现场还是推荐的 110。</p><h2 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h2><p>2021/08/23 内部很多机器配置不一致，然后上面的配置会导致起不来，而且我理解错了 <code>enforceNodeAllocatable</code> 的意思了，我以为它是开关，实际上是给这几个创建 cgroup。reserved 配置了就会减去分配的配额，它开了就会强制 cgroup 限制 kube 和 systemd 来预留，也是不推荐配置的。取消它的配置为下面相关：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#ExecStartPre=/bin/bash &#123;&#123; data_dir &#125;&#125;/kube/kubelet/kubelet-cg.sh</span><br><span class="line"></span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">  - pods</span><br><span class="line">#  - kube-reserved</span><br><span class="line">#  - system-reserved</span><br></pre></td></tr></table></figure><h2 id="oom-killer"><a href="#oom-killer" class="headerlink" title="oom killer"></a>oom killer</h2><p>当系统内存不足时候，内核会调用 <a href="https://lwn.net/Articles/317814/">oom-killer</a> 来选择讲一些进程杀掉，以便能回收一些内存，尽量继续保持系统继续运行。具体选择哪个进程杀掉，这有一套算分的策略，参考因子是进程占用的内存数，进程页表占用的内存数等，<code>oom_score_adj</code> 的值越小，进程得分越少，也就越难被杀掉。它的计算公式大概类似下面，<code>oom_score</code>的取值为[0,1000]，而 <code>oom_score_adj</code> 的取值为[-1000,1000] ，<code>oom_score_adj</code> 是给我们调整的，例如我们不希望某些进程被 oom-killer 杀掉，可以调整它的 <code>oom_score_adj</code> 为 <code>-1000</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oom_score = 内存消耗/总内存 *1000 # 这个不完全对，实际还有 cpu 实际和存活时间</span><br></pre></td></tr></table></figure><p>其中<br>内存消耗包括了：常驻内存RSS + 进程页面 +交换内存<br>总内存就简单了：总的物理内存 +交换分区</p><h3 id="k8s-的-qosClass"><a href="#k8s-的-qosClass" class="headerlink" title="k8s 的 qosClass"></a>k8s 的 qosClass</h3><p>Kubernetes 创建 Pod 时就给它指定了下列三种 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/quality-service-pod/">QoS 类</a>：</p><ul><li>Guaranteed - limit 的 cpu 和 memory 必须设置，并且 request cpu 和 limit 下 cpu 要一样数值，memory 也一样。只设置 limit 的 cpu 和 memory，k8s 会设置与之一样的 requests</li><li>Burstable - 不满足 Guaranteed ，并且 Pod 中至少一个容器具有 memory 或 CPU 请求，limit 和 request 里的 cpu 或者 内存请求数值相等和不相等都没关系</li><li>BestEffort - 所有容器都没有设置 memory 和 CPU 限制或请求</li></ul><p>查看了下，目前我们所有业务 pod 都没配置限制，也就是 <code>BestEffort</code>。下面命令查看 ns 下 pod 的 qosClass</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -o yaml | grep qosClass</span><br></pre></td></tr></table></figure><h3 id="节点-OOM-行为和-qosClass-的-oom-score-adj"><a href="#节点-OOM-行为和-qosClass-的-oom-score-adj" class="headerlink" title="节点 OOM 行为和 qosClass 的 oom_score_adj"></a>节点 OOM 行为和 qosClass 的 oom_score_adj</h3><p>根据<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource/#%E8%8A%82%E7%82%B9-oom-%E8%A1%8C%E4%B8%BA">官方文档，节点 oom 的行为</a> 为：</p><p>如果节点在 <code>kubelet</code> 回收内存之前经历了系统 OOM（内存不足）事件，它将基于 <a href="https://lwn.net/Articles/391222/">oom-killer</a> 做出响应。</p><p><code>kubelet</code> 基于 pod 的 service 质量为每个容器设置一个 <code>oom_score_adj</code> 值，这个值在容器创建的时候设置的。</p><table><thead><tr><th>Service 质量</th><th>oom_score_adj</th></tr></thead><tbody><tr><td><code>Guaranteed</code></td><td>-997</td></tr><tr><td><code>Burstable</code></td><td>min(max(2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999)</td></tr><tr><td><code>BestEffort</code></td><td>1000</td></tr></tbody></table><p>如果 <code>kubelet</code> 在节点经历系统 OOM 之前无法回收内存，<code>oom_killer</code> 将基于它在节点上<br>使用的内存百分比算出一个 <code>oom_score</code>，并加上 <code>oom_score_adj</code> 得到容器的有效<br><code>oom_score</code>，然后结束得分最高的容器。</p><p>预期的行为应该是拥有最低服务质量并消耗和调度请求相关内存量最多的容器第一个被结束，以回收内存。</p><p>和 pod 驱逐不同，如果一个 Pod 的容器是被 OOM 结束的，基于其 <code>RestartPolicy</code>，<br>它可能会被 <code>kubelet</code> 重新启动。</p><p>在文件 <a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/kuberuntime_container_linux.go#L53">pkg/kubelet/kuberuntime/kuberuntime_container_linux.go</a> 里的 <code>generateLinuxContainerConfig</code> 和 <a href="https://github.com/kubernetes/kubernetes/blob/d385d0602a1075837bf8713b9f56964c154aede7/pkg/kubelet/qos/policy.go#L40">GetContainerOOMScoreAdjust</a> 可以去了解更多细节。</p><p>主要是 <code>oomScoreAdjust := 1000 - (1000 * container.Resources.Requests.Memory().Value())/memoryCapacity</code>。<br><code>memoryCapacity</code> 是机器的物理内存大小，而不是减去预留后的。最小值就是避免 <code>memoryRequest</code> / <code>机器内存</code> 趋近于 0 ，最大值避免 <code>oomScoreAdjust</code> 等于了最大值 1000 了。 kubelet 和 docker 通常会把他们自身的 <code>oom_score_adj</code> 设置为 <code>-999</code>。</p><p>可以得出一个结论：在非 <code>Guaranteed</code> 和 request 和 limit 为空的 <code>BestEffort</code> 以外，request 内存越大则 <code>oom_score_adj</code> 越小。<code>oom_score_adj</code> 越小， oom 的时候最不会被 oom-kill 杀掉。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在 32G 的机器上，空闲占用 1G ，我们部署几个 pod 都分为三个 qos 组，每个 都是 12G 的内存请求，看看哪个最先被杀掉 :</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-12-guaranteed</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:0.13.03</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-12-Guaranteed</span></span><br><span class="line"><span class="string">        exec /stress-12-Guaranteed --vm 4  --vm-bytes 12G</span></span><br><span class="line"><span class="string"></span>    <span class="attr">resources:</span></span><br><span class="line">     <span class="attr">limits:</span></span><br><span class="line">       <span class="attr">memory:</span> <span class="string">&quot;13Gi&quot;</span></span><br><span class="line">       <span class="attr">cpu:</span> <span class="string">&quot;300m&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-12-burstable</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:0.13.03</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-12-Burstable</span></span><br><span class="line"><span class="string">        exec /stress-12-Burstable --vm 4  --vm-bytes 12G</span></span><br><span class="line"><span class="string"></span>    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;10Mi&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-12-besteffort</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:0.13.03</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-12-BestEffort</span></span><br><span class="line"><span class="string">        exec /stress-12-BestEffort --vm 4  --vm-bytes 12G</span></span><br><span class="line"><span class="string"></span><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br></pre></td></tr></table></figure><p>创建完后，通过系统日志查看是对的，oom-killer 杀掉的确实是 <code>stress-12-besteffort</code> </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[80389.171797] Memory cgroup out of memory: Kill process 27672 (stress-12-BestE) score 1105 or sacrifice child</span><br><span class="line">[80389.202470] Killed process 27672 (stress-12-BestE), UID 0, total-vm:3189272kB, anon-rss:3145848kB, file-rss:4kB, shmem-rss:8kB</span><br><span class="line">[80391.538015] stress-12-BestE invoked oom-killer: gfp_mask=0xd0, order=0, oom_score_adj=1000</span><br><span class="line">[80391.538021] stress-12-BestE cpuset=597912cbecd66eccbd66c62dfd354bf5497db8e27a5bb04672ee5a84f217fbff mems_allowed=0-3</span><br><span class="line">[80391.538026] CPU: 6 PID: 27991 Comm: stress-12-BestE Kdump: loaded Tainted: G               ------------ T 3.10.0-1127.el7.x86_64 #1</span><br><span class="line">[80391.538028] Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 09/21/2015</span><br><span class="line">[80391.538030] Call Trace:</span><br><span class="line">[80391.538041]  [&lt;ffffffff8497ff85&gt;] dump_stack+0x19/0x1b</span><br><span class="line">[80391.538045]  [&lt;ffffffff8497a8a3&gt;] dump_header+0x90/0x229</span><br><span class="line">[80391.538051]  [&lt;ffffffff8449c4a8&gt;] ? ep_poll_callback+0xf8/0x220</span><br><span class="line">[80391.538057]  [&lt;ffffffff843c246e&gt;] oom_kill_process+0x25e/0x3f0</span><br><span class="line">[80391.538062]  [&lt;ffffffff84333a41&gt;] ? cpuset_mems_allowed_intersects+0x21/0x30</span><br><span class="line">[80391.538067]  [&lt;ffffffff84440ba6&gt;] mem_cgroup_oom_synchronize+0x546/0x570</span><br><span class="line">[80391.538071]  [&lt;ffffffff84440020&gt;] ? mem_cgroup_charge_common+0xc0/0xc0</span><br><span class="line">[80391.538075]  [&lt;ffffffff843c2d14&gt;] pagefault_out_of_memory+0x14/0x90</span><br><span class="line">[80391.538078]  [&lt;ffffffff84978db3&gt;] mm_fault_error+0x6a/0x157</span><br><span class="line">[80391.538082]  [&lt;ffffffff8498d8d1&gt;] __do_page_fault+0x491/0x500</span><br><span class="line">[80391.538086]  [&lt;ffffffff8498d975&gt;] do_page_fault+0x35/0x90</span><br><span class="line">[80391.538091]  [&lt;ffffffff84989778&gt;] page_fault+0x28/0x30</span><br></pre></td></tr></table></figure><p>再测试下下面这种内存大小不一致的</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-20-guaranteed</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:0.13.03</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-20-Guaranteed</span></span><br><span class="line"><span class="string">        exec /stress-20-Guaranteed --vm 4  --vm-bytes 20G</span></span><br><span class="line"><span class="string"></span>    <span class="attr">resources:</span></span><br><span class="line">     <span class="attr">limits:</span></span><br><span class="line">       <span class="attr">memory:</span> <span class="string">&quot;24Gi&quot;</span></span><br><span class="line">       <span class="attr">cpu:</span> <span class="string">&quot;4000m&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-8-burstable</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:0.13.03</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-8-Burstable</span></span><br><span class="line"><span class="string">        exec /stress-8-Burstable --vm 4  --vm-bytes 8G</span></span><br><span class="line"><span class="string"></span>    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;300Mi&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-4-besteffort</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:0.13.03</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-4-BestEffort</span></span><br><span class="line"><span class="string">        exec /stress-4-BestEffort --vm 2  --vm-bytes 4G</span></span><br><span class="line"><span class="string"></span><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br></pre></td></tr></table></figure><p>查看日志，<code>stress-20-Guara</code> 被杀掉了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941467] stress-20-Guara invoked oom-killer: gfp_mask=0x50, order=0, oom_score_adj=1000</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941472] stress-20-Guara cpuset=4be3661456aa74304875c3a00646851baea21be3e0667e84dad7ae812d3d0169 mems_allowed=0-3</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941476] CPU: 8 PID: 10195 Comm: stress-20-Guara Kdump: loaded Tainted: G               ------------ T 3.10.0-1127.el7.x86_64 #1</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941478] Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 09/21/2015</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941479] Call Trace:</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941492]  [&lt;ffffffff8497ff85&gt;] dump_stack+0x19/0x1b</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941495]  [&lt;ffffffff8497a8a3&gt;] dump_header+0x90/0x229</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941502]  [&lt;ffffffff8449c4a8&gt;] ? ep_poll_callback+0xf8/0x220</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941508]  [&lt;ffffffff843c246e&gt;] oom_kill_process+0x25e/0x3f0</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941512]  [&lt;ffffffff84333a41&gt;] ? cpuset_mems_allowed_intersects+0x21/0x30</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941518]  [&lt;ffffffff84440ba6&gt;] mem_cgroup_oom_synchronize+0x546/0x570</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941520]  [&lt;ffffffff84440020&gt;] ? mem_cgroup_charge_common+0xc0/0xc0</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941523]  [&lt;ffffffff843c2d14&gt;] pagefault_out_of_memory+0x14/0x90</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941525]  [&lt;ffffffff84978db3&gt;] mm_fault_error+0x6a/0x157</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941529]  [&lt;ffffffff8498d8d1&gt;] __do_page_fault+0x491/0x500</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941531]  [&lt;ffffffff8498d975&gt;] do_page_fault+0x35/0x90</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941534]  [&lt;ffffffff84989778&gt;] page_fault+0x28/0x30</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941538] Task in /kubepods/podff2a4320-67f9-4afc-b1a8-0aa39caa8904/4be3661456aa74304875c3a00646851baea21be3e0667e84dad7ae812d3d0169 killed as a result of limit of /kubepods</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941540] memory: usage 29763384kB, limit 29763384kB, failcnt 734923</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941542] memory+swap: usage 29763384kB, limit 9007199254740988kB, failcnt 0</span><br><span class="line">Sep 28 09:54:39 82-174-zhang kernel: [140244.941543] kmem: usage 0kB, limit 9007199254740988kB, failcnt 0</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>按理说不应该被杀掉。查看下进程的 <code>oom_score_adj</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ ps aux | grep stress-20-Guar[a]</span><br><span class="line">root     10146  0.0  0.0  43540  2468 ?        Ss   09:54   0:00 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     10181  0.0  0.0  43544   308 ?        S    09:54   0:00 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     10184  0.0  0.0  43544   272 ?        S    09:54   0:00 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     10186  0.0  0.0  43544   276 ?        S    09:54   0:00 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     10188  0.1  0.0  43544   348 ?        S    09:54   0:00 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     11024 99.7 15.9 5286424 5243196 ?     R    09:56   1:23 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     11491 98.6 15.9 5286424 5243164 ?     R    09:57   0:23 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     11539  103 15.9 5286424 5243168 ?     R    09:57   0:16 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">root     11610  101 15.9 5286424 5243192 ?     R    09:57   0:09 /stress-20-Guaranteed --vm 4 --vm-bytes 20G</span><br><span class="line">$ pstree -sp 10146</span><br><span class="line">systemd(1)───dockerd(751)───containerd(838)───containerd-shim(10099)───stress-20-Guara(10146)─┬─stress-20-Guara(10181)───stress-20-Guara(11610)</span><br><span class="line">                                                                                              ├─stress-20-Guara(10184)───stress-20-Guara(11491)</span><br><span class="line">                                                                                              ├─stress-20-Guara(10186)───stress-20-Guara(11539)</span><br><span class="line">                                                                                              └─stress-20-Guara(10188)───stress-20-Guara(11024)</span><br><span class="line">$ cat /proc/11024/oom_score</span><br><span class="line">1160</span><br><span class="line">$ cat /proc/11024/oom_score_adj </span><br><span class="line">1000</span><br><span class="line">$ cat /proc/10146/oom_score</span><br><span class="line">0</span><br><span class="line">$ cat /proc/10146/oom_score_adj </span><br><span class="line">-997</span><br></pre></td></tr></table></figure><p>docker run 个看看 <code>oom_score_adj</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name test  --oom-score-adj -998 nginx:alpine</span><br><span class="line">$ docker exec test cat /proc/*/oom_score_adj</span><br><span class="line">-998</span><br><span class="line">-998</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>最后稍微看了下 <a href="https://github.com/ColinIanKing/stress-ng/blob/802f8afb4f508fb166234bfb7c519f0d3670c860/core-out-of-memory.c">stress-ng 源码</a> 发现了 stress-ng 会设置子进程的 <code>oom_score_adj</code> 成 1000。容器里进程只能增加 <code>oom_score_adj</code> ，不能减少，stress-ng 这块应该是没考虑到容器的情况，已经反馈 <a href="https://github.com/ColinIanKing/stress-ng/issues/150">issue</a> 了。</p><h3 id="no-oom-adjust"><a href="#no-oom-adjust" class="headerlink" title="no-oom-adjust"></a>no-oom-adjust</h3><p>stress-ng 的作者经过 <a href="https://github.com/ColinIanKing/stress-ng/issues/150">issue反馈后</a> 添加了 <code>--no-oom-adjust</code> 选项了，可以继续上面的测试了:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-20-guaranteed</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:temp</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-20-Guaranteed</span></span><br><span class="line"><span class="string">        exec /stress-20-Guaranteed --vm 4  --vm-bytes 20G --no-oom-adjust</span></span><br><span class="line"><span class="string"></span>    <span class="attr">resources:</span></span><br><span class="line">     <span class="attr">limits:</span></span><br><span class="line">       <span class="attr">memory:</span> <span class="string">&quot;22Gi&quot;</span></span><br><span class="line">       <span class="attr">cpu:</span> <span class="string">&quot;4000m&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-8-burstable</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:temp</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-8-Burstable</span></span><br><span class="line"><span class="string">        exec /stress-8-Burstable --vm 4  --vm-bytes 8G --no-oom-adjust</span></span><br><span class="line"><span class="string"></span>    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;300Mi&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-4-besteffort</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">xx.xx.82.174</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ctr</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry.aliyuncs.com/zhangguanzhang/stress-ng:temp</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">        cp stress-ng /stress-4-BestEffort</span></span><br><span class="line"><span class="string">        exec /stress-4-BestEffort --vm 2  --vm-bytes 4G --no-oom-adjust</span></span><br><span class="line"><span class="string"></span><span class="meta">---</span></span><br></pre></td></tr></table></figure><p>apply 后机器上日志最先 oom 的是 <code>4G</code> 这个:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Oct 11 10:38:03 82-174-zhang kernel: [1266038.261910] Memory cgroup out of memory: Kill process 7017 (stress-4-BestEf) score 1070 or sacrifice child</span><br><span class="line">Oct 11 10:38:03 82-174-zhang kernel: [1266038.267444] Killed process 7017 (stress-4-BestEf), UID 0, total-vm:2140696kB, anon-rss:2097272kB, file-rss:8kB, shmem-rss:4kB</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/">官方文档</a> 和 </li><li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/node-allocatable.md">最初的设计文档</a></li><li><a href="https://github.com/kubernetes-sigs/kubespray/blob/master/roles/kubernetes/node/defaults/main.yml">defaults/main.yml</a> 和 </li><li><a href="https://github.com/kubernetes-sigs/kubespray/blob/master/roles/kubernetes/node/templates/kubelet-config.v1beta1.yaml.j2">templates/kubelet-config.v1beta1.yaml.j2</a></li><li><a href="https://blog.csdn.net/u010278923/article/details/105688107">linux内核的oom score是咋算出来的</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前情提要&quot;&gt;&lt;a href=&quot;#前情提要&quot; class=&quot;headerlink&quot; title=&quot;前情提要&quot;&gt;&lt;/a&gt;前情提要&lt;/h2&gt;&lt;p&gt;我们环境有部分 pod 特殊，单独节点部署，oom 的时候会搞挂一些系统进程，这几天折腾了下配置了下 kubelet 相关的</summary>
      
    
    
    
    
    <category term="kubelet" scheme="http://zhangguanzhang.github.io/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>鲲鹏920的麒麟v10物理服务器断电后无法启动处理</title>
    <link href="http://zhangguanzhang.github.io/2021/07/26/kylin-v10-boot-hang/"/>
    <id>http://zhangguanzhang.github.io/2021/07/26/kylin-v10-boot-hang/</id>
    <published>2021-07-26T12:08:06.000Z</published>
    <updated>2021-07-26T12:08:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>珠海园区升压前置检查，上周六整个园区关电检查，然后今天来后连不上我们在 鲲鹏920的麒麟v10机器上开的虚拟机了，进 bmc 的 web 看了下是开机进入后卡住。</p><h2 id="信息同步"><a href="#信息同步" class="headerlink" title="信息同步"></a>信息同步</h2><p>是当初安装系统的同事去处理这个事情的，他 bmc 的 web 上去重启在菜单那里按 e 编辑准备改 boot cmdline 进单用户，结果按 e 后要输入用户名和密码，询问了麒麟他们。很久也没给答复。然后就在那干等，上面的虚机有我的环境，我就过去看了下。</p><h3 id="尝试的处理"><a href="#尝试的处理" class="headerlink" title="尝试的处理"></a>尝试的处理</h3><p>麒麟那边的人员没有回复，我打算这边同步尝试下其他手段，而且不只一台无法开机，哪怕麒麟的回复了密码也能同步尝试不同手段。Linux 无法开机的就搞个 yum 系列的新系统镜像挂载到光驱，然后设置成光驱启动，然后开机后进入 iso 的安装界面，<code>Troubleshooting –&gt; Rescue a CentOS Linux system</code>。先进 bmc web 上用java的远程窗口（之前华三的 h5 挂载镜像失败了），挂载本地的 麒麟v10 镜像，然后 bmc web 上设置下次从光驱启动。然后重启服务器，进 <code>Rescue</code> 模式里后，界面是显示乱的。</p><p>这个时候问了下珠海那边有同事能去机房看下吗，同事说正在赶去。然后我赶紧去找了下 centos 7的arm64镜像，后面下载完了进 <code>Rescue</code> 模式里一直卡住。估计没适配国产的服务器。后面尝试了其他国产的系统镜像，没 <code>Rescue</code> 模式。机房现场也有人去了，麒麟v10 镜像<code>Rescue</code> 模式进去后，他那边现场看了下也是显示乱的。</p><h3 id="单用户"><a href="#单用户" class="headerlink" title="单用户"></a>单用户</h3><p>后面麒麟回复了修改 boot 的时候用户名是 <code>root</code> 密码是 <code>Kylin123123</code>，确实能进入编辑 boot 的界面了，但是加了相关选项后还是无法进入单用户，左上角只有一个光标然后一直卡住。询问安装系统的同事，分区是咋搞的，他说 lvm 和有个大盘。然后问他有没有其他正常能开机的机器，他说有一个，我 ssh 上去后看到下面类似的分区：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk</span><br><span class="line">NAME            MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda               8:0    0 893.1G  0 disk </span><br><span class="line">├─sda1            8:1    0   200M  0 part /boot/efi</span><br><span class="line">├─sda2            8:2    0     1G  0 part /boot</span><br><span class="line">└─sda3            8:3    0   892G  0 part </span><br><span class="line">  ├─klas-root   252:0    0   838G  0 lvm  /</span><br><span class="line">  ├─klas-swap   252:1    0     4G  0 lvm  [SWAP]</span><br><span class="line">  └─klas-backup 252:2    0    50G  0 lvm  </span><br><span class="line">sdb               8:16   0  14.6T  0 disk </span><br><span class="line">└─sdb1            8:17   0     2T  0 part /oskvm</span><br></pre></td></tr></table></figure><p>正常机器的 lvm 信息如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vgs</span><br><span class="line">  VG   #PV #LV #SN Attr   VSize    VFree</span><br><span class="line">  klas   1   3   0 wz--n- &lt;891.94g    0 </span><br><span class="line">$ lvs</span><br><span class="line">  LV     VG   Attr       LSize    Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  backup klas -wi-a-----   50.00g                                                    </span><br><span class="line">  root   klas -wi-ao---- &lt;837.94g                                                    </span><br><span class="line">  swap   klas -wi-ao----    4.00g</span><br></pre></td></tr></table></figure><p>推测了下，无法开机的机器是因为把 sdb 搞成 lvm 的原因，所以单用户肯定别想了。</p><h3 id="Rescue-模式"><a href="#Rescue-模式" class="headerlink" title="Rescue 模式"></a>Rescue 模式</h3><p>目前的解决办法只有重装，这个时候快到中午了，其他同事催得急，重装代价太高了，安装慢，而且上面的虚拟机都没了，Rescue 模式后的乱码能解决就有办法了。看看正常机器上有没有显示的相关内核启动参数。</p><p>查找下 <code>grub</code> 的配置文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cd /boot</span><br><span class="line">$ find -type f -name &#x27;grub*&#x27;</span><br><span class="line">./efi/EFI/kylin/grubaa64.efi</span><br><span class="line">./efi/EFI/kylin/grubenv</span><br><span class="line">./efi/EFI/kylin/grub.cfg</span><br></pre></td></tr></table></figure><p>看了下果然有</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat ./efi/EFI/kylin/grub.cfg</span><br><span class="line">linux/vmlinuz-4.19.90-17.ky10.aarch64 root=/dev/mapper/klas-root ro crashkernel=auto rd.lvm.lv=klas/root rd.lvm.lv=klas/swap smmu.bypassdev=0x1000:0x17 smmu.bypassdev=0x1000:0x15 crashkernel=1024M,high video=efifb:off video=VGA-1:640x480-32@60me</span><br></pre></td></tr></table></figure><p>然后在 麒麟v10 的 iso 进入了 <code>Troubleshooting –&gt; Rescue</code> 选中 <code>Rescue</code> 先别回车，直接按 e 编辑，<code>linux</code>那行后面加了上面的<code> video=efifb:off video=VGA-1:640x480-32@60me</code>，然后 <code>ctrl + x</code> 启动，显示正常了。和 Centos 的 <code>Rescue</code> 有点不一样，进去后类似进入 emergency 模式里，然后回车继续，进入到了一个 bash。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vgchange -a y</span><br><span class="line">$ lvs</span><br><span class="line">  LV     VG   Attr       LSize    Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  18     18   -wi-ao----   14.55t                                                    </span><br><span class="line">  backup klas -wi-a-----   50.00g                                                    </span><br><span class="line">  root   klas -wi-ao---- &lt;837.94g                                                    </span><br><span class="line">  swap   klas -wi-ao----    4.00g     </span><br><span class="line">$ mkdir /mnt/sysimage</span><br></pre></td></tr></table></figure><p>然后挂载 root 分区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mount /dev/mapper/klas-root /mnt/sysimage</span><br><span class="line">$ chroot /mnt/sysimage</span><br></pre></td></tr></table></figure><p>其实也没必要 chroot 进去，无非就是 vi 多了个前面的路径。取消最后一行的挂载，然后 reboot 后重启就好了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 没chroot进去就是编辑 vi /mnt/sysimage/etc/fstab</span><br><span class="line">$ vi /etc/fstab</span><br><span class="line">...</span><br><span class="line">#/dev/mapper/18-18     /oskvm                    xfs     default   0 0</span><br></pre></td></tr></table></figure><h2 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h2><p>可能是分区太大了，lvm 在国产系统开机上有问题。另外也不推荐物理机使用 lvm，能不查资料笔记熟悉 lvm 的命令的人实际上目前不多，会修复的人更少了。lvm 扩容一时爽，恢复火葬场。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ pvs</span><br><span class="line">  PV         VG   Fmt  Attr PSize    PFree </span><br><span class="line">  /dev/sda3  klas lvm2 a--  &lt;891.94g     0 </span><br><span class="line">  /dev/sdb   18   lvm2 a--    14.55t &lt;1.16g</span><br><span class="line">l$ vgs</span><br><span class="line">  VG   #PV #LV #SN Attr   VSize    VFree </span><br><span class="line">  18     1   1   0 wz--n-   14.55t &lt;1.16g</span><br><span class="line">  klas   1   3   0 wz--n- &lt;891.94g     0 </span><br><span class="line">$ lvs</span><br><span class="line">  LV     VG   Attr       LSize    Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  18     18   -wi-ao----   14.55t                                                    </span><br><span class="line">  backup klas -wi-a-----   50.00g                                                    </span><br><span class="line">  root   klas -wi-ao---- &lt;837.94g                                                    </span><br><span class="line">  swap   klas -wi-ao----    4.00g </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前情提要&quot;&gt;&lt;a href=&quot;#前情提要&quot; class=&quot;headerlink&quot; title=&quot;前情提要&quot;&gt;&lt;/a&gt;前情提要&lt;/h2&gt;&lt;p&gt;珠海园区升压前置检查，上周六整个园区关电检查，然后今天来后连不上我们在 鲲鹏920的麒麟v10机器上开的虚拟机了，进 bmc</summary>
      
    
    
    
    
    <category term="kylin" scheme="http://zhangguanzhang.github.io/tags/kylin/"/>
    
    <category term="arm64" scheme="http://zhangguanzhang.github.io/tags/arm64/"/>
    
  </entry>
  
</feed>
